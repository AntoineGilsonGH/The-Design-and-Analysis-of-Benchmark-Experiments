{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import scipy.stats as stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import uniform, norm\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_antoine = \"/Users/antoine.gilson/Desktop/The-Design-and-Analysis-of-Benchmark-Experiments/Plots/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta2_values = np.linspace(0, 0.16, 9)\n",
    "M = [150,200,500,1000,2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction, variables, training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_training_test_sets(n=150, m=2000, seed=42): # Vérifier que la distributon de nos lois est bien la bonne\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    x = np.random.uniform(0, 5, n + m)\n",
    "    x_train = x[:n]\n",
    "    x_test = x[n:n+m]\n",
    "    \n",
    "    epsilon = np.random.normal(0, 1, n + m)\n",
    "    epsilon_train = epsilon[:n]\n",
    "    epsilon_test = epsilon[n:n+m]\n",
    "    \n",
    "    # Création de la figure avec subplots\n",
    "    fig, ax = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    \n",
    "    # Plotting X Training set\n",
    "    ax[0, 0].scatter(np.arange(n), x_train, label=\"X Training set n = 150\", color=\"blue\", s=10)\n",
    "    ax[0, 0].set_title(\"Training Set X\")\n",
    "    ax[0, 0].set_xlabel(\"Index\")\n",
    "    ax[0, 0].set_ylabel(\"Value\")\n",
    "    ax[0, 0].legend()\n",
    "    ax[0, 0].grid()\n",
    "\n",
    "    # Plotting X Test set\n",
    "    ax[0, 1].scatter(np.arange(n, n + m), x_test, label=\"X Test set m = 150\", color=\"red\", s=10)\n",
    "    ax[0, 1].set_title(\"Test Set X\")\n",
    "    ax[0, 1].set_xlabel(\"Index\")\n",
    "    ax[0, 1].set_ylabel(\"Value\")\n",
    "    ax[0, 1].legend()\n",
    "    ax[0, 1].grid()\n",
    "\n",
    "    # Plotting Epsilon Training set\n",
    "    ax[1, 0].scatter(np.arange(n), epsilon_train, label=\"Epsilon Training set n = 150\", color=\"green\", s=10)\n",
    "    ax[1, 0].set_title(\"Training Set Epsilon\")\n",
    "    ax[1, 0].set_xlabel(\"Index\")\n",
    "    ax[1, 0].set_ylabel(\"Value\")\n",
    "    ax[1, 0].legend()\n",
    "    ax[1, 0].grid()\n",
    "\n",
    "    # Plotting Epsilon Test set\n",
    "    ax[1, 1].scatter(np.arange(n, n + m), epsilon_test, label=\"Epsilon Test set m = 150\", color=\"orange\", s=10)\n",
    "    ax[1, 1].set_title(\"Test Set Epsilon\")\n",
    "    ax[1, 1].set_xlabel(\"Index\")\n",
    "    ax[1, 1].set_ylabel(\"Value\")\n",
    "    ax[1, 1].legend()\n",
    "    ax[1, 1].grid()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.scatter(np.arange(n), x_train, label = \"X Training set n = 150\", color = \"blue\", s = 8)\n",
    "    plt.scatter(np.arange(n, n+m), x_test, label = \"X Test set m = 150\", color = \"red\", s = 8)\n",
    "    plt.xlabel(\"Point de l'ensemble de test ou d'entrainement\")\n",
    "    plt.ylabel(\"Valeur de X\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.scatter(np.arange(n), epsilon_train, label = \"Eps Training set n = 150\", color = \"green\", s = 8)\n",
    "    plt.scatter(np.arange(n, n+m), epsilon_test, label = \"Eps Test set m = 150\", color = \"orange\", s = 8)\n",
    "    plt.xlabel(\"Point de l'ensemble de test ou d'entrainement\")\n",
    "    plt.ylabel(\"Valeur de Epsilon\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_training_test_sets_hist(n=150, m=2000, seed=42): # vérifier que la distribution de nos lois est bien la bonne, histogramme\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    x = np.random.uniform(0, 5, n + m)\n",
    "    x_train = x[:n]\n",
    "    x_test = x[n:n+m]\n",
    "    \n",
    "    epsilon = np.random.normal(0, 1, n + m)\n",
    "    epsilon_train = epsilon[:n]\n",
    "    epsilon_test = epsilon[n:n+m]\n",
    "\n",
    "    x_vals = np.linspace(0, 5, 100)\n",
    "    epsilon_vals = np.linspace(-4, 4, 100)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.title(\"Distribution de X\")\n",
    "    plt.hist(x_train, bins=30, label=\"X Training set n_train = 150\", color=\"blue\", edgecolor='black', alpha=0.7, density=True)\n",
    "    plt.hist(x_test, bins=30, label=\"X Test set n_test = 2000\", color=\"red\", edgecolor='black', alpha=0.7, density=True)\n",
    "    plt.plot(x_vals, uniform.pdf(x_vals, 0, 5), 'k-', label=\"Uniform(0, 5)\")\n",
    "    plt.xlabel(\"Value\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.title(\"Distribution de epsilon\")\n",
    "    plt.hist(epsilon_train, bins=30, label=\"Eps Training set n_train = 150\", color=\"green\", edgecolor='black', alpha=0.7, density=True)\n",
    "    plt.hist(epsilon_test, bins=30, label=\"Eps Test set m_train = 2000\", color=\"orange\", edgecolor='black', alpha=0.7, density=True)\n",
    "    plt.plot(epsilon_vals, norm.pdf(epsilon_vals, 0, 1), 'k-', label=\"Normal(0, 1)\")\n",
    "    plt.xlabel(\"Value\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_training_test_sets_2(n=150, m=2000, seed = 42): # ensemble x_train, y_train\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    beta1 = 2\n",
    "    x = np.random.uniform(0, 5, n + m)\n",
    "    x_train = x[:n]\n",
    "    x_test = x[n:n+m]\n",
    "    \n",
    "    epsilon = np.random.normal(0, 1, n + m)\n",
    "    epsilon_train = epsilon[:n]\n",
    "    epsilon_test = epsilon[n:n+m]   \n",
    "\n",
    "    for beta2 in beta2_values:\n",
    "\n",
    "          y_train = beta1 * x_train + beta2 * x_train**2 + epsilon_train\n",
    "          y_test = beta1 * x_test + beta2 * x_test**2 + epsilon_test\n",
    "          y = beta1 * x + beta2 * x**2 + epsilon\n",
    "\n",
    "          plt.figure()\n",
    "          plt.title(\"ratio\")\n",
    "          plt.plot(x[np.argsort(x)],y[np.argsort(x)], label =\"tout y\", color = \"black\")\n",
    "          plt.plot(x_train[np.argsort(x_train)],y_train[np.argsort(x_train)], label =\"ensembe d'entrainement\", color = \"yellow\")\n",
    "          plt.grid()\n",
    "          plt.legend()\n",
    "          plt.show()\n",
    "\n",
    "          plt.figure()\n",
    "          plt.title(\"ratio\")\n",
    "          plt.plot(x[np.argsort(x)],y[np.argsort(x)], label =\"tout y\", color = \"black\")\n",
    "          plt.plot(x_test[np.argsort(x_test)],y_test[np.argsort(x_test)], label =\"ensembe d'entrainement\", color = \"green\")\n",
    "          plt.grid()\n",
    "          plt.legend()\n",
    "          plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_training_test_sets_3(): # Modèles fitted\n",
    "    \n",
    "      n = 150\n",
    "      m = 2000\n",
    "\n",
    "      np.random.seed(42)\n",
    "      beta1 = 2\n",
    "      epsilon = np.random.normal(0, 1, n + m) \n",
    "      x = np.random.uniform(0, 5, n + m)\n",
    "\n",
    "      x_train = x[:n]\n",
    "      x_test = x[n:n+m]\n",
    "\n",
    "      epsilon_train = epsilon[:n]\n",
    "      epsilon_test = epsilon[n:n+m]\n",
    "    \n",
    "      for beta2 in [1]:\n",
    "            \n",
    "          \n",
    "          y_train = beta1 * x_train + beta2 * x_train**2 + epsilon_train\n",
    "          y_test = beta1 * x_test + beta2 * x_test**2 + epsilon_test\n",
    "\n",
    "           # Linear Model : A\n",
    "          model_a = LinearRegression().fit(x_train.reshape(-1, 1), y_train)\n",
    "          y_pred_a = model_a.predict(x_test.reshape(-1, 1))\n",
    "          pa = (y_test - y_pred_a)**2\n",
    "\n",
    "          coef_a = model_a.coef_[0]\n",
    "          intercept_a = model_a.intercept_     \n",
    "        \n",
    "          # Quadratic Model : B\n",
    "          x_train_quad = np.column_stack((x_train, x_train**2))\n",
    "          x_test_quad = np.column_stack((x_test, x_test**2))\n",
    "            \n",
    "          model_b = LinearRegression().fit(x_train_quad, y_train)\n",
    "          y_pred_b = model_b.predict(x_test_quad)\n",
    "          pb = (y_test - y_pred_b)**2\n",
    "\n",
    "          coef_b = model_b.coef_\n",
    "          intercept_b = model_b.intercept_\n",
    "\n",
    "          y = beta1*x + beta2*x**2 +epsilon \n",
    "          eq_a = intercept_a + coef_a * x\n",
    "          eq_a_train = intercept_a + coef_a * x_train\n",
    "          eq_a_test = intercept_a + coef_a * x_test\n",
    "          eq_b = intercept_b + coef_b[0] * x + coef_b[1] * x**2\n",
    "          eq_b_train = intercept_b + coef_b[0] * x_train + coef_b[1] * x_train**2\n",
    "          eq_b_test = intercept_b + coef_b[0] * x_test + coef_b[1] * x_test**2\n",
    "\n",
    "          plt.figure() # Fits des modèles \n",
    "          plt.title(\"Fits d'entrainement des modèles pour \" f\"beta2 = {beta2}\" \" et pour \"f\"n_train= {n}\" )  \n",
    "          plt.plot(x_train[np.argsort(x_train)], y_train[np.argsort(x_train)], label = \"Y réel\", color = \"green\")\n",
    "          plt.plot(x_train[np.argsort(x_train)], eq_a_train[np.argsort(x_train)], label = \"Prédiction linéaire\", color = \"Red\")\n",
    "          plt.plot(x_train[np.argsort(x_train)], eq_b_train[np.argsort(x_train)], label = \"Prédiction quadratique\", color = \"Orange\")\n",
    "          plt.xlabel(\"X\")\n",
    "          plt.ylabel(\"Y\")\n",
    "          plt.grid()\n",
    "          plt.legend()  \n",
    "          plt.show()     \n",
    "\n",
    "\n",
    "          plt.figure() # Fits des modèles \n",
    "          plt.title(\"Fits de test des modèles pour \" f\"beta2 = {beta2}\" \" et pour \"f\"n_test = {m}\" )  \n",
    "          plt.plot(x_test[np.argsort(x_test)], y_test[np.argsort(x_test)], label = \"Y réel\", color = \"green\")\n",
    "          plt.plot(x_test[np.argsort(x_test)], eq_a_test[np.argsort(x_test)], label = \"Prédiction linéaire\", color = \"Red\")\n",
    "          plt.plot(x_test[np.argsort(x_test)], eq_b_test[np.argsort(x_test)], label = \"Prédiction quadratique\", color = \"Orange\")\n",
    "          plt.xlabel(\"X\")\n",
    "          plt.ylabel(\"Y\")\n",
    "          plt.grid()\n",
    "          plt.legend()  \n",
    "          plt.show()  \n",
    "\n",
    "          plt.figure() # Fits des modèles \n",
    "          plt.title(\"Fits des modèles pour \" f\"beta2 = {beta2}\" \" et pour \"f\"n_test = {m}\" )  \n",
    "          plt.plot(x[np.argsort(x)], y[np.argsort(x)], label = \"Y réel\", color = \"green\")\n",
    "          plt.plot(x[np.argsort(x)], eq_a[np.argsort(x)], label = \"Prédiction linéaire\", color = \"Red\")\n",
    "          plt.plot(x[np.argsort(x)], eq_b[np.argsort(x)], label = \"Prédiction quadratique\", color = \"Orange\")\n",
    "          plt.xlabel(\"X\")\n",
    "          plt.ylabel(\"Y\")\n",
    "          plt.grid()\n",
    "          plt.legend()  \n",
    "          plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphical approach of model precision and errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performances_metrics_boxplot():\n",
    "    np.random.seed(42)\n",
    "    n = 150\n",
    "    M = [150, 200, 500, 1000, 2000]\n",
    "    beta1 = 2\n",
    "\n",
    "\n",
    "    for m in M:\n",
    "\n",
    "        x = np.random.uniform(0, 5, n + m)\n",
    "        x_train = x[:n]\n",
    "\n",
    "        epsilon = np.random.normal(0, 1, n + m)\n",
    "        epsilon_train = epsilon[:n]\n",
    "        x_test = x[n:n + m]\n",
    "        epsilon_test = epsilon[n:n + m]\n",
    "\n",
    "        for beta2 in beta2_values:\n",
    "            y = beta1 * x + beta2 * x**2 + epsilon\n",
    "            y_train = beta1 * x_train + beta2 * x_train**2 + epsilon_train\n",
    "            y_test = beta1 * x_test + beta2 * x_test**2 + epsilon_test\n",
    "\n",
    "            # Linear Model : A\n",
    "            model_a = LinearRegression().fit(x_train.reshape(-1, 1), y_train)\n",
    "            y_pred_a = model_a.predict(x_test.reshape(-1, 1))\n",
    "            pa = (y_test - y_pred_a)**2\n",
    "\n",
    "            # Quadratic Model : B\n",
    "            x_train_quad = np.column_stack((x_train, x_train**2))\n",
    "            x_test_quad = np.column_stack((x_test, x_test**2))\n",
    "\n",
    "            model_b = LinearRegression().fit(x_train_quad, y_train)\n",
    "            y_pred_b = model_b.predict(x_test_quad)\n",
    "            pb = (y_test - y_pred_b)**2\n",
    "\n",
    "            differences = pa - pb\n",
    "\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.title(f\"pa - pb  pour beta2 = {beta2} et pour n_test= {m}\")\n",
    "\n",
    "            # Scatter plot des différences\n",
    "            sns.scatterplot(x=x_test, y=differences, color=\"red\", s=6, label=f\"Differences pour beta2 = {beta2} et pour n_test = {m}\")\n",
    "            plt.axhline(y=0, color='black', linestyle='--', label='y = 0')\n",
    "\n",
    "            # Ajouter les données pour le boxplot\n",
    "            box = plt.boxplot(differences, positions=[max(x_test) + 1], widths=0.5, patch_artist=True,\n",
    "                              boxprops=dict(facecolor='blue', color='blue', alpha=0.5),\n",
    "                              medianprops=dict(color='yellow'),\n",
    "                              whiskerprops=dict(color='blue'),\n",
    "                              capprops=dict(color='blue'),\n",
    "                              flierprops=dict(color='blue', markeredgecolor='blue'))\n",
    "\n",
    "            # Récupérer les valeurs des whiskers et des quartiles\n",
    "            whisker_min = box['whiskers'][0].get_ydata()[1]\n",
    "            whisker_max = box['whiskers'][1].get_ydata()[1]\n",
    "            q1 = box['boxes'][0].get_path().vertices[0, 1]\n",
    "            median = box['medians'][0].get_ydata()[0]\n",
    "            q3 = box['boxes'][0].get_path().vertices[2, 1]\n",
    "\n",
    "            # Annoter les valeurs sur le graphique\n",
    "            plt.text(max(x_test) + 1, whisker_min, f'Whisker Min: {whisker_min:.2f}', horizontalalignment='center', color='black')\n",
    "            plt.text(max(x_test) + 1, whisker_max, f'Whisker Max: {whisker_max:.2f}', horizontalalignment='center', color='black')\n",
    "            plt.text(max(x_test) + 1, q1, f'Q1: {q1:.2f}', horizontalalignment='center', color='black')\n",
    "            plt.text(max(x_test) + 1, median, f'Median: {median:.2f}', horizontalalignment='center', color='black')\n",
    "            plt.text(max(x_test) + 1, q3, f'Q3: {q3:.2f}', horizontalalignment='center', color='black')\n",
    "\n",
    "            plt.xlabel(\"X test set\")\n",
    "            plt.ylabel(\"Differences\")\n",
    "            plt.grid()\n",
    "            plt.legend()\n",
    "\n",
    "            filename = f\"{path_antoine}/Erreurs/ModeleB/CondToX/plot_m_{m}_beta2_{beta2}.png\"\n",
    "            plt.savefig(filename)\n",
    "\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_metrics_hist():\n",
    "    \n",
    "    n = 150\n",
    "\n",
    "    M = [150, 200, 500, 1000, 2000]\n",
    "\n",
    "    for m in M:\n",
    "\n",
    "      np.random.seed(42)\n",
    "      beta1 = 2\n",
    "      epsilon = np.random.normal(0, 1, n + m) \n",
    "      x = np.random.uniform(0, 5, n + m)\n",
    "\n",
    "      x_train = x[:n]\n",
    "      x_test = x[n:n+m]\n",
    "\n",
    "      epsilon_train = epsilon[:n]\n",
    "      epsilon_test = epsilon[n:n+m]\n",
    "    \n",
    "      for beta2 in [0, 0.2, 0.4, 0.6, 0.6, 0.1, 0.12, 0.14, 0.16, 0.3, 0.5, 1]:\n",
    "            \n",
    "          \n",
    "          y_train = beta1 * x_train + beta2 * x_train**2 + epsilon_train\n",
    "          y_test = beta1 * x_test + beta2 * x_test**2 + epsilon_test\n",
    "\n",
    "           # Linear Model : A\n",
    "          model_a = LinearRegression().fit(x_train.reshape(-1, 1), y_train)\n",
    "          y_pred_a = model_a.predict(x_test.reshape(-1, 1))\n",
    "          pa = (y_test - y_pred_a)**2\n",
    "\n",
    "          coef_a = model_a.coef_[0]\n",
    "          intercept_a = model_a.intercept_     \n",
    "        \n",
    "          # Quadratic Model : B\n",
    "          x_train_quad = np.column_stack((x_train, x_train**2))\n",
    "          x_test_quad = np.column_stack((x_test, x_test**2))\n",
    "            \n",
    "          model_b = LinearRegression().fit(x_train_quad, y_train)\n",
    "          y_pred_b = model_b.predict(x_test_quad)\n",
    "          pb = (y_test - y_pred_b)**2\n",
    "\n",
    "          coef_b = model_b.coef_\n",
    "          intercept_b = model_b.intercept_\n",
    "\n",
    "          differences = pa - pb\n",
    "\n",
    "          plt.figure() # Erreur individuelle des modèles\n",
    "          plt.title(\"prédiction du modèle linéaire pour \" f\"beta2 = {beta2}\" \" et pour \"f\"n_test = {m}\" ) \n",
    "          plt.hist(pa, bins=30, label=f\"pa = (y - ya)^2 pour beta2 = {beta2} et pour n_test = {m}\", color=\"red\", edgecolor='black', alpha=0.7)\n",
    "          plt.xlabel(\" Erreur associée \")\n",
    "          plt.ylabel(\"Nombre d'occurences\")      \n",
    "          plt.grid()\n",
    "          plt.legend()\n",
    "          filename = f\"{path_antoine}/Erreurs/ModeleA/Frequency/plot_m_{m}_beta2_{beta2}.png\"\n",
    "          plt.savefig(filename)\n",
    "          plt.show()\n",
    "\n",
    "          plt.figure()\n",
    "          plt.title(\"prédiction du modèle quadratique pour \" f\"beta2 = {beta2}\" \" et pour \"f\"n_test = {m}\" )       \n",
    "          plt.hist(pb, bins=30, label=f\"pb = (y - yb)^2 pour beta2 = {beta2} et pour n_test = {m}\", color=\"orange\", edgecolor='black', alpha=0.7)\n",
    "          plt.xlabel(\" Erreur associée \")\n",
    "          plt.ylabel(\"Nombre d'occurences\")      \n",
    "          plt.grid()\n",
    "          plt.legend()\n",
    "          filename = f\"{path_antoine}/Erreurs/ModeleB/Frequency/plot_m_{m}_beta2_{beta2}.png\"\n",
    "          plt.savefig(filename)\n",
    "          plt.show()\n",
    "\n",
    "          plt.figure()\n",
    "          plt.title(\"Différence de prédiction des modèles \" f\"beta2 = {beta2}\" \" et pour \"f\"n_test = {m}\" )        \n",
    "          plt.hist(differences, bins=30, label=f\"pa - pb pour beta2 = {beta2} et pour n_test = {m}\", color=\"blue\", edgecolor='black', alpha=0.7)\n",
    "          plt.xlabel(\" Erreur associée \")\n",
    "          plt.ylabel(\"Nombre d'occurences\")      \n",
    "          plt.grid()\n",
    "          plt.legend()\n",
    "          filename = f\"{path_antoine}/Erreurs/Differences/Frequency/plot_m_{m}_beta2_{beta2}.png\"\n",
    "          plt.savefig(filename)\n",
    "          plt.show()\n",
    "\n",
    "          \"\"\"\n",
    "\n",
    "          y = beta1*x + beta2*x**2 +epsilon \n",
    "          eq_a = intercept_a + coef_a * x\n",
    "          eq_a_train = intercept_a + coef_a * x_train\n",
    "          eq_a_test = intercept_a + coef_a * x_test\n",
    "          eq_b = intercept_b + coef_b[0] * x + coef_b[1] * x**2\n",
    "          eq_b_train = intercept_b + coef_b[0] * x_train + coef_b[1] * x_train**2\n",
    "          eq_b_test = intercept_b + coef_b[0] * x_test + coef_b[1] * x_test**2\n",
    "\n",
    "          plt.figure() # Fits des modèles \n",
    "          plt.title(\"Fits d'entrainement du modèle quadratique pour \" f\"beta2 = {beta2}\" \" et pour \"f\"n_test = {m}\" )  \n",
    "          plt.plot(x[np.argsort(x)], y[np.argsort(x)], label = \"Y réel\", color = \"green\")\n",
    "          plt.plot(x[np.argsort(x)], eq_a[np.argsort(x)], label = \"Prédiction linéaire\", color = \"Red\")\n",
    "          plt.plot(x[np.argsort(x)], eq_b[np.argsort(x)], label = \"Prédiction quadratique\", color = \"Orange\")\n",
    "          plt.xlabel(\"X\")\n",
    "          plt.ylabel(\"Y\")\n",
    "          plt.grid()\n",
    "          plt.legend()  \n",
    "          filename = f\"{path_antoine}/Fits/Continuous/plot_m_{m}_beta2_{beta2}.png\"\n",
    "          plt.savefig(filename)\n",
    "          plt.show()   \n",
    "          \"\"\"  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE():\n",
    "    \n",
    "    n = 150\n",
    "    m = 2000\n",
    "\n",
    "    np.random.seed(42)\n",
    "    beta1 = 2\n",
    "    epsilon = np.random.normal(0, 1, n + m) \n",
    "    x = np.random.uniform(0, 5, n + m)\n",
    "\n",
    "    x_train = x[:n]\n",
    "    x_test = x[n:n+m]\n",
    "\n",
    "    epsilon_train = epsilon[:n]\n",
    "    epsilon_test = epsilon[n:n+m]\n",
    "\n",
    "    mse_A = []\n",
    "    mse_B = []\n",
    "    \n",
    "    for beta2 in beta2_values:\n",
    "            \n",
    "        y_train = beta1 * x_train + beta2 * x_train**2 + epsilon_train\n",
    "        y_test = beta1 * x_test + beta2 * x_test**2 + epsilon_test\n",
    "\n",
    "         # Linear Model : A\n",
    "        model_a = LinearRegression().fit(x_train.reshape(-1, 1), y_train)\n",
    "        y_pred_a = model_a.predict(x_test.reshape(-1, 1))\n",
    "\n",
    "        mse_A.append(mean_squared_error(y_pred_a, y_test))\n",
    "    \n",
    "          # Quadratic Model : B\n",
    "        x_train_quad = np.column_stack((x_train, x_train**2))\n",
    "        x_test_quad = np.column_stack((x_test, x_test**2))\n",
    "            \n",
    "        model_b = LinearRegression().fit(x_train_quad, y_train)\n",
    "        y_pred_b = model_b.predict(x_test_quad)\n",
    "        mse_B.append(mean_squared_error(y_pred_b, y_test))\n",
    "\n",
    "    plt.figure()\n",
    "    plt.title(\"Différence des MSE\")\n",
    "    plt.plot(beta2_values, mse_A, label = \"MSE_A\")\n",
    "    plt.plot(beta2_values, mse_B, label = \"MSE_B\")\n",
    "       \n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptive Statistics, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descriptive_statistics():\n",
    "    \n",
    "    n = 150\n",
    "\n",
    "    M = [150, 200, 500, 1000, 2000]\n",
    "\n",
    "    empirical_means_A = []\n",
    "    standard_deviations_A = []\n",
    "    medians_A = []\n",
    "    Q1_A = []\n",
    "    Q3_A = []\n",
    "    IQR_A = []\n",
    "\n",
    "    empirical_means_B = []\n",
    "    standard_deviations_B = []\n",
    "    medians_B = []\n",
    "    Q1_B = []\n",
    "    Q3_B = []\n",
    "    IQR_B = []\n",
    "\n",
    "    for m in M:\n",
    "\n",
    "      a = []\n",
    "      b = []\n",
    "      c = []\n",
    "      d = []\n",
    "      q = []\n",
    "      iqr = []\n",
    "\n",
    "      e = []\n",
    "      f = []\n",
    "      g = []\n",
    "      h = []\n",
    "      q_ = []\n",
    "      iqr_ = []\n",
    "\n",
    "\n",
    "      np.random.seed(42)\n",
    "      beta1 = 2\n",
    "      beta2_values_bis = [0.2, 0.3, 0.4, 0.5, 1]\n",
    "      epsilon = np.random.normal(0, 1, n + m) \n",
    "      x = np.random.uniform(0, 5, n + m)\n",
    "\n",
    "      x_train = x[:n]\n",
    "      x_test = x[n:n+m]\n",
    "\n",
    "      epsilon_train = epsilon[:n]\n",
    "      epsilon_test = epsilon[n:n+m]\n",
    "    \n",
    "      for beta2 in beta2_values:\n",
    "            \n",
    "          y_train = beta1 * x_train + beta2 * x_train**2 + epsilon_train\n",
    "          y_test = beta1 * x_test + beta2 * x_test**2 + epsilon_test\n",
    "\n",
    "        # Linear Model : A\n",
    "          model_a = LinearRegression().fit(x_train.reshape(-1, 1), y_train)\n",
    "          y_pred_a = model_a.predict(x_test.reshape(-1, 1))\n",
    "          pa = (y_test - y_pred_a)**2\n",
    "    \n",
    "        # Quadratic Model : B\n",
    "          x_train_quad = np.column_stack((x_train, x_train**2))\n",
    "          x_test_quad = np.column_stack((x_test, x_test**2))\n",
    "            \n",
    "          model_b = LinearRegression().fit(x_train_quad, y_train)\n",
    "          y_pred_b = model_b.predict(x_test_quad)\n",
    "          pb = (y_test - y_pred_b)**2\n",
    "\n",
    "          mean_a = sum(pa)/m\n",
    "          mean_b = sum(pb)/m\n",
    "\n",
    "          a.append(mean_a)\n",
    "          e.append(mean_b)\n",
    "\n",
    "          std_a = np.std(pa, ddof=1)\n",
    "          std_b = np.std(pb, ddof = 1)\n",
    "\n",
    "          b.append(std_a)\n",
    "          f.append(std_b)\n",
    "\n",
    "          q1_a = np.percentile(pa, 25)\n",
    "          med_a = np.percentile(pa, 50)        \n",
    "          q3_a = np.percentile(pa, 75)\n",
    "\n",
    "          q1_b = np.percentile(pb, 25)\n",
    "          med_b = np.percentile(pb, 50)        \n",
    "          q3_b = np.percentile(pb, 75)\n",
    "\n",
    "          c.append(med_a)\n",
    "          g.append(med_b)\n",
    "          d.append(q1_a)\n",
    "          q.append(q3_a)\n",
    "          h.append(q1_b)\n",
    "          q_.append(q3_b)\n",
    "\n",
    "          iqr.append(q3_a - q1_a)\n",
    "          iqr_.append(q3_b - q1_b)\n",
    "\n",
    "      empirical_means_A.append(a)\n",
    "      empirical_means_B.append(e)\n",
    "      standard_deviations_A.append(b)\n",
    "      standard_deviations_B.append(f)\n",
    "      medians_A.append(c)\n",
    "      medians_B.append(g)\n",
    "      Q1_A.append(d)\n",
    "      Q1_B.append(h)\n",
    "      Q3_A.append(q)\n",
    "      Q3_B.append(q_)\n",
    "      IQR_A.append(iqr)\n",
    "      IQR_B.append(iqr_)\n",
    "\n",
    "    return empirical_means_A, standard_deviations_A, medians_A, Q1_A, Q3_A, IQR_A, empirical_means_B, standard_deviations_B, medians_B, Q1_B, Q3_B, IQR_B\n",
    "\n",
    "\n",
    "empirical_means_A, standard_deviations_A, medians_A, Q1_A, Q3_A, IQR_A, empirical_means_B, standard_deviations_B, medians_B, Q1_B, Q3_B, IQR_B = descriptive_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data():\n",
    "    \n",
    "    M = [150, 200, 500, 1000, 2000]\n",
    "    \n",
    "    empirical_means_A, standard_deviations_A, medians_A, Q1_A, Q3_A, IQR_A, empirical_means_B, standard_deviations_B, medians_B, Q1_B, Q3_B, IQR_B = descriptive_statistics()\n",
    "    \n",
    "    \n",
    "    data_A_all = {\n",
    "    \"Empirical Mean\": empirical_means_A,\n",
    "    \"Standard Deviation\": standard_deviations_A,\n",
    "    \"Median\": medians_A,\n",
    "    \"Q1\": Q1_A,\n",
    "    \"Q3\": Q3_A,\n",
    "    \"IQR\": IQR_A\n",
    "   }\n",
    "\n",
    "    stats_A_all = pd.DataFrame(data_A_all, index=M)\n",
    "\n",
    "    data_B_all = {\n",
    "    \"Empirical Mean\": empirical_means_B,\n",
    "    \"Standard Deviation\": standard_deviations_B,\n",
    "    \"Median\": medians_B,\n",
    "    \"Q1\": Q1_B,\n",
    "    \"Q3\": Q3_B,\n",
    "    \"IQR\": IQR_B\n",
    "   }\n",
    "\n",
    "    stats_B_all = pd.DataFrame(data_B_all, index=M)\n",
    "\n",
    "    df_empirical_means_A = pd.DataFrame(empirical_means_A, index=M, columns=beta2_values).transpose()\n",
    "    df_empirical_standard_deviations_A = pd.DataFrame(standard_deviations_A, index=M, columns=beta2_values).transpose()\n",
    "    df_medians_A = pd.DataFrame(medians_A, index=M, columns=beta2_values).transpose()\n",
    "    df_Q1_A = pd.DataFrame(Q1_A, index=M, columns=beta2_values).transpose()\n",
    "    df_Q3_A = pd.DataFrame(Q3_A, index=M, columns=beta2_values).transpose()\n",
    "    df_IQR_A = pd.DataFrame(IQR_A, index=M, columns=beta2_values).transpose()\n",
    "\n",
    "    df_empirical_means_B = pd.DataFrame(empirical_means_B, index=M, columns=beta2_values).transpose()\n",
    "    df_empirical_standard_deviations_B = pd.DataFrame(standard_deviations_B, index=M, columns=beta2_values).transpose()\n",
    "    df_medians_B = pd.DataFrame(medians_B, index=M, columns=beta2_values).transpose()\n",
    "    df_Q1_B = pd.DataFrame(Q1_B, index=M, columns=beta2_values).transpose()\n",
    "    df_Q3_B = pd.DataFrame(Q3_B, index=M, columns=beta2_values).transpose()\n",
    "    df_IQR_B = pd.DataFrame(IQR_B, index=M, columns=beta2_values).transpose()    \n",
    "\n",
    "    return stats_A_all, df_empirical_means_A, df_empirical_standard_deviations_A, df_medians_A, df_Q1_A, df_Q3_A, df_IQR_A, \\\n",
    "    stats_B_all, df_empirical_means_B, df_empirical_standard_deviations_B, df_medians_B, df_Q1_B, df_Q3_B, df_IQR_B\n",
    "\n",
    "\n",
    "(stats_A_all, df_empirical_means_A, df_empirical_standard_deviations_A, df_medians_A, df_Q1_A, df_Q3_A, df_IQR_A, \n",
    "    stats_B_all, df_empirical_means_B, df_empirical_standard_deviations_B, df_medians_B, df_Q1_B, df_Q3_B, df_IQR_B) = create_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First shot looking at our Standard deviations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varying beta2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Premier subplot : Comparaison des valeurs de deviations standard selon beta2\n",
    "axs[0, 0].plot(beta2_values, df_empirical_standard_deviations_A[2000], label=\"std error A\", color = \"black\")\n",
    "axs[0, 0].plot(beta2_values, df_empirical_standard_deviations_B[2000], label=\"std error B\", color = \"yellow\")\n",
    "axs[0, 0].set_title(\"Comparaison des valeurs de deviations standard selon beta2\")\n",
    "axs[0, 0].grid()\n",
    "axs[0, 0].legend()\n",
    "\n",
    "# Deuxième subplot : Quartiles de l'erreur selon le modèle\n",
    "axs[0, 1].plot(beta2_values, df_Q1_A[2000], label=\"Q1 error A\")\n",
    "axs[0, 1].plot(beta2_values, df_Q1_B[2000], label=\"Q1 error B\")\n",
    "axs[0, 1].plot(beta2_values, df_medians_A[2000], label=\"median error A\")\n",
    "axs[0, 1].plot(beta2_values, df_medians_B[2000], label=\"median error B\")\n",
    "axs[0, 1].plot(beta2_values, df_Q3_A[2000], label=\"Q3 error A\")\n",
    "axs[0, 1].plot(beta2_values, df_Q3_B[2000], label=\"Q3 error B\")\n",
    "axs[0, 1].set_title(\"Quartiles de l'erreur selon le modèle\")\n",
    "axs[0, 1].grid()\n",
    "axs[0, 1].legend()\n",
    "\n",
    "# Troisième subplot : Quartiles Q1 de l'erreur selon le modèle\n",
    "axs[1, 0].plot(beta2_values, df_Q1_A[2000], label=\"Q1 error A\")\n",
    "axs[1, 0].plot(beta2_values, df_Q1_B[2000], label=\"Q1 error B\")\n",
    "axs[1, 0].set_title(\"Quartiles Q1 de l'erreur selon le modèle\")\n",
    "axs[1, 0].grid()\n",
    "axs[1, 0].legend()\n",
    "\n",
    "# Quatrième subplot : Quartiles Q3 de l'erreur selon le modèle\n",
    "axs[1, 1].plot(beta2_values, df_Q3_A[2000], label=\"Q3 error A\", color = \"purple\")\n",
    "axs[1, 1].plot(beta2_values, df_Q3_B[2000], label=\"Q3 error B\", color = \"brown\")\n",
    "axs[1, 1].set_title(\"Quartiles Q3 de l'erreur selon le modèle\")\n",
    "axs[1, 1].grid()\n",
    "axs[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varying n_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta2_1 = 0.0\n",
    "beta2_2 = 0.08\n",
    "beta2_3 = 0.16\n",
    "\n",
    "df1 = df_empirical_standard_deviations_A.loc[beta2_1]\n",
    "df2 = df_empirical_standard_deviations_A.loc[beta2_2]\n",
    "df3 = df_empirical_standard_deviations_A.loc[beta2_3]\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Premier subplot : Comparaison des valeurs de deviations standard selon beta2\n",
    "axs[0, 0].plot(M, df1, label=\"std error A, beta2 = 0\", color = \"black\")\n",
    "axs[0, 0].plot(M, df2, label=\"std error A beta2 = 0.08\", color = \"yellow\")\n",
    "axs[0, 0].plot(M, df3, label=\"std error A, beta2 = 0.16\", color = \"red\")\n",
    "axs[0, 0].set_title(\"Comparaison des valeurs de deviations standard selon n_test\")\n",
    "axs[0, 0].grid()\n",
    "axs[0, 0].legend()\n",
    "\n",
    "df1 = df_medians_A.loc[beta2_1]\n",
    "df2 = df_medians_A.loc[beta2_2]\n",
    "df3 = df_medians_A.loc[beta2_3]\n",
    "df4 = df_Q1_A.loc[beta2_1]\n",
    "df5 = df_Q1_A.loc[beta2_2]\n",
    "df6 = df_Q1_A.loc[beta2_3]\n",
    "df7 = df_Q3_A.loc[beta2_1]\n",
    "df8 = df_Q3_A.loc[beta2_2]\n",
    "df9 = df_Q3_A.loc[beta2_3]\n",
    "\n",
    "\n",
    "# Deuxième subplot : Quartiles de l'erreur selon le modèle\n",
    "axs[0, 1].plot(M, df4, label=\"Q1 error A, beta = 0\")\n",
    "axs[0, 1].plot(M, df5, label=\"Q1 error A, beta = 0.08\")\n",
    "axs[0, 1].plot(M, df6, label=\"Q1 error A, beta = 1\")\n",
    "axs[0, 1].plot(M, df1, label=\"median error A, beta = 0\")\n",
    "axs[0, 1].plot(M, df2, label=\"median error A, beta = 0.08\")\n",
    "axs[0, 1].plot(M, df3, label=\"median error A, beta = 1\")\n",
    "axs[0, 1].plot(M, df7, label=\"Q3 error A, beta = 0\")\n",
    "axs[0, 1].plot(M, df8, label=\"Q3 error A, beta = 0.08\")\n",
    "axs[0, 1].plot(M, df9, label=\"Q3 error A, beta = 1\")\n",
    "axs[0, 1].set_title(\"Quartiles de l'erreur selon le modèle\")\n",
    "axs[0, 1].grid()\n",
    "axs[0, 1].legend()\n",
    "\n",
    "# Troisième subplot : Quartiles Q1 de l'erreur selon le modèle\n",
    "axs[1, 0].plot(M, df4, label=\"Q1 error A, beta = 0\")\n",
    "axs[1, 0].plot(M, df5, label=\"Q1 error A, beta = 0.08\")\n",
    "axs[1, 0].plot(M, df6, label=\"Q1 error A, beta = 1\")\n",
    "axs[1, 0].set_title(\"Quartiles Q1 de l'erreur selon betae\")\n",
    "axs[1, 0].grid()\n",
    "axs[1, 0].legend()\n",
    "\n",
    "# Quatrième subplot : Quartiles Q3 de l'erreur selon le modèle\n",
    "axs[1, 1].plot(M, df7, label=\"Q3 error A, beta = 0\")\n",
    "axs[1, 1].plot(M, df8, label=\"Q3 error A, beta = 0.08\")\n",
    "axs[1, 1].plot(M, df9, label=\"Q3 error A, beta = 1\")\n",
    "axs[1, 1].set_title(\"Quartiles Q3 de l'erreur selon le modèle\")\n",
    "axs[1, 1].grid()\n",
    "axs[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # pareil pour B\n",
    "\n",
    "beta2_1 = 0.0\n",
    "beta2_2 = 0.08\n",
    "beta2_3 = 0.16\n",
    "\n",
    "df1 = df_empirical_standard_deviations_B.loc[beta2_1]\n",
    "df2 = df_empirical_standard_deviations_B.loc[beta2_2]\n",
    "df3 = df_empirical_standard_deviations_B.loc[beta2_3]\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Premier subplot : Comparaison des valeurs de deviations standard selon beta2\n",
    "axs[0, 0].plot(M, df1, label=\"std error B, beta2 = 0\", color = \"black\")\n",
    "axs[0, 0].plot(M, df2, label=\"std error B beta2 = 0.08\", color = \"yellow\")\n",
    "axs[0, 0].plot(M, df3, label=\"std error B, beta2 = 0.16\", color = \"red\")\n",
    "axs[0, 0].set_title(\"Comparaison des valeurs de deviations standard selon n_test\")\n",
    "axs[0, 0].grid()\n",
    "axs[0, 0].legend()\n",
    "\n",
    "df1 = df_medians_B.loc[beta2_1]\n",
    "df2 = df_medians_B.loc[beta2_2]\n",
    "df3 = df_medians_B.loc[beta2_3]\n",
    "df4 = df_Q1_B.loc[beta2_1]\n",
    "df5 = df_Q1_B.loc[beta2_2]\n",
    "df6 = df_Q1_B.loc[beta2_3]\n",
    "df7 = df_Q3_B.loc[beta2_1]\n",
    "df8 = df_Q3_B.loc[beta2_2]\n",
    "df9 = df_Q3_B.loc[beta2_3]\n",
    "\n",
    "# Deuxième subplot : Quartiles de l'erreur selon le modèle\n",
    "axs[0, 1].plot(M, df4, label=\"Q1 error B, beta = 0\")\n",
    "axs[0, 1].plot(M, df5, label=\"Q1 error B, beta = 0.08\")\n",
    "axs[0, 1].plot(M, df6, label=\"Q1 error B, beta = 1\")\n",
    "axs[0, 1].plot(M, df1, label=\"median error B, beta = 0\")\n",
    "axs[0, 1].plot(M, df2, label=\"median error B, beta = 0.08\")\n",
    "axs[0, 1].plot(M, df3, label=\"median error B, beta = 1\")\n",
    "axs[0, 1].plot(M, df7, label=\"Q3 error B, beta = 0\")\n",
    "axs[0, 1].plot(M, df8, label=\"Q3 error B, beta = 0.08\")\n",
    "axs[0, 1].plot(M, df9, label=\"Q3 error B, beta = 1\")\n",
    "axs[0, 1].set_title(\"Quartiles de l'erreur selon le modèle\")\n",
    "axs[0, 1].grid()\n",
    "axs[0, 1].legend()\n",
    "\n",
    "# Troisième subplot : Quartiles Q1 de l'erreur selon le modèle\n",
    "axs[1, 0].plot(M, df4, label=\"Q1 error B, beta = 0\")\n",
    "axs[1, 0].plot(M, df5, label=\"Q1 error B, beta = 0.08\")\n",
    "axs[1, 0].plot(M, df6, label=\"Q1 error B, beta = 1\")\n",
    "axs[1, 0].set_title(\"Quartiles Q1 de l'erreur selon betae\")\n",
    "axs[1, 0].grid()\n",
    "axs[1, 0].legend()\n",
    "\n",
    "# Quatrième subplot : Quartiles Q3 de l'erreur selon le modèle\n",
    "axs[1, 1].plot(M, df7, label=\"Q3 error B, beta = 0\")\n",
    "axs[1, 1].plot(M, df8, label=\"Q3 error B, beta = 0.08\")\n",
    "axs[1, 1].plot(M, df9, label=\"Q3 error B, beta = 1\")\n",
    "axs[1, 1].set_title(\"Quartiles Q3 de l'erreur selon le modèle\")\n",
    "axs[1, 1].grid()\n",
    "axs[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inferential statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already have the standard error of the mean (according to m and beta2), that gives us a first information of the precisation of mA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Derive formulas (or algorithms) for the standard error (SE) of the mean\n",
    "\n",
    "Methods: \n",
    "- parametric estimates (consider different cases when n is small versus large and when VA is assumed to be Gaussian or not)\n",
    "- bootstrap estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Parametric estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### when n_test is large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_by_sqrt(df):\n",
    "    return df.apply(lambda x: x / np.sqrt(x.name), axis=0)\n",
    "\n",
    "def standard_error_m_large():\n",
    "\n",
    "    (stats_A_all, df_empirical_means_A, df_empirical_standard_deviations_A, df_medians_A, df_Q1_A, df_Q3_A, df_IQR_A, \n",
    "    stats_B_all, df_empirical_means_B, df_empirical_standard_deviations_B, df_medians_B, df_Q1_B, df_Q3_B, df_IQR_B) = create_data()\n",
    "\n",
    "    df_standard_error_A = divide_by_sqrt(df_empirical_standard_deviations_A)\n",
    "    df_standard_error_B = divide_by_sqrt(df_empirical_standard_deviations_B)\n",
    "\n",
    "    return df_standard_error_A, df_standard_error_B\n",
    "\n",
    "\n",
    "df_standard_error_A, df_standard_error_B = standard_error_m_large()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### when n_test is small"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n_test is small and residual is not gaussian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 / Non parametric estimates - Bootstrap estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bootstrap on test sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_error_bootstrap_test():\n",
    "   \n",
    "   n = 150\n",
    "   np.random.seed(42)\n",
    "\n",
    "   M = [150, 200, 500, 1000, 2000]\n",
    "\n",
    "   B = 250\n",
    "\n",
    "   se_bootstrap_A = []\n",
    "   se_bootstrap_B = []\n",
    "\n",
    "   for m in M:\n",
    "   \n",
    "      liste_A = []\n",
    "      liste_B = []\n",
    "      beta1 = 2\n",
    "      epsilon = np.random.normal(0, 1, n + m) \n",
    "      x = np.random.uniform(0, 5, n + m)\n",
    "\n",
    "      x_train = x[:n]\n",
    "      epsilon_train = epsilon[:n]\n",
    "      x_train_quad = np.column_stack((x_train, x_train**2))\n",
    "      bootstrap_indices = np.random.choice(m, size=(B, m), replace=True)\n",
    "    \n",
    "      for beta2 in beta2_values:\n",
    "                \n",
    "            liste_boot_A = []\n",
    "            liste_boot_B = []\n",
    "            y_train = beta1 * x_train + beta2 * x_train**2 + epsilon_train\n",
    "          \n",
    "            for bootstrap_index in bootstrap_indices:\n",
    "         \n",
    "               x_test = x[bootstrap_index]\n",
    "               y_test = beta1 * x_test + beta2 * x_test**2 + epsilon[bootstrap_index]\n",
    "            \n",
    "               model_a = LinearRegression().fit(x_train.reshape(-1, 1), y_train)\n",
    "               y_pred_a = model_a.predict(x_test.reshape(-1, 1))\n",
    "               pa = (y_test - y_pred_a)**2\n",
    "    \n",
    "               \n",
    "               x_test_quad = np.column_stack((x_test, x_test**2))\n",
    "               model_b = LinearRegression().fit(x_train_quad, y_train)\n",
    "               y_pred_b = model_b.predict(x_test_quad)\n",
    "               pb = (y_test - y_pred_b)**2\n",
    "\n",
    "               sea = np.std(pa, ddof=1) / (m**0.5)\n",
    "               seb = np.std(pb, ddof = 1) / (m**0.5)\n",
    "\n",
    "               liste_boot_A.append(sea)\n",
    "               liste_boot_B.append(seb)\n",
    "\n",
    "            liste_A.append(np.mean(liste_boot_A))\n",
    "            liste_B.append(np.mean(liste_boot_B))\n",
    "    \n",
    "      se_bootstrap_A.append(liste_A)\n",
    "      se_bootstrap_B.append(liste_B)\n",
    "\n",
    "   df_se_bootstrap_A = pd.DataFrame(se_bootstrap_A, index=M, columns=beta2_values).transpose()\n",
    "   df_se_bootstrap_B = pd.DataFrame(se_bootstrap_B, index=M, columns=beta2_values).transpose()\n",
    "\n",
    "   return df_se_bootstrap_A, df_se_bootstrap_B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bootstrap on train sample (pas utile pour l'instant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def se_each_bootstrap(n, B, m):\n",
    "\n",
    "    np.random.seed(42)\n",
    "\n",
    "    se_bootstrap_A = []\n",
    "    se_bootstrap_B = []\n",
    "\n",
    "    beta1 = 2\n",
    "    B = 250\n",
    "    epsilon = np.random.normal(0, 1, n + m) \n",
    "    x = np.random.uniform(0, 5, n + m)\n",
    "\n",
    "    x_train = x[:n]\n",
    "    x_test = x[n:n+m]\n",
    "\n",
    "    epsilon_train = epsilon[:n]\n",
    "    epsilon_test = epsilon[n:n+m]\n",
    "\n",
    "    bootstrap_indices = np.random.choice(n, size=(B, n), replace=True) # bootstrapping\n",
    "    \n",
    "    for beta2 in beta2_values:\n",
    "\n",
    "        liste_A = []\n",
    "        liste_B = []\n",
    "\n",
    "        for bootstrap_index in bootstrap_indices:\n",
    "       \n",
    "\n",
    "           x_train = x[bootstrap_index]\n",
    "           y_train = beta1 * x_train + beta2 * x_train**2 + epsilon[bootstrap_index]\n",
    "      \n",
    "           y_train = beta1 * x_train + beta2 * x_train**2 + epsilon_train\n",
    "           y_test = beta1 * x_test + beta2 * x_test**2 + epsilon_test\n",
    "\n",
    "           model_a = LinearRegression().fit(x_train.reshape(-1, 1), y_train)\n",
    "           y_pred_a = model_a.predict(x_test.reshape(-1, 1))\n",
    "           pa = (y_test - y_pred_a)**2\n",
    "\n",
    "           x_train_quad = np.column_stack((x_train, x_train**2))\n",
    "           x_test_quad = np.column_stack((x_test, x_test**2))\n",
    "\n",
    "           model_b = LinearRegression().fit(x_train_quad, y_train)\n",
    "           y_pred_b = model_b.predict(x_test_quad)\n",
    "           pb = (y_test - y_pred_b)**2\n",
    "\n",
    "           sea = np.std(pa, ddof=1) / (n**0.5)\n",
    "           seb = np.std(pb, ddof = 1) / (n**0.5)\n",
    "\n",
    "           liste_A.append(sea)\n",
    "           liste_B.append(seb)\n",
    "\n",
    "        se_bootstrap_A.append(sum(liste_A)/B)\n",
    "        se_bootstrap_B.append(sum(liste_B)/B)\n",
    "    \n",
    "    return se_bootstrap_A, se_bootstrap_B     \n",
    "\n",
    "\n",
    "def standard_error_bootstrap_train():\n",
    "\n",
    "   M = [50, 100, 150, 200, 500, 1000, 2000]\n",
    "\n",
    "   liste_se_bootstrap_A = []\n",
    "   liste_se_bootstrap_B = []\n",
    "\n",
    "   for m in M:\n",
    "\n",
    "      se_bootstrap_A, se_bootstrap_B = se_each_bootstrap(150,250,m)\n",
    "\n",
    "      liste_se_bootstrap_A.append(se_bootstrap_A)\n",
    "      liste_se_bootstrap_B.append(se_bootstrap_B)\n",
    "\n",
    "   df_se_bootstrap_A_train = pd.DataFrame(liste_se_bootstrap_A, index=M, columns=beta2_values).transpose()\n",
    "   df_se_bootstrap_B_train = pd.DataFrame(liste_se_bootstrap_B, index=M, columns=beta2_values).transpose()\n",
    "\n",
    "   return df_se_bootstrap_A_train, df_se_bootstrap_B_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_se_bootstrap_A_test, df_se_bootstrap_B_test = standard_error_bootstrap_test() \n",
    "df_standard_error_A, df_standard_error_B = standard_error_m_large()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Première figure : Comparaison des valeurs d'erreur standard obtenues selon la méthode\n",
    "fig1, ax1 = plt.subplots(figsize=(8, 4))\n",
    "ax1.plot(beta2_values, df_standard_error_A[2000], label=\"Méthode paramétrique\", color=\"blue\")\n",
    "ax1.plot(beta2_values, df_se_bootstrap_A_test[2000], label=\"Méthode bootstrap sur ensemble de test\", color=\"red\")\n",
    "ax1.set_title(\"Erreur standard pour A selon la méthode\")\n",
    "ax1.grid()\n",
    "ax1.legend()\n",
    "\n",
    "# Sauvegarde ou affichage de la première figure\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Deuxième figure : Comparaison des valeurs d'erreur standard selon le bootstrapping\n",
    "fig2, ax2 = plt.subplots(figsize=(8, 4))\n",
    "ax2.plot(beta2_values, df_standard_error_A[2000], label=\"Méthode paramétrique A\", color=\"blue\")\n",
    "ax2.plot(beta2_values, df_se_bootstrap_A_test[2000], label=\"Méthode bootstrap A sur ensemble de test\", color=\"red\")\n",
    "ax2.plot(beta2_values, df_standard_error_B[2000], label=\"Méthode paramétrique B\", color=\"darkblue\")\n",
    "ax2.plot(beta2_values, df_se_bootstrap_B_test[2000], label=\"Méthode bootstrap B sur ensemble de test\", color=\"darkred\")\n",
    "ax2.set_xlabel(\"beta2\")\n",
    "ax2.set_ylabel(\"standard error\")\n",
    "ax2.set_title(\"Erreur standard pour A et B\")\n",
    "ax2.grid()\n",
    "ax2.legend()\n",
    "\n",
    "# Sauvegarde ou affichage de la deuxième figure\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta2_1 = 0.0\n",
    "beta2_2 = 0.08\n",
    "beta2_3 = 0.16\n",
    "\n",
    "df1 = df_standard_error_A.loc[beta2_1]\n",
    "df2 = df_standard_error_A.loc[beta2_2]\n",
    "df3 = df_standard_error_A.loc[beta2_3]\n",
    "df4 = df_se_bootstrap_A_test.loc[beta2_1]\n",
    "df5 = df_se_bootstrap_A_test.loc[beta2_2]\n",
    "df6 = df_se_bootstrap_A_test.loc[beta2_3]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df1.index, df1.values, marker='o', label = \"erreur standard parametrique selon n_test pour beta2 = \"  f'{beta2_1}', color = \"lightblue\")\n",
    "plt.plot(df4.index, df4.values, marker='o', label = \"erreur standard bootstrap selon n_test pour beta2 = \" f'{beta2_1}', color = \"darkblue\")\n",
    "plt.plot(df2.index, df2.values, marker='o', label = \"erreur standard parametrique selon n_test pour beta2 = \" f'{beta2_2}', color = \"red\")\n",
    "plt.plot(df5.index, df5.values, marker='o', label = \"erreur standard bootstrap selon n_test pour beta2 = \" f'{beta2_2}', color = \"darkred\")\n",
    "plt.plot(df3.index, df3.values, marker='o', label = \"erreur standard parametrique selon n_test pour beta2 = \" f'{beta2_3}', color = \"lightgreen\")\n",
    "plt.plot(df6.index, df6.values, marker='o', label = \"erreur standard bootstrap selon n_test pour beta2 = \" f'{beta2_3}', color = \"darkgreen\")\n",
    "plt.xlabel(\"n_test\")\n",
    "plt.title(f'erreur standard du modèle linéaire pour beta2 = {beta2_1}, {beta2_2}, {beta2_3}')\n",
    "plt.ylabel('Erreur standard')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subsets of training sets (varying k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_error_varying_test_derived():\n",
    "\n",
    "    liste_subsets = [150,200,500,1000,2000]\n",
    "\n",
    "    n = 150\n",
    "    m = 2000\n",
    "    standard_errors_A = []\n",
    "    standard_errors_B = []\n",
    "    np.random.seed(42)\n",
    "    beta1 = 2\n",
    "    epsilon = np.random.normal(0, 1, n + m) \n",
    "    x = np.random.uniform(0, 5, n + m)\n",
    "\n",
    "    for k in liste_subsets:\n",
    "\n",
    "      x_train = x[:n]\n",
    "      x_test = x[n:n+k]\n",
    "\n",
    "      epsilon_train = epsilon[:n]\n",
    "      epsilon_test = epsilon[n:n+k]\n",
    "\n",
    "      liste_A = []\n",
    "      liste_B = []\n",
    "    \n",
    "      for beta2 in beta2_values:\n",
    "            \n",
    "          y_train = beta1 * x_train + beta2 * x_train**2 + epsilon_train\n",
    "          y_test = beta1 * x_test + beta2 * x_test**2 + epsilon_test\n",
    "\n",
    "        # Linear Model : A\n",
    "          model_a = LinearRegression().fit(x_train.reshape(-1, 1), y_train)\n",
    "          y_pred_a = model_a.predict(x_test.reshape(-1, 1))\n",
    "          pa = (y_test - y_pred_a)**2\n",
    "    \n",
    "        # Quadratic Model : B\n",
    "          x_train_quad = np.column_stack((x_train, x_train**2))\n",
    "          x_test_quad = np.column_stack((x_test, x_test**2))\n",
    "            \n",
    "          model_b = LinearRegression().fit(x_train_quad, y_train)\n",
    "          y_pred_b = model_b.predict(x_test_quad)\n",
    "          pb = (y_test - y_pred_b)**2\n",
    "\n",
    "          se_a = np.std(pa, ddof=1)/(k**0.5)\n",
    "          se_b = np.std(pb, ddof = 1)/(k**0.5)\n",
    "\n",
    "          liste_A.append(se_a)\n",
    "          liste_B.append(se_b)\n",
    "\n",
    "      standard_errors_A.append(liste_A)\n",
    "      standard_errors_B.append(liste_B)\n",
    "\n",
    "    df_se_varying_k_A = pd.DataFrame(standard_errors_A, index=liste_subsets, columns=beta2_values).transpose()\n",
    "    df_se_varying_k_B = pd.DataFrame(standard_errors_B, index=liste_subsets, columns=beta2_values).transpose()\n",
    "\n",
    "    return df_se_varying_k_A, df_se_varying_k_B\n",
    "\n",
    "\n",
    "df_se_varying_k_A, df_se_varying_k_B = standard_error_varying_test_derived()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_subsets = [150,200,500,1000,2000]\n",
    "beta2_1 = 0.0\n",
    "beta2_2 = 0.08\n",
    "beta2_3 = 0.16\n",
    "\n",
    "df1 = df_se_varying_k_A.loc[beta2_1]\n",
    "df2 = df_se_varying_k_A.loc[beta2_2]\n",
    "df3 = df_se_varying_k_A.loc[beta2_3]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df1.index, df1.values, marker='o', label = \"evolution de l'erreur standard selon k pour beta2 = \"  f'{beta2_1}', color = \"lightblue\")\n",
    "plt.plot(df2.index, df2.values, marker='o', label = \"evolution de l'erreur standard selon k pour beta2 = \" f'{beta2_2}', color = \"red\")\n",
    "plt.plot(df3.index, df3.values, marker='o', label = \"evolution de l'erreur standard selon k pour beta2 = \" f'{beta2_3}', color =\"lightgreen\")\n",
    "plt.title(f'Evolution de l\\'erreur standard du modèle linéaire pour beta2 = {beta2_1}, {beta2_2}, {beta2_3}')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Erreur standard')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Varying k + Bootstrapped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrapped on train ensemble (pas utile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def se_each_bootstrap_varying(k):\n",
    "\n",
    "    n = 150\n",
    "    np.random.seed(42)\n",
    "    m = 2000\n",
    "\n",
    "    se_bootstrap_A = []\n",
    "    se_bootstrap_B = []\n",
    "\n",
    "    beta1 = 2\n",
    "    B = 250\n",
    "    epsilon = np.random.normal(0, 1, n + m) \n",
    "    x = np.random.uniform(0, 5, n + m)\n",
    "\n",
    "    x_train = x[:n]\n",
    "    x_test = x[n:n+k]\n",
    "\n",
    "    epsilon_train = epsilon[:n]\n",
    "    epsilon_test = epsilon[n:n+k]\n",
    "\n",
    "    bootstrap_indices = np.random.choice(n, size=(B, n), replace=True) # bootstrapping\n",
    "    \n",
    "    for beta2 in beta2_values:\n",
    "\n",
    "        liste_A = []\n",
    "        liste_B = []\n",
    "\n",
    "        for bootstrap_index in bootstrap_indices:\n",
    "       \n",
    "\n",
    "           x_train = x[bootstrap_index]\n",
    "           y_train = beta1 * x_train + beta2 * x_train**2 + epsilon[bootstrap_index]\n",
    "      \n",
    "           y_train = beta1 * x_train + beta2 * x_train**2 + epsilon_train\n",
    "           y_test = beta1 * x_test + beta2 * x_test**2 + epsilon_test\n",
    "\n",
    "           model_a = LinearRegression().fit(x_train.reshape(-1, 1), y_train)\n",
    "           y_pred_a = model_a.predict(x_test.reshape(-1, 1))\n",
    "           pa = (y_test - y_pred_a)**2\n",
    "\n",
    "           x_train_quad = np.column_stack((x_train, x_train**2))\n",
    "           x_test_quad = np.column_stack((x_test, x_test**2))\n",
    "\n",
    "           model_b = LinearRegression().fit(x_train_quad, y_train)\n",
    "           y_pred_b = model_b.predict(x_test_quad)\n",
    "           pb = (y_test - y_pred_b)**2\n",
    "\n",
    "           sea = np.std(pa, ddof=1) / (n**0.5)\n",
    "           seb = np.std(pb, ddof = 1) / (n**0.5)\n",
    "\n",
    "           liste_A.append(sea)\n",
    "           liste_B.append(seb)\n",
    "\n",
    "        se_bootstrap_A.append(sum(liste_A)/B)\n",
    "        se_bootstrap_B.append(sum(liste_B)/B)\n",
    "    \n",
    "    return se_bootstrap_A, se_bootstrap_B     \n",
    "\n",
    "\n",
    "def standard_error_varying_test_bootstrapped_train():\n",
    "\n",
    "   K = [50,100,150,200,500,1000,2000]\n",
    "\n",
    "   liste_se_bootstrap_A = []\n",
    "   liste_se_bootstrap_B = []\n",
    "\n",
    "   for k in K:\n",
    "\n",
    "      se_bootstrap_A, se_bootstrap_B = se_each_bootstrap_varying(k)\n",
    "\n",
    "      liste_se_bootstrap_A.append(se_bootstrap_A)\n",
    "      liste_se_bootstrap_B.append(se_bootstrap_B)\n",
    "\n",
    "   df_se_varying_bootstrap_A_train = pd.DataFrame(liste_se_bootstrap_A, index=K, columns=beta2_values).transpose()\n",
    "   df_se_varying_bootstrap_B_train = pd.DataFrame(liste_se_bootstrap_B, index=K, columns=beta2_values).transpose()\n",
    "\n",
    "   return df_se_varying_bootstrap_A_train, df_se_varying_bootstrap_B_train\n",
    "\n",
    "df_se_varying_bootstrap_A_train, df_se_varying_bootstrap_B_train = standard_error_varying_test_bootstrapped_train()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrapped on test ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def standard_error_varying_bootstrapped_test():\n",
    "   \n",
    "   n = 150\n",
    "   np.random.seed(42)\n",
    "   m = 2000\n",
    "\n",
    "   B = 250\n",
    "\n",
    "   K = [150,200,500,1000,2000]\n",
    "\n",
    "   se_bootstrap_A = []\n",
    "   se_bootstrap_B = []\n",
    "\n",
    "   for k in K:\n",
    "   \n",
    "      liste_A = []\n",
    "      liste_B = []\n",
    "      beta1 = 2\n",
    "      epsilon = np.random.normal(0, 1, n + m) \n",
    "      x = np.random.uniform(0, 5, n + m)\n",
    "\n",
    "      x_train = x[:n]\n",
    "      x_test = x[n:n+k]\n",
    "\n",
    "      epsilon_train = epsilon[:n]\n",
    "      epsilon_test = epsilon[n:n+k]\n",
    "\n",
    "      x_train_quad = np.column_stack((x_train, x_train**2))\n",
    "\n",
    "      bootstrap_indices = np.random.choice(k, size=(B, k), replace=True)\n",
    "    \n",
    "      for beta2 in beta2_values:\n",
    "                \n",
    "            liste_boot_A = []\n",
    "            liste_boot_B = []\n",
    "            y_train = beta1 * x_train + beta2 * x_train**2 + epsilon_train\n",
    "          \n",
    "            for bootstrap_index in bootstrap_indices:\n",
    "         \n",
    "               \n",
    "               x_test = x[bootstrap_index]\n",
    "               y_test = beta1 * x_test + beta2 * x_test**2 + epsilon[bootstrap_index]\n",
    "            \n",
    "               model_a = LinearRegression().fit(x_train.reshape(-1, 1), y_train)\n",
    "               y_pred_a = model_a.predict(x_test.reshape(-1, 1))\n",
    "               pa = (y_test - y_pred_a)**2\n",
    "    \n",
    "               \n",
    "               x_test_quad = np.column_stack((x_test, x_test**2))\n",
    "               model_b = LinearRegression().fit(x_train_quad, y_train)\n",
    "               y_pred_b = model_b.predict(x_test_quad)\n",
    "               pb = (y_test - y_pred_b)**2\n",
    "\n",
    "               sea = np.std(pa, ddof=1) / (k**0.5)\n",
    "               seb = np.std(pb, ddof = 1) / (k**0.5)\n",
    "\n",
    "               liste_boot_A.append(sea)\n",
    "               liste_boot_B.append(seb)\n",
    "\n",
    "            liste_A.append(np.mean(liste_boot_A))\n",
    "            liste_B.append(np.mean(liste_boot_B))\n",
    "    \n",
    "      se_bootstrap_A.append(liste_A)\n",
    "      se_bootstrap_B.append(liste_B)\n",
    "\n",
    "   df_se_bootstrap_A = pd.DataFrame(se_bootstrap_A, index=K, columns=beta2_values).transpose()\n",
    "   df_se_bootstrap_B = pd.DataFrame(se_bootstrap_B, index=K, columns=beta2_values).transpose()\n",
    "\n",
    "   return df_se_bootstrap_A, df_se_bootstrap_B\n",
    "\n",
    "df_se_varying_bootstrap_A_test, df_se_varying_bootstrap_B_test = standard_error_varying_bootstrapped_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison between bootstrapped method and derived method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df_se_varying_bootstrap_A_test.loc[beta2_1]\n",
    "df2 = df_se_varying_bootstrap_A_test.loc[beta2_2]\n",
    "df3 = df_se_varying_bootstrap_A_test.loc[beta2_3]\n",
    "df4 = df_se_varying_k_A.loc[beta2_1]\n",
    "df5 = df_se_varying_k_A.loc[beta2_2]\n",
    "df6 = df_se_varying_k_A.loc[beta2_3]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df1.index, df1.values, marker='o', label = \"Bootstrap pour beta2 = \"  f'{beta2_1}', color = \"darkblue\")\n",
    "plt.plot(df1.index, df4.values, marker='o', label = \"Derived pour beta2 = \"  f'{beta2_1}', color = \"lightblue\")\n",
    "plt.plot(df2.index, df2.values, marker='o', label = \"Bootstrap pour beta2 = \" f'{beta2_2}', color = \"darkred\")\n",
    "plt.plot(df2.index, df5.values, marker='o', label = \"Derived pour beta2 = \" f'{beta2_2}', color = \"#FF6666\")\n",
    "plt.plot(df3.index, df3.values, marker='o', label = \"Bootstrap pour beta2 = \" f'{beta2_3}', color = \"darkgreen\")\n",
    "plt.plot(df3.index, df6.values, marker='o', label = \"Derived pour beta2 = \" f'{beta2_3}', color = \"lightgreen\")\n",
    "plt.title('Evolution de l\\'erreur standard du modèle varying k bootstrapped')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Erreur standard')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison between varying test samples and varying test size (corresponds when k = m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"Comparison of varying method vs reducing test size\")\n",
    "plt.plot(beta2_values, df_se_bootstrap_A_test[1000], label = \"m = 250, smaller size test sample\")\n",
    "plt.plot(beta2_values, df_se_varying_bootstrap_A_test[1000], label = \"m = 2000, k = 250, k < m method\")\n",
    "plt.plot()\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison for a given value \n",
    "df4 = df_se_varying_k_A.loc[beta2_1]\n",
    "df5 = df_se_varying_k_A.loc[beta2_2]\n",
    "df6 = df_se_varying_k_A.loc[beta2_3]\n",
    "dff1 = df_standard_error_A.loc[beta2_1]\n",
    "dff2 = df_standard_error_A.loc[beta2_2]\n",
    "dff3 = df_standard_error_A.loc[beta2_3]\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Comparison of standard errors derived method\")\n",
    "\n",
    "\n",
    "plt.plot(df4.index, df1.values, marker='o', label = \"Varying method k < m pour beta2 = \" f'{beta2_1}', color = \"darkblue\") # confondue\n",
    "plt.plot(dff1.index, dff1.values, marker='o', label = \"m = k pour beta2 = \" f'{beta2_1}', color = \"lightblue\")\n",
    "plt.plot(df5.index, df2.values, marker='o', label = \"Varying method k < m pour beta2 = \" f'{beta2_2}', color = \"darkred\")\n",
    "plt.plot(dff2.index, dff2.values, marker='o', label = \"m = k pour beta2 = \" f'{beta2_2}', color = \"red\")\n",
    "plt.plot(df6.index, df3.values, marker='o', label = \"Varying method k < m pour beta2 = \" f'{beta2_3}', color = \"darkgreen\")\n",
    "plt.plot(dff3.index, dff3.values, marker='o', label = \"m = k pour beta2 = \" f'{beta2_3}', color = \"lightgreen\")\n",
    "\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison for a given value \n",
    "df1 = df_se_varying_bootstrap_A_test.loc[beta2_1]\n",
    "dff1 = df_se_bootstrap_A_test.loc[beta2_1]\n",
    "df2 = df_se_varying_bootstrap_A_test.loc[beta2_2]\n",
    "dff2 = df_se_bootstrap_A_test.loc[beta2_2]\n",
    "df3 = df_se_varying_bootstrap_A_test.loc[beta2_3]\n",
    "dff3 = df_se_bootstrap_A_test.loc[beta2_3]\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Comparison of standard errors bootstrap test\")\n",
    "\n",
    "\n",
    "plt.plot(df1.index, df1.values, marker='o', label = \"Varying method k < m pour beta2 = \" f'{beta2_1}', color = \"darkblue\") # confondue\n",
    "plt.plot(dff1.index, dff1.values, marker='o', label = \"m = k pour beta2 = \" f'{beta2_1}', color = \"blue\")\n",
    "plt.plot(df2.index, df2.values, marker='o', label = \"Varying method k < m pour beta2 = \" f'{beta2_2}', color = \"darkred\")\n",
    "plt.plot(dff2.index, dff2.values, marker='o', label = \"m = k pour beta2 = \" f'{beta2_2}', color = \"red\")\n",
    "plt.plot(df3.index, df3.values, marker='o', label = \"Varying method k < m pour beta2 = \" f'{beta2_3}', color = \"darkgreen\")\n",
    "plt.plot(dff3.index, dff3.values, marker='o', label = \"m = k pour beta2 = \" f'{beta2_3}', color = \"lightgreen\")\n",
    "\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confidence interval of the mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parametric method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_interval(lower, upper):\n",
    "      return pd.Interval(left=lower, right=upper, closed='both')\n",
    "\n",
    "\n",
    "def confidence_interval_mean():\n",
    "     \n",
    "     \n",
    "   (stats_A_all, df_empirical_means_A, df_empirical_standard_deviations_A, df_medians_A, df_Q1_A, df_Q3_A, df_IQR_A, \n",
    "     stats_B_all, df_empirical_means_B, df_empirical_standard_deviations_B, df_medians_B, df_Q1_B, df_Q3_B, df_IQR_B) = create_data()\n",
    "    \n",
    "   df_standard_error_A, df_standard_error_B = standard_error_m_large()\n",
    "\n",
    "   t_critical = 1.96\n",
    "   CI_lower_A = df_empirical_means_A - t_critical * df_standard_error_A\n",
    "   CI_lower_B = df_empirical_means_B - t_critical * df_standard_error_B\n",
    "   CI_upper_A = df_empirical_means_A + t_critical * df_standard_error_A\n",
    "   CI_upper_B = df_empirical_means_B + t_critical * df_standard_error_B\n",
    "     \n",
    "   confidence_intervals_A = pd.DataFrame(index=CI_lower_A.index, columns=CI_lower_A.columns)\n",
    "   confidence_intervals_B = pd.DataFrame(index=CI_lower_B.index, columns=CI_lower_B.columns)\n",
    "\n",
    "   for col in CI_lower_A.columns:\n",
    "    confidence_intervals_A[col] = CI_lower_A[col].combine(CI_upper_A[col], create_interval)\n",
    "\n",
    "   for col in CI_lower_B.columns:\n",
    "    confidence_intervals_B[col] = CI_lower_B[col].combine(CI_upper_B[col], create_interval)\n",
    "\n",
    "   return confidence_intervals_A, confidence_intervals_B\n",
    "\n",
    "confidence_intervals_A, confidence_intervals_B = confidence_interval_mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_each_bootstrap(n, B, m):\n",
    "\n",
    "    np.random.seed(42)\n",
    "\n",
    "    ci_bootstrap_A = []\n",
    "    ci_bootstrap_B = []\n",
    "\n",
    "    beta1 = 2\n",
    "    B = 250\n",
    "    alpha = 0.05\n",
    "    epsilon = np.random.normal(0, 1, n + m) \n",
    "    x = np.random.uniform(0, 5, n + m)\n",
    "\n",
    "    x_train = x[:n]\n",
    "    x_test = x[n:n+m]\n",
    "\n",
    "    epsilon_train = epsilon[:n]\n",
    "    epsilon_test = epsilon[n:n+m]\n",
    "\n",
    "    bootstrap_indices = np.random.choice(m, size=(B, m), replace=True) # bootstrapping\n",
    "    \n",
    "    for beta2 in beta2_values:\n",
    "\n",
    "        moy_boot_A = []\n",
    "        moy_boot_B = []\n",
    "        y_train = beta1 * x_train + beta2 * x_train**2 + epsilon_train\n",
    "\n",
    "        for bootstrap_index in bootstrap_indices:\n",
    "       \n",
    "           x_test = x[bootstrap_index]\n",
    "           y_test = beta1 * x_test + beta2 * x_test**2 + epsilon_test\n",
    "\n",
    "           model_a = LinearRegression().fit(x_train.reshape(-1, 1), y_train)\n",
    "           y_pred_a = model_a.predict(x_test.reshape(-1, 1))\n",
    "           pa = (y_test - y_pred_a)**2\n",
    "\n",
    "           x_train_quad = np.column_stack((x_train, x_train**2))\n",
    "           x_test_quad = np.column_stack((x_test, x_test**2))\n",
    "\n",
    "           model_b = LinearRegression().fit(x_train_quad, y_train)\n",
    "           y_pred_b = model_b.predict(x_test_quad)\n",
    "           pb = (y_test - y_pred_b)**2\n",
    "    \n",
    "           moy_boot_A.append(np.mean(pa))\n",
    "           moy_boot_B.append(np.mean(pb))\n",
    "\n",
    "        lower_A = np.percentile(moy_boot_A, 100 * (alpha / 2))\n",
    "        upper_A = np.percentile(moy_boot_A, 100 * (1 - alpha / 2))\n",
    "        lower_B = np.percentile(moy_boot_B, 100 * (alpha / 2))\n",
    "        upper_B = np.percentile(moy_boot_B, 100 * (1 - alpha / 2))\n",
    "\n",
    "        ci_bootstrap_A.append(pd.Interval(left=lower_A, right=upper_A, closed='both'))\n",
    "        ci_bootstrap_B.append(pd.Interval(left=lower_B, right=upper_B, closed='both'))\n",
    "    \n",
    "    return ci_bootstrap_A, ci_bootstrap_B     \n",
    "\n",
    "def confidence_interval_bootstrap():\n",
    "\n",
    "   M = [150, 200, 500, 1000, 2000]\n",
    "\n",
    "   liste_ci_bootstrap_A = []\n",
    "   liste_ci_bootstrap_B = []\n",
    "\n",
    "   for m in M:\n",
    "\n",
    "      ci_bootstrap_A, ci_bootstrap_B = conf_each_bootstrap(150,250,m)\n",
    "\n",
    "      liste_ci_bootstrap_A.append(ci_bootstrap_A)\n",
    "      liste_ci_bootstrap_B.append(ci_bootstrap_B)\n",
    "\n",
    "   df_ci_bootstrap_A = pd.DataFrame(liste_ci_bootstrap_A, index=M, columns=beta2_values).transpose()\n",
    "   df_ci_bootstrap_B = pd.DataFrame(liste_ci_bootstrap_B, index=M, columns=beta2_values).transpose()\n",
    "\n",
    "   return df_ci_bootstrap_A, df_ci_bootstrap_B\n",
    "\n",
    "df_ci_bootstrap_A, df_ci_bootstrap_B = confidence_interval_bootstrap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graphs_confidence_intervals_A():\n",
    "\n",
    "    confidence_intervals_A, confidence_intervals_B = confidence_interval_mean()\n",
    "    df_ci_bootstrap_A, df_ci_bootstrap_B = confidence_interval_bootstrap()\n",
    "    df1 = df_ci_bootstrap_A.loc[beta2_1]\n",
    "    df2 = df_ci_bootstrap_A.loc[beta2_2]\n",
    "    df3 = df_ci_bootstrap_A.loc[beta2_3]\n",
    "    df4 = confidence_intervals_A.loc[beta2_1]\n",
    "    df5 = confidence_intervals_A.loc[beta2_2]\n",
    "    df6 = confidence_intervals_A.loc[beta2_3]\n",
    "\n",
    "    y_values = [\n",
    "        [1.053598913427204, 1.068366766251598],\n",
    "        [0.9292457054668812, 0.9833748402327965],\n",
    "        [0.9962042595799346, 0.9983462990635036],\n",
    "        [0.9886493946391038, 0.9893143185309117],\n",
    "        [0.9962861220803533, 1.0083750605773054]\n",
    "    ]\n",
    "    table_1 = [\n",
    "        [1.0390093295288756, 1.1466015653801718],\n",
    "        [0.9361297529233542, 1.0229671747404647],\n",
    "        [0.9962322602731206, 1.0516027736303146],\n",
    "        [0.9993335114928288, 1.0355278335905707],\n",
    "        [1.010542001326182, 1.0375079528724687]\n",
    "    ]\n",
    "    table_2 = [\n",
    "        [1.0688079662229757, 1.2833752084872891],\n",
    "        [0.9769788312057663, 1.1388984494706547],\n",
    "        [1.0437656863998515, 1.1563363689670394],\n",
    "        [1.055111355556954, 1.1263943592363688],\n",
    "        [1.0669256435790109, 1.116089657564828]\n",
    "    ]\n",
    "    table_3 = [\n",
    "        [0.7664312269412913, 1.369792424998975],\n",
    "        [0.7155858600787521, 1.176581810309871],\n",
    "        [0.865445418757162, 1.1309658094405943],\n",
    "        [0.8999263681837879, 1.0781280797392638],\n",
    "        [0.9376255326483326, 1.0652662396334127]\n",
    "    ]\n",
    "    table_4 = [\n",
    "        [0.7877581893125734, 1.3685939092694972],\n",
    "        [0.7190325401994103, 1.178493327109527],\n",
    "        [0.8743764346979922, 1.1442302502484871],\n",
    "        [0.9386904011625568, 1.126800882686477],\n",
    "        [0.9554520642623406, 1.0863686009438385]\n",
    "    ]\n",
    "    table_5 = [\n",
    "        [0.8458032216182627, 1.4184482427628125],\n",
    "        [0.7543543857512403, 1.2265836665003071],\n",
    "        [0.9273727708382743, 1.2132884768753862],\n",
    "        [1.0193129286747022, 1.2254957368259625],\n",
    "        [1.015251783409371, 1.1554206717907454]\n",
    "    ]\n",
    "\n",
    "    x = [150, 200, 500, 1000, 2000]\n",
    "    y1, y2 = zip(*y_values)\n",
    "    y3, y4 = zip(*table_1)\n",
    "    y5, y6 = zip(*table_2)\n",
    "    y7, y8 = zip(*table_3)\n",
    "    y9, y10 = zip(*table_4)\n",
    "    y11, y12 = zip(*table_5)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(x, y1, label='lower bound beta2 = 0', marker='o', color=\"lightblue\")\n",
    "    plt.plot(x, y2, label='upper bound beta2 = 0', marker='o', color=\"darkblue\")\n",
    "    plt.plot(x, y3, label='lower bound beta2 = 0.06', marker='o', color=\"brown\")\n",
    "    plt.plot(x, y4, label='upper bound beta2 = 0.08', marker='o', color=\"darkred\")\n",
    "    plt.plot(x, y5, label='lower bound beta2 = 0.16', marker='o', color=\"lightgreen\")\n",
    "    plt.plot(x, y6, label='upper bound beta2 = 0.16', marker='o', color=\"darkgreen\")\n",
    "\n",
    "    plt.fill_between(x, y1, y2, color='blue', alpha=0.3, label='Interval for beta2 = 0')\n",
    "    plt.fill_between(x, y3, y4, color='red', alpha=0.3, label='Interval for beta2 = 0.08')\n",
    "    plt.fill_between(x, y5, y6, color='yellow', alpha=0.3, label='Interval for beta2 = 0.16')\n",
    "    plt.xlabel('Values of n_test')\n",
    "    plt.ylabel('Interval confidence of the mean A')\n",
    "    plt.title('Boostrapped confidence intervals of mean A as a function of N_test')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(x, y7, label='lower bound beta2 = 0', color=\"lightblue\")\n",
    "    plt.plot(x, y8, label='upper bound beta2 = 0', color=\"darkblue\")\n",
    "    plt.plot(x, y9, label='lower bound beta2 = 0.06', color=\"brown\")\n",
    "    plt.plot(x, y10, label='upper bound beta2 = 0.08', color=\"darkred\")\n",
    "    plt.plot(x, y11, label='lower bound beta2 = 0.16', color=\"lightgreen\")\n",
    "    plt.plot(x, y12, label='upper bound beta2 = 0.16', color=\"darkgreen\")\n",
    "\n",
    "    plt.fill_between(x, y7, y8, color='blue', alpha=0.5, label='Interval for beta2 = 0')\n",
    "    plt.fill_between(x, y9, y10, color='red', alpha=0.5, label='Interval for beta2 = 0.08')\n",
    "    plt.fill_between(x, y11, y12, color='yellow', alpha=0.5, label='Interval for beta2 = 0.16')\n",
    "    plt.xlabel('Values of n_test')\n",
    "    plt.ylabel('Interval confidence of the mean of A')\n",
    "    plt.title('Derived confidence intervals of mean A as a function of N_test')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "graphs_confidence_intervals_A()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graphs_confidence_intervals_B():\n",
    "    confidence_intervals_A, confidence_intervals_B = confidence_interval_mean()\n",
    "    df_ci_bootstrap_A, df_ci_bootstrap_B = confidence_interval_bootstrap()\n",
    "    \n",
    "    df1 = df_ci_bootstrap_B.loc[beta2_1]\n",
    "    df2 = df_ci_bootstrap_B.loc[beta2_2]\n",
    "    df3 = df_ci_bootstrap_B.loc[beta2_3]\n",
    "    df4 = confidence_intervals_B.loc[beta2_1]\n",
    "    df5 = confidence_intervals_B.loc[beta2_2]\n",
    "    df6 = confidence_intervals_B.loc[beta2_3]\n",
    "\n",
    "    y_values = [\n",
    "    [1.053808267884721, 1.0688762122899125],\n",
    "    [0.9292976160288866, 1.0083354785602343],\n",
    "    [0.9937484365303293, 1.0004365255248169],\n",
    "    [0.9857804263439052, 0.9914301642805049],\n",
    "    [1.01907270447993, 1.0464838908607992]\n",
    "]\n",
    "\n",
    "    table_1 = [\n",
    "    [1.0531808267884717, 1.0688762122898913],\n",
    "    [0.9292976160288865, 1.0083354785602343],\n",
    "    [0.9937484365303297, 1.000436525524817],\n",
    "    [0.9857804263439051, 0.9914301642805046],\n",
    "    [1.019072704479927, 1.046483890860799]\n",
    "]\n",
    "\n",
    "    table_2 = [\n",
    "    [1.0531808267884717, 1.0688762122899127],\n",
    "    [0.929297616028887, 1.008335478560235],\n",
    "    [0.9937484365303295, 1.0004365255248169],\n",
    "    [0.985780426343905, 0.9914301642805047],\n",
    "    [1.01907270447993, 1.0464838908607992]\n",
    "]\n",
    "\n",
    "    table_3 = [\n",
    "    [0.7666644036644075, 1.368281244228714],\n",
    "    [0.7352823535856203, 1.2069875315994218],\n",
    "    [0.8670675727868207, 1.132846997115552],\n",
    "    [0.897680106912762, 1.0750969043388854],\n",
    "    [0.9672562473475386, 1.0983035624868063]\n",
    "]\n",
    "\n",
    "    table_4 = [\n",
    "    [0.7666644036644075, 1.3682812442287144],\n",
    "    [0.7352823535856203, 1.2069875315994216],\n",
    "    [0.8670675727868219, 1.132846997115563],\n",
    "    [0.8976801069127621, 1.0750969043388854],\n",
    "    [0.9672562473475383, 1.098303562486806]\n",
    "]\n",
    "\n",
    "    table_5 = [\n",
    "    [0.7666644036644047, 1.3682812442287136],\n",
    "    [0.7352823535856208, 1.2069875315994225],\n",
    "    [0.8670675727868209, 1.132846997115554],\n",
    "    [0.8976801069127622, 1.0750969043388854],\n",
    "    [0.9672562473475388, 1.0983035624868065]\n",
    "]\n",
    "\n",
    "    x = [150, 200, 500, 1000, 2000]\n",
    "    y1, y2 = zip(*y_values)\n",
    "    y3, y4 = zip(*table_1)\n",
    "    y5, y6 = zip(*table_2)\n",
    "    y7, y8 = zip(*table_3)\n",
    "    y9, y10 = zip(*table_4)\n",
    "    y11, y12 = zip(*table_5)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(x, y1, label='lower bound beta2 = 0', marker='o', color=\"lightblue\")\n",
    "    plt.plot(x, y2, label='upper bound beta2 = 0', marker='o', color=\"darkblue\")\n",
    "    plt.plot(x, y3, label='lower bound beta2 = 0.06', marker='o', color=\"brown\")\n",
    "    plt.plot(x, y4, label='upper bound beta2 = 0.08', marker='o', color=\"darkred\")\n",
    "    plt.plot(x, y5, label='lower bound beta2 = 0.16', marker='o', color=\"lightgreen\")\n",
    "    plt.plot(x, y6, label='upper bound beta2 = 0.16', marker='o', color=\"darkgreen\")\n",
    "\n",
    "    plt.fill_between(x, y1, y2, color='blue', alpha=0.3, label='Interval for beta2 = 0')\n",
    "    plt.fill_between(x, y3, y4, color='red', alpha=0.3, label='Interval for beta2 = 0.08')\n",
    "    plt.fill_between(x, y5, y6, color='yellow', alpha=0.3, label='Interval for beta2 = 0.16')\n",
    "    plt.xlabel('Values of n_test')\n",
    "    plt.ylabel('Interval confidence of the mean for B')\n",
    "    plt.title('Boostrapped confidence intervals of mean B as a function of N_test')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(x, y7, label='lower bound beta2 = 0', color=\"lightblue\")\n",
    "    plt.plot(x, y8, label='upper bound beta2 = 0', color=\"darkblue\")\n",
    "    plt.plot(x, y9, label='lower bound beta2 = 0.06', color=\"brown\")\n",
    "    plt.plot(x, y10, label='upper bound beta2 = 0.08', color=\"darkred\")\n",
    "    plt.plot(x, y11, label='lower bound beta2 = 0.16', color=\"lightgreen\")\n",
    "    plt.plot(x, y12, label='upper bound beta2 = 0.16', color=\"darkgreen\")\n",
    "\n",
    "    plt.fill_between(x, y7, y8, color='blue', alpha=0.5, label='Interval for beta2 = 0')\n",
    "    plt.fill_between(x, y9, y10, color='red', alpha=0.5, label='Interval for beta2 = 0.08')\n",
    "    plt.fill_between(x, y11, y12, color='yellow', alpha=0.5, label='Interval for beta2 = 0.16')\n",
    "    plt.xlabel('Values of n_test')\n",
    "    plt.ylabel('Interval confidence of the mean for B')\n",
    "    plt.title('Derived confidence intervals of mean B as a function of N_test')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "graphs_confidence_intervals_B()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferential statistics : is a model better than the other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confidence interval for the difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derived method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descriptive_statistics_diff():\n",
    "    \n",
    "    n = 150\n",
    "\n",
    "    M = [150, 200, 500, 1000, 2000]\n",
    "\n",
    "    empirical_means_diff = []\n",
    "    standard_deviations_diff = []\n",
    "\n",
    "    for m in M:\n",
    "\n",
    "      np.random.seed(42)\n",
    "      beta1 = 2\n",
    "      beta2_values_bis = [0.2, 0.3, 0.4, 0.5, 1]\n",
    "      epsilon = np.random.normal(0, 1, n + m) \n",
    "      x = np.random.uniform(0, 5, n + m)\n",
    "\n",
    "      x_train = x[:n]\n",
    "      x_test = x[n:n+m]\n",
    "\n",
    "      epsilon_train = epsilon[:n]\n",
    "      epsilon_test = epsilon[n:n+m]\n",
    "\n",
    "      means = []\n",
    "      stds =[]\n",
    "\n",
    "    \n",
    "      for beta2 in beta2_values:\n",
    "            \n",
    "          y_train = beta1 * x_train + beta2 * x_train**2 + epsilon_train\n",
    "          y_test = beta1 * x_test + beta2 * x_test**2 + epsilon_test\n",
    "\n",
    "        # Linear Model : A\n",
    "          model_a = LinearRegression().fit(x_train.reshape(-1, 1), y_train)\n",
    "          y_pred_a = model_a.predict(x_test.reshape(-1, 1))\n",
    "          pa = (y_test - y_pred_a)**2\n",
    "    \n",
    "        # Quadratic Model : B\n",
    "          x_train_quad = np.column_stack((x_train, x_train**2))\n",
    "          x_test_quad = np.column_stack((x_test, x_test**2))\n",
    "            \n",
    "          model_b = LinearRegression().fit(x_train_quad, y_train)\n",
    "          y_pred_b = model_b.predict(x_test_quad)\n",
    "          pb = (y_test - y_pred_b)**2\n",
    "\n",
    "          differences = pa - pb\n",
    "\n",
    "          mean = sum(differences)/m\n",
    "          std = np.std(differences, ddof=1)\n",
    "          means.append(mean)\n",
    "          stds.append(std)\n",
    "\n",
    "      empirical_means_diff.append(means)\n",
    "      standard_deviations_diff.append(stds)\n",
    "\n",
    "    return empirical_means_diff, standard_deviations_diff\n",
    "\n",
    "def create_data_diff():\n",
    "    \n",
    "    M = [150, 200, 500, 1000, 2000]\n",
    "    \n",
    "    empirical_means_diff, standard_deviations_diff = descriptive_statistics_diff()\n",
    "\n",
    "\n",
    "\n",
    "    df_empirical_means_diff = pd.DataFrame(empirical_means_diff, index=M, columns=beta2_values).transpose()\n",
    "    df_empirical_standard_deviations_diff = pd.DataFrame(standard_deviations_diff, index=M, columns=beta2_values).transpose()\n",
    "    \n",
    "\n",
    "    return df_empirical_means_diff, df_empirical_standard_deviations_diff\n",
    "\n",
    "\n",
    "def divide_by_sqrt(df):\n",
    "    return df.apply(lambda x: x / np.sqrt(x.name), axis=0)\n",
    "\n",
    "def standard_error_m_large_diff():\n",
    "\n",
    "    df_empirical_means_diff, df_empirical_standard_deviations_diff = create_data_diff()\n",
    "\n",
    "    df_standard_error_diff = divide_by_sqrt(df_empirical_standard_deviations_diff)\n",
    "\n",
    "    return df_standard_error_diff\n",
    "\n",
    "\n",
    "df_standard_error_diff = standard_error_m_large_diff()\n",
    "\n",
    "def create_interval(lower, upper):\n",
    "      return pd.Interval(left=lower, right=upper, closed='both')\n",
    "\n",
    "\n",
    "def confidence_interval_mean_diff():\n",
    "     \n",
    "     \n",
    "   df_empirical_means_diff, df_empirical_standard_deviations_diff = create_data_diff()\n",
    "    \n",
    "   df_standard_error_diff = standard_error_m_large_diff()\n",
    "\n",
    "   t_critical = 1.96\n",
    "   CI_lower_diff = df_empirical_means_diff - t_critical * df_standard_error_diff\n",
    "   CI_upper_diff = df_empirical_means_diff + t_critical * df_standard_error_diff\n",
    "\n",
    "     \n",
    "   confidence_intervals_diff = pd.DataFrame(index=CI_lower_diff.index, columns=CI_lower_diff.columns)\n",
    "\n",
    "   for col in CI_lower_diff.columns:\n",
    "    confidence_intervals_diff[col] = CI_lower_diff[col].combine(CI_upper_diff[col], create_interval)\n",
    "\n",
    "\n",
    "   return confidence_intervals_diff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def graphs_confidence_intervals_diff():\n",
    "\n",
    "    confidence_intervals_diff = confidence_interval_mean_diff()\n",
    "  \n",
    "    df4 = confidence_intervals_diff.loc[beta2_1]\n",
    "    df5 = confidence_intervals_diff.loc[beta2_2]\n",
    "    df6 = confidence_intervals_diff.loc[beta2_3]\n",
    "\n",
    "    y_values = [\n",
    "    [-0.00224048499549938, 0.0035020525466965434],\n",
    "    [-0.055586561742080424, 0.005484346945660815],\n",
    "    [-0.0047738783907312725, 0.0012688340901101367],\n",
    "    [-0.000298699052576929, 0.005570306576659783],\n",
    "    [-0.04647783243064141, -0.016190205121959147]\n",
    "]\n",
    "\n",
    "    table_1 = [\n",
    "    [-0.033615345464745254, 0.05502179615369398],\n",
    "    [-0.09216435241715609, 0.04742033454105213],\n",
    "    [-0.0218683137802478, 0.040577243826127075],\n",
    "    [0.02384741082744665, 0.06886686176993852],\n",
    "    [-0.040706890144407032, 0.01697745515906775]\n",
    "]\n",
    "\n",
    "    table_2 = [\n",
    "    [-0.027037504233300133, 0.1564332072125412],\n",
    "    [-0.09032617142688239, 0.1289943384938562],\n",
    "    [0.010822213501137913, 0.1299276714144535],\n",
    "    [0.09286671611121941, 0.17916493813779735],\n",
    "    [0.009693510844370888, 0.09541913452140233]\n",
    "]\n",
    "    \n",
    "\n",
    "    x = [150, 200, 500, 1000, 2000]\n",
    "    y1, y2 = zip(*y_values)\n",
    "    y3, y4 = zip(*table_1)\n",
    "    y5, y6 = zip(*table_2)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(x, y1, label='lower bound beta2 = 0', marker='o', color=\"lightblue\")\n",
    "    plt.plot(x, y2, label='upper bound beta2 = 0', marker='o', color=\"darkblue\")\n",
    "    plt.plot(x, y3, label='lower bound beta2 = 0.06', marker='o', color=\"brown\")\n",
    "    plt.plot(x, y4, label='upper bound beta2 = 0.08', marker='o', color=\"darkred\")\n",
    "    plt.plot(x, y5, label='lower bound beta2 = 0.16', marker='o', color=\"lightgreen\")\n",
    "    plt.plot(x, y6, label='upper bound beta2 = 0.16', marker='o', color=\"darkgreen\")\n",
    "\n",
    "    plt.fill_between(x, y1, y2, color='blue', alpha=0.3, label='Interval for beta2 = 0')\n",
    "    plt.fill_between(x, y3, y4, color='red', alpha=0.3, label='Interval for beta2 = 0.08')\n",
    "    plt.fill_between(x, y5, y6, color='yellow', alpha=0.3, label='Interval for beta2 = 0.16')\n",
    "    plt.xlabel('Values of n_test')\n",
    "    plt.ylabel('Interval confidence of the mean of diff')\n",
    "    plt.title('Derived confidence intervals of mean diff as a function of N_test')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs_confidence_intervals_diff()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_each_bootstrap_diff(n, B, m):\n",
    "\n",
    "    np.random.seed(42)\n",
    "\n",
    "    ci_bootstrap_diff = []\n",
    "\n",
    "    beta1 = 2\n",
    "    B = 250\n",
    "    alpha = 0.05\n",
    "    epsilon = np.random.normal(0, 1, n + m) \n",
    "    x = np.random.uniform(0, 5, n + m)\n",
    "\n",
    "    x_train = x[:n]\n",
    "    x_test = x[n:n+m]\n",
    "\n",
    "    epsilon_train = epsilon[:n]\n",
    "    epsilon_test = epsilon[n:n+m]\n",
    "\n",
    "    bootstrap_indices = np.random.choice(m, size=(B, m), replace=True) # bootstrapping\n",
    "    \n",
    "    for beta2 in beta2_values:\n",
    "\n",
    "        moy_boot = []\n",
    "        y_train = beta1 * x_train + beta2 * x_train**2 + epsilon_train\n",
    "\n",
    "        for bootstrap_index in bootstrap_indices:\n",
    "       \n",
    "           x_test = x[bootstrap_index]\n",
    "           y_test = beta1 * x_test + beta2 * x_test**2 + epsilon_test\n",
    "\n",
    "           model_a = LinearRegression().fit(x_train.reshape(-1, 1), y_train)\n",
    "           y_pred_a = model_a.predict(x_test.reshape(-1, 1))\n",
    "           pa = (y_test - y_pred_a)**2\n",
    "\n",
    "           x_train_quad = np.column_stack((x_train, x_train**2))\n",
    "           x_test_quad = np.column_stack((x_test, x_test**2))\n",
    "\n",
    "           model_b = LinearRegression().fit(x_train_quad, y_train)\n",
    "           y_pred_b = model_b.predict(x_test_quad)\n",
    "           pb = (y_test - y_pred_b)**2\n",
    "\n",
    "           difference = pa - pb\n",
    "    \n",
    "           moy_boot.append(np.mean(difference))\n",
    "           \n",
    "\n",
    "        lower_A = np.percentile(moy_boot, 100 * (alpha / 2))\n",
    "        upper_A = np.percentile(moy_boot, 100 * (1 - alpha / 2))\n",
    "\n",
    "\n",
    "        ci_bootstrap_diff.append(pd.Interval(left=lower_A, right=upper_A, closed='both'))\n",
    "    \n",
    "    return ci_bootstrap_diff    \n",
    "\n",
    "def confidence_interval_bootstrap_diff():\n",
    "\n",
    "   M = [150, 200, 500, 1000, 2000]\n",
    "\n",
    "   liste_ci_bootstrap_diff = []\n",
    "\n",
    "   for m in M:\n",
    "\n",
    "      ci_bootstrap_diff = conf_each_bootstrap_diff(150,250,m)\n",
    "\n",
    "      liste_ci_bootstrap_diff.append(ci_bootstrap_diff)\n",
    "\n",
    "   df_ci_bootstrap_diff = pd.DataFrame(liste_ci_bootstrap_diff, index=M, columns=beta2_values).transpose()\n",
    "\n",
    "   return df_ci_bootstrap_diff\n",
    "\n",
    "df_ci_bootstrap_diff = confidence_interval_bootstrap_diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def graphs_confidence_intervals_boot_diff():\n",
    "\n",
    "    df_ci_bootstrap_diff = confidence_interval_bootstrap_diff()\n",
    "  \n",
    "    df4 = df_ci_bootstrap_diff.loc[beta2_1]\n",
    "    df5 = df_ci_bootstrap_diff.loc[beta2_2]\n",
    "    df6 = df_ci_bootstrap_diff.loc[beta2_3]\n",
    "\n",
    "    y_values = [\n",
    "    [-0.003512964579693098, 0.0028840226022357764],\n",
    "    [-0.04380779140377065, 0.01563652071406074],\n",
    "    [-0.00309317748416536, 0.003051016152389021],\n",
    "    [-0.002632494411487736, 0.003061574986012803],\n",
    "    [-0.042311176847253454, -0.016673972045885124]\n",
    "]\n",
    "\n",
    "    table_1 = [\n",
    "    [-0.020543797503679004, 0.08059332100761392],\n",
    "    [-0.0546462587354289, 0.08022161602502724],\n",
    "    [-0.00426251210462769, 0.05818729143812169],\n",
    "    [0.007948508651204597, 0.049743690822452905],\n",
    "    [-0.031922069955109655, 0.01643259944779306]\n",
    "]\n",
    "\n",
    "    table_2 = [\n",
    "    [0.006554879722131183, 0.21821821194090696],\n",
    "    [-0.01765086059119779, 0.1977468360437992],\n",
    "    [0.04326867542452211, 0.16253827878341376],\n",
    "    [0.06373489985349622, 0.14070408077429012],\n",
    "    [0.02385983683331472, 0.09556055683693368]\n",
    "]\n",
    "\n",
    "    x = [150, 200, 500, 1000, 2000]\n",
    "    y1, y2 = zip(*y_values)\n",
    "    y3, y4 = zip(*table_1)\n",
    "    y5, y6 = zip(*table_2)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(x, y1, label='lower bound beta2 = 0', marker='o', color=\"lightblue\")\n",
    "    plt.plot(x, y2, label='upper bound beta2 = 0', marker='o', color=\"darkblue\")\n",
    "    plt.plot(x, y3, label='lower bound beta2 = 0.06', marker='o', color=\"brown\")\n",
    "    plt.plot(x, y4, label='upper bound beta2 = 0.08', marker='o', color=\"darkred\")\n",
    "    plt.plot(x, y5, label='lower bound beta2 = 0.16', marker='o', color=\"lightgreen\")\n",
    "    plt.plot(x, y6, label='upper bound beta2 = 0.16', marker='o', color=\"darkgreen\")\n",
    "\n",
    "    plt.fill_between(x, y1, y2, color='blue', alpha=0.3, label='Interval for beta2 = 0')\n",
    "    plt.fill_between(x, y3, y4, color='red', alpha=0.3, label='Interval for beta2 = 0.08')\n",
    "    plt.fill_between(x, y5, y6, color='yellow', alpha=0.3, label='Interval for beta2 = 0.16')\n",
    "    plt.xlabel('Values of n_test')\n",
    "    plt.ylabel('Interval confidence of the mean of diff')\n",
    "    plt.title('Bootstrapped confidence intervals of mean diff as a function of N_test')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs_confidence_intervals_boot_diff()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_simulation():\n",
    "\n",
    "    np.random.seed(42)\n",
    "    n= 150\n",
    "    m = 2000\n",
    "    power = []\n",
    "    standard_errors = []\n",
    "    test_statistics = []\n",
    "    beta1 = 2\n",
    "    epsilon = np.random.normal(0, 1, n + m) \n",
    "    x = np.random.uniform(0, 5, n + m)\n",
    "\n",
    "    x_train = x[:n]\n",
    "    x_test = x[n:n+m]\n",
    "    epsilon_train = epsilon[:n]\n",
    "    epsilon_test = epsilon[n:n+m]\n",
    "\n",
    "    for beta2 in beta2_values:\n",
    "\n",
    "        \n",
    "        y_train = beta1 * x_train + beta2 * x_train **2 + epsilon_train\n",
    "        y_test = beta1 * x_test + beta2 * x_test**2 + epsilon_test\n",
    "\n",
    "        # Linear Model\n",
    "        model_a1 = LinearRegression().fit(x_train.reshape(-1, 1), y_train)\n",
    "        y_pred_a1 = model_a1.predict(x_test.reshape(-1, 1))\n",
    "        pa = (y_test-y_pred_a1)**2\n",
    "\n",
    "            # Quadratic Model\n",
    "        x_train_quad = np.column_stack((x_train, x_train**2))\n",
    "        x_test_quad = np.column_stack((x_test, x_test**2))    \n",
    "        model_a2 = LinearRegression().fit(x_train_quad, y_train)\n",
    "        y_pred_a2 = model_a2.predict(x_test_quad)\n",
    "        pb = (y_test-y_pred_a2)**2\n",
    "\n",
    "        diff = pa - pb\n",
    "\n",
    "        d_barre = np.mean(diff)\n",
    "        se = np.std(diff)/(m**0.5)\n",
    " \n",
    "        test_stat = d_barre/se # Statistique pour l'hypothèse nulle\n",
    "\n",
    "        student = stats.t.ppf(0.95, df=m-1)\n",
    "        test_alt = student - test_stat\n",
    "        puissance = 1 - stats.norm.cdf(test_alt, 0, 1)\n",
    "       \n",
    "        standard_errors.append(se)\n",
    "        test_statistics.append(test_stat)\n",
    "        power.append(puissance)\n",
    "\n",
    "    return  standard_errors, test_statistics, power\n",
    "\n",
    "\n",
    "standard_errors, test_statistics, power = power_simulation()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"Puissance du test selon beta2\")\n",
    "plt.plot(beta2_values, power, label = \"puissance\", color = \"red\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_simulation_boot():\n",
    "\n",
    "    np.random.seed(42)\n",
    "    n = 150\n",
    "    m = 2000\n",
    "    power = []\n",
    "    standard_errors = []\n",
    "    test_statistics = []\n",
    "    beta1 = 2\n",
    "    epsilon = np.random.normal(0, 1, n + m) \n",
    "    x = np.random.uniform(0, 5, n + m)\n",
    "\n",
    "    x_train = x[:n]\n",
    "    epsilon_train = epsilon[:n]\n",
    "    epsilon_test = epsilon[n:n+m]\n",
    "\n",
    "    B = 250\n",
    "    bootstrap_indices = np.random.choice(m, size=(B, m), replace=True) # bootstrapping\n",
    "    \n",
    "    for beta2 in beta2_values:\n",
    "\n",
    "        moy_boot_diff = []\n",
    "        y_train = beta1 * x_train + beta2 * x_train**2 + epsilon_train\n",
    "\n",
    "        for bootstrap_index in bootstrap_indices:\n",
    "       \n",
    "           x_test = x[bootstrap_index]\n",
    "           y_test = beta1 * x_test + beta2 * x_test**2 + epsilon_test\n",
    "\n",
    "           model_a = LinearRegression().fit(x_train.reshape(-1, 1), y_train)\n",
    "           y_pred_a = model_a.predict(x_test.reshape(-1, 1))\n",
    "           pa = (y_test - y_pred_a)**2\n",
    "\n",
    "           x_train_quad = np.column_stack((x_train, x_train**2))\n",
    "           x_test_quad = np.column_stack((x_test, x_test**2))\n",
    "\n",
    "           model_b = LinearRegression().fit(x_train_quad, y_train)\n",
    "           y_pred_b = model_b.predict(x_test_quad)\n",
    "           pb = (y_test - y_pred_b)**2\n",
    "\n",
    "           diff = pa - pb\n",
    "    \n",
    "           moy_boot_diff.append(np.mean(diff))\n",
    "\n",
    "        d_barre = np.mean(moy_boot_diff)\n",
    "        se = np.std(moy_boot_diff)/(m**0.5)\n",
    " \n",
    "        test_stat = d_barre/se # Statistique pour l'hypothèse nulle\n",
    "\n",
    "        student = stats.t.ppf(0.95, df=m-1)\n",
    "        test_alt = student - test_stat\n",
    "        puissance = 1 - stats.norm.cdf(test_alt, 0, 1)\n",
    "       \n",
    "        standard_errors.append(se)\n",
    "        test_statistics.append(test_stat)\n",
    "        power.append(puissance)\n",
    "\n",
    "    return  standard_errors, test_statistics, power\n",
    "\n",
    "\n",
    "standard_errors_boot, test_statistics_boot, power_boot = power_simulation_boot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.title(\"Puissance du test selon beta2\")\n",
    "plt.plot(beta2_values, power_boot, label = \"puissance bootstrap\", color = \"darkred\")\n",
    "plt.plot(beta2_values, power, label = \"puissance paramétrique\", color = \"red\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permutation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_simulation_with_permutation(n_permutations=1000):\n",
    "    np.random.seed(42)\n",
    "    n = 150\n",
    "    m = 2000\n",
    "    power = []\n",
    "    standard_errors = []\n",
    "    test_statistics = []\n",
    "    permutation_p_values = []\n",
    "    \n",
    "    beta1 = 2\n",
    "    epsilon = np.random.normal(0, 1, n + m) \n",
    "    x = np.random.uniform(0, 5, n + m)\n",
    "\n",
    "    x_train = x[:n]\n",
    "    x_test = x[n:n+m]\n",
    "    epsilon_train = epsilon[:n]\n",
    "    epsilon_test = epsilon[n:n+m]\n",
    "\n",
    "    for beta2 in beta2_values:\n",
    "        y_train = beta1 * x_train + beta2 * x_train ** 2 + epsilon_train\n",
    "        y_test = beta1 * x_test + beta2 * x_test ** 2 + epsilon_test\n",
    "\n",
    "        # Linear Model\n",
    "        model_a1 = LinearRegression().fit(x_train.reshape(-1, 1), y_train)\n",
    "        y_pred_a1 = model_a1.predict(x_test.reshape(-1, 1))\n",
    "        pa = (y_test - y_pred_a1) ** 2\n",
    "\n",
    "        # Quadratic Model\n",
    "        x_train_quad = np.column_stack((x_train, x_train ** 2))\n",
    "        x_test_quad = np.column_stack((x_test, x_test ** 2))    \n",
    "        model_a2 = LinearRegression().fit(x_train_quad, y_train)\n",
    "        y_pred_a2 = model_a2.predict(x_test_quad)\n",
    "        pb = (y_test - y_pred_a2) ** 2\n",
    "\n",
    "        diff = pa - pb\n",
    "        d_barre = np.mean(diff)\n",
    "        se = np.std(diff) / (m ** 0.5)\n",
    "        test_stat = d_barre / se\n",
    "\n",
    "        perm_stats = []\n",
    "        for _ in range(n_permutations):\n",
    "            perm_indices = np.random.permutation(m)\n",
    "            perm_diff = pa[perm_indices] - pb[perm_indices]\n",
    "            perm_d_barre = np.mean(perm_diff)\n",
    "            perm_stats.append(perm_d_barre / se)\n",
    "\n",
    "        perm_stats = np.array(perm_stats)\n",
    "        p_value = (np.sum(perm_stats >= test_stat) + 1) / (n_permutations + 1)\n",
    "        permutation_p_values.append(p_value)  \n",
    "        puissance =  np.mean(np.array(permutation_p_values) < 0.05)\n",
    "\n",
    "        standard_errors.append(se)\n",
    "        test_statistics.append(test_stat)\n",
    "        power.append(puissance)\n",
    "\n",
    "    return standard_errors, test_statistics, power, permutation_p_values\n",
    "\n",
    "standard_errors_perm, test_statistics_perm, power_perm, permutation_p_values = power_simulation_with_permutation()\n",
    "\n",
    "print(\"Standard Errors:\", standard_errors)\n",
    "print(\"Test Statistics:\", test_statistics)\n",
    "print(\"Power:\", power_perm)\n",
    "print(\"Permutation P-values:\", permutation_p_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Errors: [0.007724503687533174, 0.009460719201810157, 0.01120244172585826, 0.012951381596032516, 0.014709238570989542, 0.016477699128963595, 0.01825843385151428, 0.02005309491021282, 0.021863313671305225]\n",
      "Test Statistics: [-4.056444277044139, -3.2432040637045767, -2.430003857926712, -1.6176513350658734, -0.8069467536879653, 0.0013209147015453993, 0.8063777122010404, 1.6074682375883356, 2.40385897000896]\n",
      "Power (Permutation): [5.918389112125055e-09, 5.072101761927073e-07, 2.294594387564075e-05, 0.000550677392535226, 0.007092126911732759, 0.050057606397363105, 0.2006677332492435, 0.4847848361120924, 0.7758471550081736]\n",
      "Permutation P-values: [0.3676323676323676, 0.5824175824175825, 0.7122877122877123, 0.6883116883116883, 0.5774225774225774, 0.5464535464535465, 0.5734265734265734, 0.46253746253746253, 0.8241758241758241]\n"
     ]
    }
   ],
   "source": [
    "def power_simulation_with_permutation_2(n_permutations=1000):\n",
    "    np.random.seed(42)\n",
    "    n = 150\n",
    "    m = 2000\n",
    "    power = []\n",
    "    power_perm = []\n",
    "    standard_errors = []\n",
    "    test_statistics = []\n",
    "    permutation_p_values = []\n",
    "    \n",
    "    beta1 = 2\n",
    "    epsilon = np.random.normal(0, 1, n + m) \n",
    "    x = np.random.uniform(0, 5, n + m)\n",
    "\n",
    "    x_train = x[:n]\n",
    "    x_test = x[n:n+m]\n",
    "    epsilon_train = epsilon[:n]\n",
    "    epsilon_test = epsilon[n:n+m]\n",
    "\n",
    "    for beta2 in beta2_values:\n",
    "        y_train = beta1 * x_train + beta2 * x_train ** 2 + epsilon_train\n",
    "        y_test = beta1 * x_test + beta2 * x_test ** 2 + epsilon_test\n",
    "\n",
    "        # Linear Model\n",
    "        model_a1 = LinearRegression().fit(x_train.reshape(-1, 1), y_train)\n",
    "        y_pred_a1 = model_a1.predict(x_test.reshape(-1, 1))\n",
    "        pa = (y_test - y_pred_a1) ** 2\n",
    "\n",
    "        # Quadratic Model\n",
    "        x_train_quad = np.column_stack((x_train, x_train ** 2))\n",
    "        x_test_quad = np.column_stack((x_test, x_test ** 2))    \n",
    "        model_a2 = LinearRegression().fit(x_train_quad, y_train)\n",
    "        y_pred_a2 = model_a2.predict(x_test_quad)\n",
    "        pb = (y_test - y_pred_a2) ** 2\n",
    "\n",
    "        diff = pa - pb\n",
    "        d_barre = np.mean(diff)\n",
    "        se = np.std(diff) / (m ** 0.5)\n",
    "        test_stat = d_barre / se\n",
    "\n",
    "        perm_stats = []\n",
    "        for _ in range(n_permutations):\n",
    "            perm_indices = np.random.permutation(m)\n",
    "            perm_diff = pa[perm_indices] - pb\n",
    "            perm_d_barre = np.mean(perm_diff)\n",
    "            perm_stats.append(perm_d_barre / se)\n",
    "\n",
    "        perm_stats = np.array(perm_stats)\n",
    "\n",
    "        p_value = (np.sum(perm_stats >= test_stat) + 1) / (n_permutations + 1)\n",
    "        permutation_p_values.append(p_value)\n",
    "\n",
    "\n",
    "        perm_student = stats.t.ppf(0.95, df=m-1)\n",
    "        perm_test_alt = perm_student - perm_stats\n",
    "        perm_puissance = 1 - stats.norm.cdf(perm_test_alt, 0, 1)\n",
    "\n",
    "        power_perm.append(np.mean(perm_puissance))\n",
    "\n",
    "        standard_errors.append(se)\n",
    "        test_statistics.append(test_stat)\n",
    "\n",
    "    return standard_errors, test_statistics, power_perm, permutation_p_values\n",
    "\n",
    "standard_errors_perm_2, test_statistics_perm_2, power_perm_2, permutation_p_values_2 = power_simulation_with_permutation_2()\n",
    "\n",
    "print(\"Standard Errors:\", standard_errors_perm_2)\n",
    "print(\"Test Statistics:\", test_statistics_perm_2)\n",
    "print(\"Power (Permutation):\", power_perm_2)\n",
    "print(\"Permutation P-values:\", permutation_p_values_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.title(\"Puissance du test selon beta2\")\n",
    "plt.plot(beta2_values, power_boot, label = \"puissanc testbootstrap\", color = \"darkred\")\n",
    "plt.plot(beta2_values, power, label = \"puissance test paramétrique\", color = \"red\")\n",
    "plt.plot(beta2_values, power_perm_2, label = \"puissance test permutation 2\", color = \"black\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non parametric testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import wilcoxon\n",
    "\n",
    "def power_simulation_with_wilcoxon():\n",
    "    np.random.seed(42)\n",
    "    n = 150\n",
    "    m = 2000\n",
    "    power = []\n",
    "    standard_errors = []\n",
    "    test_statistics = []\n",
    "    wilcoxon_p_values = []\n",
    "    \n",
    "    beta1 = 2\n",
    "    epsilon = np.random.normal(0, 1, n + m) \n",
    "    x = np.random.uniform(0, 5, n + m)\n",
    "\n",
    "    x_train = x[:n]\n",
    "    x_test = x[n:n+m]\n",
    "    epsilon_train = epsilon[:n]\n",
    "    epsilon_test = epsilon[n:n+m]\n",
    "\n",
    "    for beta2 in beta2_values:\n",
    "        y_train = beta1 * x_train + beta2 * x_train ** 2 + epsilon_train\n",
    "        y_test = beta1 * x_test + beta2 * x_test ** 2 + epsilon_test\n",
    "\n",
    "        # Linear Model\n",
    "        model_a1 = LinearRegression().fit(x_train.reshape(-1, 1), y_train)\n",
    "        y_pred_a1 = model_a1.predict(x_test.reshape(-1, 1))\n",
    "        pa = (y_test - y_pred_a1) ** 2\n",
    "\n",
    "        # Quadratic Model\n",
    "        x_train_quad = np.column_stack((x_train, x_train ** 2))\n",
    "        x_test_quad = np.column_stack((x_test, x_test ** 2))    \n",
    "        model_a2 = LinearRegression().fit(x_train_quad, y_train)\n",
    "        y_pred_a2 = model_a2.predict(x_test_quad)\n",
    "        pb = (y_test - y_pred_a2) ** 2\n",
    "\n",
    "        diff = pa - pb\n",
    "        d_barre = np.mean(diff)\n",
    "        se = np.std(diff) / (m ** 0.5)\n",
    "        test_stat = d_barre / se\n",
    "\n",
    "        wilcoxon_stat, p_value = wilcoxon(diff)\n",
    "        wilcoxon_p_values.append(p_value)\n",
    "\n",
    "        puissance = np.mean(np.array(wilcoxon_p_values) < 0.05)\n",
    "        standard_errors.append(se)\n",
    "        test_statistics.append(test_stat)\n",
    "        power.append(puissance)\n",
    "\n",
    "    return standard_errors, test_statistics, power, wilcoxon_p_values\n",
    "\n",
    "standard_errors_wil, test_statistics_wil, power_wil, wilcoxon_p_values = power_simulation_with_wilcoxon()\n",
    "\n",
    "print(\"Standard Errors:\", standard_errors_wil)\n",
    "print(\"Test Statistics:\", test_statistics_wil)\n",
    "print(\"Power:\", power_wil)\n",
    "print(\"Wilcoxon P-values:\", wilcoxon_p_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"Puissance du test selon beta2\")\n",
    "plt.plot(beta2_values, power_boot, label = \"puissanc testbootstrap\", color = \"darkred\")\n",
    "plt.plot(beta2_values, power, label = \"puissance test paramétrique\", color = \"red\")\n",
    "plt.plot(beta2_values, power_perm, label = \"puissance test permutation\", color = \"black\")\n",
    "plt.plot(beta2_values, power_wil, label = \"puissance test non param\", color = \"blue\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
