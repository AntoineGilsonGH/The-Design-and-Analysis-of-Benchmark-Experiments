{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import scipy.stats as stats\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_antoine = \"/Users/antoine.gilson/Desktop/The-Design-and-Analysis-of-Benchmark-Experiments/Plots/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta2_values = np.linspace(0, 0.16, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction, variables, training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_training_test_sets(n=150, m=2000, seed=42):\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    x = np.random.uniform(0, 5, n + m)\n",
    "    x_train = x[:n]\n",
    "    x_test = x[n:n+m]\n",
    "    \n",
    "    epsilon = np.random.normal(0, 1, n + m)\n",
    "    epsilon_train = epsilon[:n]\n",
    "    epsilon_test = epsilon[n:n+m]\n",
    "    \n",
    "    # Création de la figure avec subplots\n",
    "    fig, ax = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    \n",
    "    # Plotting X Training set\n",
    "    ax[0, 0].scatter(np.arange(n), x_train, label=\"X Training set n = 150\", color=\"blue\", s=10)\n",
    "    ax[0, 0].set_title(\"Training Set X\")\n",
    "    ax[0, 0].set_xlabel(\"Index\")\n",
    "    ax[0, 0].set_ylabel(\"Value\")\n",
    "    ax[0, 0].legend()\n",
    "    ax[0, 0].grid()\n",
    "\n",
    "    # Plotting X Test set\n",
    "    ax[0, 1].scatter(np.arange(n, n + m), x_test, label=\"X Test set m = 2000\", color=\"red\", s=10)\n",
    "    ax[0, 1].set_title(\"Test Set X\")\n",
    "    ax[0, 1].set_xlabel(\"Index\")\n",
    "    ax[0, 1].set_ylabel(\"Value\")\n",
    "    ax[0, 1].legend()\n",
    "    ax[0, 1].grid()\n",
    "\n",
    "    # Plotting Epsilon Training set\n",
    "    ax[1, 0].scatter(np.arange(n), epsilon_train, label=\"Epsilon Training set n = 150\", color=\"green\", s=10)\n",
    "    ax[1, 0].set_title(\"Training Set Epsilon\")\n",
    "    ax[1, 0].set_xlabel(\"Index\")\n",
    "    ax[1, 0].set_ylabel(\"Value\")\n",
    "    ax[1, 0].legend()\n",
    "    ax[1, 0].grid()\n",
    "\n",
    "    # Plotting Epsilon Test set\n",
    "    ax[1, 1].scatter(np.arange(n, n + m), epsilon_test, label=\"Epsilon Test set m = 2000\", color=\"orange\", s=10)\n",
    "    ax[1, 1].set_title(\"Test Set Epsilon\")\n",
    "    ax[1, 1].set_xlabel(\"Index\")\n",
    "    ax[1, 1].set_ylabel(\"Value\")\n",
    "    ax[1, 1].legend()\n",
    "    ax[1, 1].grid()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.scatter(np.arange(n), x_train, label = \"X Training set n = 150\", color = \"blue\", s = 8)\n",
    "    plt.scatter(np.arange(n, n+m), x_test, label = \"X Test set m = 2000\", color = \"red\", s = 8)\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.scatter(np.arange(n), epsilon_train, label = \"Eps Training set n = 150\", color = \"green\", s = 8)\n",
    "    plt.scatter(np.arange(n, n+m), epsilon_test, label = \"Eps Test set m = 2000\", color = \"orange\", s = 8)\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective function : y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_objective_function(m):\n",
    "    \n",
    "    n = 150\n",
    "    np.random.seed(42)\n",
    "\n",
    "    beta1 = 2\n",
    "    epsilon = np.random.normal(0, 1, n + m) \n",
    "    x = np.random.uniform(0, 5, n + m)\n",
    "\n",
    "    x_train = x[:n]\n",
    "    x_test = x[n:n+m]\n",
    "\n",
    "    epsilon_train = epsilon[:n]\n",
    "    epsilon_test = epsilon[n:n+m]\n",
    "    \n",
    "    for beta2 in beta2_values:\n",
    "            \n",
    "       y_train = beta1 * x_train + beta2 * x_train**2 + epsilon_train\n",
    "       y_test = beta1 * x_test + beta2 * x_test**2 + epsilon_test\n",
    "\n",
    "       plt.figure()\n",
    "       plt.scatter(np.arange(n), y_train, label = \"Y corresponding to training set n = 150\", color = \"blue\", s = 8)\n",
    "       plt.scatter(np.arange(n, n+m), y_test, label = \"Y corresponding to test set m =\" f\"{m}\", color = \"red\", s = 8)\n",
    "       plt.legend()\n",
    "       plt.grid()\n",
    "       filename = f\"{path_antoine}/Objective/objective_y_m_{m}_beta2_{beta2}.png\"\n",
    "       plt.savefig(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphical approach of model precision and errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_metrics():\n",
    "    \n",
    "    n = 150\n",
    "\n",
    "    M = [50, 100, 150, 200, 500, 1000, 2000]\n",
    "\n",
    "    for m in M:\n",
    "\n",
    "      np.random.seed(42)\n",
    "      beta1 = 2\n",
    "      epsilon = np.random.normal(0, 1, n + m) \n",
    "      x = np.random.uniform(0, 5, n + m)\n",
    "\n",
    "      x_train = x[:n]\n",
    "      x_test = x[n:n+m]\n",
    "\n",
    "      epsilon_train = epsilon[:n]\n",
    "      epsilon_test = epsilon[n:n+m]\n",
    "    \n",
    "      for beta2 in beta2_values:\n",
    "            \n",
    "          y_train = beta1 * x_train + beta2 * x_train**2 + epsilon_train\n",
    "          y_test = beta1 * x_test + beta2 * x_test**2 + epsilon_test\n",
    "\n",
    "           # Linear Model : A\n",
    "          model_a = LinearRegression().fit(x_train.reshape(-1, 1), y_train)\n",
    "          y_pred_a = model_a.predict(x_test.reshape(-1, 1))\n",
    "          pa = (y_test - y_pred_a)**2\n",
    "    \n",
    "          # Quadratic Model : B\n",
    "          x_train_quad = np.column_stack((x_train, x_train**2))\n",
    "          x_test_quad = np.column_stack((x_test, x_test**2))\n",
    "            \n",
    "          model_b = LinearRegression().fit(x_train_quad, y_train)\n",
    "          y_pred_b = model_b.predict(x_test_quad)\n",
    "          pb = (y_test - y_pred_b)**2\n",
    "\n",
    "          differences = pa - pb\n",
    "\n",
    "          plt.figure() # Erreur individuelle des modèles\n",
    "          plt.title(\"Erreurs de prédiction des modèles pour \" f\"beta2 = {beta2}\" \" et pour \"f\"m = {m}\" )  \n",
    "      \n",
    "          plt.scatter(x_test, pb, label = \"pb = (y - yb) pour \" f\"beta2 = {beta2}\" \" et pour \"f\"m = {m}\", color = \"orange\", s = 8)\n",
    "          plt.scatter(x_test, pa, label = \"pa = (y - ya) pour \" f\"beta2 = {beta2}\" \" et pour \"f\"m = {m}\", color = \"red\", s = 8)\n",
    "       \n",
    "          plt.grid()\n",
    "          plt.legend()\n",
    "\n",
    "          filename = f\"{path_antoine}/Erreurs/plot_m_{m}_beta2_{beta2}.png\"\n",
    "          plt.savefig(filename)\n",
    "\n",
    "          plt.show()\n",
    "\n",
    "          plt.figure() # Différence de prédiction des modèles\n",
    "          plt.title(\"Différence de prédiction des modèles pour \" f\"beta2 = {beta2}\" \" et pour \"f\"m = {m}\" )  \n",
    "      \n",
    "          plt.scatter(x_test, differences, label = \"pb = (y - yb) pour \" f\"beta2 = {beta2}\" \" et pour \"f\"m = {m}\", color = \"red\", s = 8)\n",
    "          plt.axhline(y=0, color='black', linestyle='--', label='y = 0')\n",
    "       \n",
    "          plt.grid()\n",
    "          plt.legend()\n",
    "\n",
    "          filename = f\"{path_antoine}/Differences/plot_m_{m}_beta2_{beta2}.png\"\n",
    "          plt.savefig(filename)\n",
    "\n",
    "          plt.show()\n",
    "\n",
    "          plt.figure() # Fits des modèles \n",
    "          plt.title(\"Fits des modèles pour \" f\"beta2 = {beta2}\" \" et pour \"f\"m = {m}\" )  \n",
    "\n",
    "      \n",
    "          plt.scatter(x_test, y_test, label = \"Y réel\", color = \"green\", s = 8)\n",
    "          plt.scatter(x_test, y_pred_a, label = \"Prédiction linéaire pour \" f\"beta2 = {beta2}\" \" et pour \"f\"m = {m}\", color = \"red\", s = 8)\n",
    "          plt.scatter(x_test, y_pred_b, label = \"Prédiction quadratique pour \" f\"beta2 = {beta2}\" \" et pour \"f\"m = {m}\", color = \"orange\", s = 8)\n",
    "       \n",
    "          plt.grid()\n",
    "          plt.legend()\n",
    "\n",
    "          filename = f\"{path_antoine}/Fits/plot_m_{m}_beta2_{beta2}.png\"\n",
    "          plt.savefig(filename)\n",
    "\n",
    "          plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descriptive_statistics():\n",
    "    \n",
    "    n = 150\n",
    "\n",
    "    M = [50, 100, 150, 200, 500, 1000, 2000]\n",
    "\n",
    "    empirical_means_A = []\n",
    "    standard_deviations_A = []\n",
    "    medians_A = []\n",
    "    Q1_A = []\n",
    "    Q3_A = []\n",
    "    IQR_A = []\n",
    "\n",
    "    empirical_means_B = []\n",
    "    standard_deviations_B = []\n",
    "    medians_B = []\n",
    "    Q1_B = []\n",
    "    Q3_B = []\n",
    "    IQR_B = []\n",
    "\n",
    "    for m in M:\n",
    "\n",
    "      a = []\n",
    "      b = []\n",
    "      c = []\n",
    "      d = []\n",
    "      q = []\n",
    "      iqr = []\n",
    "\n",
    "      e = []\n",
    "      f = []\n",
    "      g = []\n",
    "      h = []\n",
    "      q_ = []\n",
    "      iqr_ = []\n",
    "\n",
    "\n",
    "      np.random.seed(42)\n",
    "      beta1 = 2\n",
    "      beta2_values_bis = [0.2, 0.3, 0.4, 0.5, 1]\n",
    "      epsilon = np.random.normal(0, 1, n + m) \n",
    "      x = np.random.uniform(0, 5, n + m)\n",
    "\n",
    "      x_train = x[:n]\n",
    "      x_test = x[n:n+m]\n",
    "\n",
    "      epsilon_train = epsilon[:n]\n",
    "      epsilon_test = epsilon[n:n+m]\n",
    "    \n",
    "      for beta2 in beta2_values:\n",
    "            \n",
    "       y_train = beta1 * x_train + beta2 * x_train**2 + epsilon_train\n",
    "       y_test = beta1 * x_test + beta2 * x_test**2 + epsilon_test\n",
    "\n",
    "        # Linear Model : A\n",
    "       model_a = LinearRegression().fit(x_train.reshape(-1, 1), y_train)\n",
    "       y_pred_a = model_a.predict(x_test.reshape(-1, 1))\n",
    "       pa = (y_test - y_pred_a)**2\n",
    "    \n",
    "        # Quadratic Model : B\n",
    "       x_train_quad = np.column_stack((x_train, x_train**2))\n",
    "       x_test_quad = np.column_stack((x_test, x_test**2))\n",
    "            \n",
    "       model_b = LinearRegression().fit(x_train_quad, y_train)\n",
    "       y_pred_b = model_b.predict(x_test_quad)\n",
    "       pb = (y_test - y_pred_b)**2\n",
    "\n",
    "       mean_a = sum(pa)/m\n",
    "       mean_b = sum(pb)/m\n",
    "\n",
    "       a.append(mean_a)\n",
    "       e.append(mean_b)\n",
    "\n",
    "       std_a = np.std(pa, ddof=1)\n",
    "       std_b = np.std(pb, ddof = 1)\n",
    "\n",
    "       b.append(std_a)\n",
    "       f.append(std_b)\n",
    "\n",
    "       q1_a = np.percentile(pa, 25)\n",
    "       med_a = np.percentile(pa, 50)        \n",
    "       q3_a = np.percentile(pa, 75)\n",
    "\n",
    "       q1_b = np.percentile(pb, 25)\n",
    "       med_b = np.percentile(pb, 50)        \n",
    "       q3_b = np.percentile(pb, 75)\n",
    "\n",
    "       c.append(med_a)\n",
    "       g.append(med_b)\n",
    "       d.append(q1_a)\n",
    "       q.append(q3_a)\n",
    "       h.append(q1_b)\n",
    "       q_.append(q3_b)\n",
    "\n",
    "       iqr.append(q3_a - q1_a)\n",
    "       iqr_.append(q3_b - q1_b)\n",
    "\n",
    "    empirical_means_A.append(a)\n",
    "    empirical_means_B.append(e)\n",
    "    standard_deviations_A.append(b)\n",
    "    standard_deviations_B.append(f)\n",
    "    medians_A.append(c)\n",
    "    medians_B.append(g)\n",
    "    Q1_A.append(d)\n",
    "    Q1_B.append(h)\n",
    "    Q3_A.append(q)\n",
    "    Q3_B.append(q_)\n",
    "    IQR_A.append(iqr)\n",
    "    IQR_B.append(iqr_)\n",
    "\n",
    "    return empirical_means_A, standard_deviations_A, medians_A, Q1_A, Q3_A, IQR_A, empirical_means_B, standard_deviations_B, medians_B, Q1_B, Q3_B, IQR_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data():\n",
    "    \n",
    "    M = [50, 100, 150, 200, 500, 1000, 2000]\n",
    "    \n",
    "    empirical_means_A, standard_deviations_A, medians_A, Q1_A, Q3_A, IQR_A, empirical_means_B, standard_deviations_B, medians_B, Q1_B, Q3_B, IQR_B = descriptive_statistics()\n",
    "    \n",
    "    \n",
    "    data_A_all = {\n",
    "    \"Empirical Mean\": empirical_means_A,\n",
    "    \"Standard Deviation\": standard_deviations_A,\n",
    "    \"Median\": medians_A,\n",
    "    \"Q1\": Q1_A,\n",
    "    \"Q3\": Q3_A,\n",
    "    \"IQR\": IQR_A\n",
    "   }\n",
    "\n",
    "    stats_A_all = pd.DataFrame(data_A_all, index=M)\n",
    "\n",
    "    data_B_all = {\n",
    "    \"Empirical Mean\": empirical_means_B,\n",
    "    \"Standard Deviation\": standard_deviations_B,\n",
    "    \"Median\": medians_B,\n",
    "    \"Q1\": Q1_B,\n",
    "    \"Q3\": Q3_B,\n",
    "    \"IQR\": IQR_B\n",
    "   }\n",
    "\n",
    "    stats_B_all = pd.DataFrame(data_B_all, index=M)\n",
    "\n",
    "    df_empirical_means_A = pd.DataFrame(empirical_means_A, index=M, columns=beta2_values).transpose()\n",
    "    df_empirical_standard_deviations_A = pd.DataFrame(standard_deviations_A, index=M, columns=beta2_values).transpose()\n",
    "    df_medians_A = pd.DataFrame(medians_A, index=M, columns=beta2_values).transpose()\n",
    "    df_Q1_A = pd.DataFrame(Q1_A, index=M, columns=beta2_values).transpose()\n",
    "    df_Q3_A = pd.DataFrame(Q3_A, index=M, columns=beta2_values).transpose()\n",
    "    df_IQR_A = pd.DataFrame(IQR_A, index=M, columns=beta2_values).transpose()\n",
    "\n",
    "    df_empirical_means_B = pd.DataFrame(empirical_means_B, index=M, columns=beta2_values).transpose()\n",
    "    df_empirical_standard_deviations_B = pd.DataFrame(standard_deviations_B, index=M, columns=beta2_values).transpose()\n",
    "    df_medians_B = pd.DataFrame(medians_B, index=M, columns=beta2_values).transpose()\n",
    "    df_Q1_B = pd.DataFrame(Q1_B, index=M, columns=beta2_values).transpose()\n",
    "    df_Q3_B = pd.DataFrame(Q3_B, index=M, columns=beta2_values).transpose()\n",
    "    df_IQR_B = pd.DataFrame(IQR_B, index=M, columns=beta2_values).transpose()    \n",
    "\n",
    "    return stats_A_all, df_empirical_means_A, df_empirical_standard_deviations_A, df_medians_A, df_Q1_A, df_Q3_A, df_IQR_A, \\\n",
    "    stats_B_all, df_empirical_means_B, df_empirical_standard_deviations_B, df_medians_B, df_Q1_B, df_Q3_B, df_IQR_B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inferential statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already have the standard error of the mean (according to m and beta2), that gives us a first information of the precisation of mA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Derive formulas (or algorithms) for the standard error (SE) of the mean\n",
    "\n",
    "Methods: \n",
    "- parametric estimates (consider different cases when n is small versus large and when VA is assumed to be Gaussian or not)\n",
    "- bootstrap estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_error_n_large():\n",
    "\n",
    "    (stats_A_all, df_empirical_means_A, df_empirical_standard_deviations_A, df_medians_A, df_Q1_A, df_Q3_A, df_IQR_A, \n",
    "    stats_B_all, df_empirical_means_B, df_empirical_standard_deviations_B, df_medians_B, df_Q1_B, df_Q3_B, df_IQR_B) = create_data()\n",
    "\n",
    "    n_sqrt = np.sqrt(n)\n",
    "    df_standard_error_A = df_empirical_standard_deviations_A.apply(lambda x: x / n_sqrt)\n",
    "    df_standard_error_B = df_empirical_standard_deviations_B.apply(lambda x: x / n_sqrt)\n",
    "\n",
    "    return df_standard_error_A, df_standard_error_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moyenne de l'échantillon: 1.085336227600059\n",
      "Erreur standard de la moyenne: 0.1305674524267048\n",
      "Intervalle de confiance à 95.0% pour l'erreur standard de la moyenne: [0.2580030065711649, -0.2580030065711649]\n"
     ]
    }
   ],
   "source": [
    "def standard_error_n_small():\n",
    "    \n",
    "   n = 150\n",
    "   confidence_level = 0.95\n",
    "   degrees_freedom = n - 1\n",
    "\n",
    "   (stats_A_all, df_empirical_means_A, df_empirical_standard_deviations_A, df_medians_A, df_Q1_A, df_Q3_A, df_IQR_A, \n",
    "    stats_B_all, df_empirical_means_B, df_empirical_standard_deviations_B, df_medians_B, df_Q1_B, df_Q3_B, df_IQR_B) = create_data()\n",
    "\n",
    "\n",
    "   confidence_interval = stats.t.interval(confidence_level, degrees_freedom, loc=sample_standard_error, scale=sample_standard_error)\n",
    "   print(f\"Intervalle de confiance à {confidence_level*100}% pour l'erreur standard de la moyenne:\", confidence_interval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap estimate : sur l'ensemble de test\n",
    "\n",
    "n = 150\n",
    "\n",
    "M = [50, 100, 150, 200, 500, 1000, 2000]\n",
    "\n",
    "se_bootstrap_A = []\n",
    "se_bootstrap_B = []\n",
    "\n",
    "for m in M:\n",
    "   \n",
    "   liste_A = []\n",
    "   liste_B = []\n",
    "\n",
    "   np.random.seed(42)\n",
    "   beta1 = 2\n",
    "   beta2_values_bis = [0.2, 0.3, 0.4, 0.5, 1]\n",
    "   epsilon = np.random.normal(0, 1, n + m) \n",
    "   x = np.random.uniform(0, 5, n + m)\n",
    "\n",
    "   x_train = x[:n]\n",
    "   x_test = x[n:n+m]\n",
    "\n",
    "   epsilon_train = epsilon[:n]\n",
    "   epsilon_test = epsilon[n:n+m]\n",
    "    \n",
    "   for beta2 in beta2_values:\n",
    "            \n",
    "       y_train = beta1 * x_train + beta2 * x_train**2 + epsilon_train\n",
    "       y_test = beta1 * x_test + beta2 * x_test**2 + epsilon_test\n",
    "\n",
    "        # Linear Model : A\n",
    "       model_a = LinearRegression().fit(x_train.reshape(-1, 1), y_train)\n",
    "       y_pred_a = model_a.predict(x_test.reshape(-1, 1))\n",
    "       pa = (y_test - y_pred_a)**2\n",
    "    \n",
    "        # Quadratic Model : B\n",
    "       x_train_quad = np.column_stack((x_train, x_train**2))\n",
    "       x_test_quad = np.column_stack((x_test, x_test**2))\n",
    "            \n",
    "       model_b = LinearRegression().fit(x_train_quad, y_train)\n",
    "       y_pred_b = model_b.predict(x_test_quad)\n",
    "       pb = (y_test - y_pred_b)**2\n",
    "       \n",
    "       B = 1000\n",
    "       bootstrap_means = np.zeros(B)\n",
    "\n",
    "       for i in range(B):\n",
    "          \n",
    "          sample_indices = np.random.choice(np.arange(m), size=m, replace=True)\n",
    "          bootstrap_sample = pa[sample_indices]\n",
    "          bootstrap_means[i] = np.mean(bootstrap_sample)\n",
    "\n",
    "       se_bootstrap_A_i = np.std(bootstrap_means)\n",
    "\n",
    "       liste_A.append(se_bootstrap_A_i)\n",
    "\n",
    "       for i in range(B):\n",
    "          \n",
    "          sample_indices = np.random.choice(np.arange(m), size=m, replace=True)\n",
    "          bootstrap_sample = pb[sample_indices]\n",
    "          bootstrap_means[i] = np.mean(bootstrap_sample)\n",
    "\n",
    "       se_bootstrap_B_i = np.std(bootstrap_means)\n",
    "\n",
    "       liste_B.append(se_bootstrap_B_i)\n",
    "    \n",
    "   se_bootstrap_A.append(liste_A)\n",
    "   se_bootstrap_B.append(liste_B)\n",
    "\n",
    "   df_se_bootstrap_A = pd.DataFrame(se_bootstrap_A, index=M, columns=beta2_values).transpose()\n",
    "   df_se_bootstrap_B = pd.DataFrame(se_bootstrap_B, index=M, columns=beta2_values).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap ensemble d'entrainement\n",
    "\n",
    "def se_bootstrap(n, B, m):\n",
    "\n",
    "    np.random.seed(42)\n",
    "\n",
    "    se_bootstrap_A = []\n",
    "    se_bootstrap_B = []\n",
    "\n",
    "    beta1 = 2\n",
    "    B = 250\n",
    "    epsilon = np.random.normal(0, 1, n + m) \n",
    "    x = np.random.uniform(0, 5, n + m)\n",
    "\n",
    "    x_train = x[:n]\n",
    "    x_test = x[n:n+m]\n",
    "\n",
    "    epsilon_train = epsilon[:n]\n",
    "    epsilon_test = epsilon[n:n+m]\n",
    "\n",
    "    bootstrap_indices = np.random.choice(n, size=(B, n), replace=True) # bootstrapping\n",
    "    \n",
    "    for beta2 in beta2_values:\n",
    "\n",
    "        liste_A = []\n",
    "        liste_B = []\n",
    "\n",
    "        for bootstrap_index in bootstrap_indices:\n",
    "       \n",
    "           x_train = x[bootstrap_index]\n",
    "           y_train = beta1 * x_train + beta2 * x_train**2 + epsilon[bootstrap_index]\n",
    "      \n",
    "           y_train = beta1 * x_train + beta2 * x_train**2 + epsilon_train\n",
    "           y_test = beta1 * x_test + beta2 * x_test**2 + epsilon_test\n",
    "\n",
    "           model_a = LinearRegression().fit(x_train.reshape(-1, 1), y_train)\n",
    "           y_pred_a = model_a.predict(x_test.reshape(-1, 1))\n",
    "           pa = (y_test - y_pred_a)**2\n",
    "\n",
    "           x_train_quad = np.column_stack((x_train, x_train**2))\n",
    "           x_test_quad = np.column_stack((x_test, x_test**2))\n",
    "\n",
    "           model_b = LinearRegression().fit(x_train_quad, y_train)\n",
    "           y_pred_b = model_b.predict(x_test_quad)\n",
    "           pb = (y_test - y_pred_b)**2\n",
    "\n",
    "           sea = np.std(pa, ddof=1) / (m**0.5)\n",
    "           seb = np.std(pb, ddof = 1) / (m**0.5)\n",
    "\n",
    "           liste_A.append(sea)\n",
    "           liste_B.append(seb)\n",
    "\n",
    "        se_bootstrap_A.append(sum(liste_A)/B)\n",
    "        se_bootstrap_B.append(sum(liste_B)/B)\n",
    "    \n",
    "    return se_bootstrap_A, se_bootstrap_B     \n",
    "\n",
    "M = [50, 100, 150, 200, 500, 1000, 2000]\n",
    "\n",
    "liste_se_bootstrap_A = []\n",
    "liste_se_bootstrap_B = []\n",
    "\n",
    "for m in M:\n",
    "\n",
    "    se_bootstrap_A, se_bootstrap_B = se_bootstrap(150,250,m)\n",
    "\n",
    "    liste_se_bootstrap_A.append(se_bootstrap_A)\n",
    "    liste_se_bootstrap_B.append(se_bootstrap_B)\n",
    "\n",
    "liste_se_bootstrap_A, liste_se_bootstrap_B\n",
    "\n",
    "df_se_bootstrap_A_v2 = pd.DataFrame(liste_se_bootstrap_A, index=M, columns=beta2_values).transpose()\n",
    "df_se_bootstrap_B_v2 = pd.DataFrame(liste_se_bootstrap_B, index=M, columns=beta2_values).transpose()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparaison des statistiques de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparaison_stats():\n",
    "    M = [100, 150, 200, 500, 1000, 2000, 4000]\n",
    "    np.random.seed(42)\n",
    "    test_statistics2 = []\n",
    "\n",
    "    for m in M:\n",
    "\n",
    "       test_statistics, esperances_2000, variances_2000, msea_2000, mseb_2000 = power_simple(150,m)\n",
    "       test_statistics2.append(test_statistics)\n",
    "\n",
    "    df = pd.DataFrame(test_statistics2)\n",
    "    df = df.transpose()\n",
    "    df.columns = [\"m = 100\", \"m = 150\", \"m = 200\", \"m = 500\", \"m = 1000\", \"m = 2000\", \"m = 4000\"]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "df = comparaison_stats()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"T pour différentes tailles de l'ensemble de test\")\n",
    "plt.plot(beta2_values, df[\"m = 100\"], label = \"m = 100\")\n",
    "plt.plot(beta2_values, df[\"m = 150\"], label = \"m = 150\")\n",
    "plt.plot(beta2_values, df[\"m = 200\"], label = \"m = 200\")\n",
    "plt.plot(beta2_values, df[\"m = 500\"], label = \"m = 500\")\n",
    "plt.plot(beta2_values, df[\"m = 1000\"], label = \"m = 1000\")\n",
    "plt.plot(beta2_values, df[\"m = 2000\"], label = \"m = 2000\")\n",
    "plt.plot(beta2_values, df[\"m = 4000\"], label = \"m = 4000\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparaison de puissances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparaison_puissancess():\n",
    "    M = [100, 150, 200, 500, 1000, 2000, 4000]\n",
    "    np.random.seed(42)\n",
    "    puissances2 = []\n",
    "\n",
    "    for m in M:\n",
    "\n",
    "       puissances, test_statistics, esperances_2000, variances_2000, msea_2000, mseb_2000 = puissance_simple(150,m)\n",
    "       puissances2.append(puissances)\n",
    "\n",
    "    df = pd.DataFrame(puissances2)\n",
    "    df = df.transpose()\n",
    "    df.columns = [\"m = 100\", \"m = 150\", \"m = 200\", \"m = 500\", \"m = 1000\", \"m = 2000\", \"m = 4000\"]\n",
    "\n",
    "    return df\n",
    "\n",
    "df2 = comparaison_puissancess()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Puissance du test pour différentes tailles de l'ensemble de test\")\n",
    "plt.plot(beta2_values, df2[\"m = 100\"], label = \"m = 100\")\n",
    "plt.plot(beta2_values, df2[\"m = 150\"], label = \"m = 150\")\n",
    "plt.plot(beta2_values, df2[\"m = 200\"], label = \"m = 200\")\n",
    "plt.plot(beta2_values, df2[\"m = 500\"], label = \"m = 500\")\n",
    "plt.plot(beta2_values, df2[\"m = 1000\"], label = \"m = 1000\")\n",
    "plt.plot(beta2_values, df2[\"m = 2000\"], label = \"m = 2000\")\n",
    "plt.plot(beta2_values, df2[\"m = 4000\"], label = \"m = 4000\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.plot()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
