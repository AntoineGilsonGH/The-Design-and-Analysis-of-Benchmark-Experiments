{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import scipy.stats as stats\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_antoine = \"/Users/antoine.gilson/Desktop/The-Design-and-Analysis-of-Benchmark-Experiments/Plots/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta2_values = np.linspace(0, 0.16, 9)\n",
    "M = [50,100,150,200,500,1000,2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction, variables, training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_training_test_sets(n=150, m=2000, seed=42):\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    x = np.random.uniform(0, 5, n + m)\n",
    "    x_train = x[:n]\n",
    "    x_test = x[n:n+m]\n",
    "    \n",
    "    epsilon = np.random.normal(0, 1, n + m)\n",
    "    epsilon_train = epsilon[:n]\n",
    "    epsilon_test = epsilon[n:n+m]\n",
    "    \n",
    "    # Création de la figure avec subplots\n",
    "    fig, ax = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    \n",
    "    # Plotting X Training set\n",
    "    ax[0, 0].scatter(np.arange(n), x_train, label=\"X Training set n = 150\", color=\"blue\", s=10)\n",
    "    ax[0, 0].set_title(\"Training Set X\")\n",
    "    ax[0, 0].set_xlabel(\"Index\")\n",
    "    ax[0, 0].set_ylabel(\"Value\")\n",
    "    ax[0, 0].legend()\n",
    "    ax[0, 0].grid()\n",
    "\n",
    "    # Plotting X Test set\n",
    "    ax[0, 1].scatter(np.arange(n, n + m), x_test, label=\"X Test set m = 2000\", color=\"red\", s=10)\n",
    "    ax[0, 1].set_title(\"Test Set X\")\n",
    "    ax[0, 1].set_xlabel(\"Index\")\n",
    "    ax[0, 1].set_ylabel(\"Value\")\n",
    "    ax[0, 1].legend()\n",
    "    ax[0, 1].grid()\n",
    "\n",
    "    # Plotting Epsilon Training set\n",
    "    ax[1, 0].scatter(np.arange(n), epsilon_train, label=\"Epsilon Training set n = 150\", color=\"green\", s=10)\n",
    "    ax[1, 0].set_title(\"Training Set Epsilon\")\n",
    "    ax[1, 0].set_xlabel(\"Index\")\n",
    "    ax[1, 0].set_ylabel(\"Value\")\n",
    "    ax[1, 0].legend()\n",
    "    ax[1, 0].grid()\n",
    "\n",
    "    # Plotting Epsilon Test set\n",
    "    ax[1, 1].scatter(np.arange(n, n + m), epsilon_test, label=\"Epsilon Test set m = 2000\", color=\"orange\", s=10)\n",
    "    ax[1, 1].set_title(\"Test Set Epsilon\")\n",
    "    ax[1, 1].set_xlabel(\"Index\")\n",
    "    ax[1, 1].set_ylabel(\"Value\")\n",
    "    ax[1, 1].legend()\n",
    "    ax[1, 1].grid()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.scatter(np.arange(n), x_train, label = \"X Training set n = 150\", color = \"blue\", s = 8)\n",
    "    plt.scatter(np.arange(n, n+m), x_test, label = \"X Test set m = 2000\", color = \"red\", s = 8)\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.scatter(np.arange(n), epsilon_train, label = \"Eps Training set n = 150\", color = \"green\", s = 8)\n",
    "    plt.scatter(np.arange(n, n+m), epsilon_test, label = \"Eps Test set m = 2000\", color = \"orange\", s = 8)\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective function : y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_objective_function(m):\n",
    "    \n",
    "    n = 150\n",
    "    np.random.seed(42)\n",
    "\n",
    "    beta1 = 2\n",
    "    epsilon = np.random.normal(0, 1, n + m) \n",
    "    x = np.random.uniform(0, 5, n + m)\n",
    "\n",
    "    x_train = x[:n]\n",
    "    x_test = x[n:n+m]\n",
    "\n",
    "    epsilon_train = epsilon[:n]\n",
    "    epsilon_test = epsilon[n:n+m]\n",
    "    \n",
    "    for beta2 in beta2_values:\n",
    "            \n",
    "       y_train = beta1 * x_train + beta2 * x_train**2 + epsilon_train\n",
    "       y_test = beta1 * x_test + beta2 * x_test**2 + epsilon_test\n",
    "\n",
    "       plt.figure()\n",
    "       plt.scatter(np.arange(n), y_train, label = \"Y corresponding to training set n = 150\", color = \"blue\", s = 8)\n",
    "       plt.scatter(np.arange(n, n+m), y_test, label = \"Y corresponding to test set m =\" f\"{m}\", color = \"red\", s = 8)\n",
    "       plt.legend()\n",
    "       plt.grid()\n",
    "       filename = f\"{path_antoine}/Objective/objective_y_m_{m}_beta2_{beta2}.png\"\n",
    "       plt.savefig(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphical approach of model precision and errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_metrics():\n",
    "    \n",
    "    n = 150\n",
    "\n",
    "    M = [50, 100, 150, 200, 500, 1000, 2000]\n",
    "\n",
    "    for m in M:\n",
    "\n",
    "      np.random.seed(42)\n",
    "      beta1 = 2\n",
    "      epsilon = np.random.normal(0, 1, n + m) \n",
    "      x = np.random.uniform(0, 5, n + m)\n",
    "\n",
    "      x_train = x[:n]\n",
    "      x_test = x[n:n+m]\n",
    "\n",
    "      epsilon_train = epsilon[:n]\n",
    "      epsilon_test = epsilon[n:n+m]\n",
    "    \n",
    "      for beta2 in beta2_values:\n",
    "            \n",
    "          y_train = beta1 * x_train + beta2 * x_train**2 + epsilon_train\n",
    "          y_test = beta1 * x_test + beta2 * x_test**2 + epsilon_test\n",
    "\n",
    "           # Linear Model : A\n",
    "          model_a = LinearRegression().fit(x_train.reshape(-1, 1), y_train)\n",
    "          y_pred_a = model_a.predict(x_test.reshape(-1, 1))\n",
    "          pa = (y_test - y_pred_a)**2\n",
    "    \n",
    "          # Quadratic Model : B\n",
    "          x_train_quad = np.column_stack((x_train, x_train**2))\n",
    "          x_test_quad = np.column_stack((x_test, x_test**2))\n",
    "            \n",
    "          model_b = LinearRegression().fit(x_train_quad, y_train)\n",
    "          y_pred_b = model_b.predict(x_test_quad)\n",
    "          pb = (y_test - y_pred_b)**2\n",
    "\n",
    "          differences = pa - pb\n",
    "\n",
    "          plt.figure() # Erreur individuelle des modèles\n",
    "          plt.title(\"Erreurs de prédiction des modèles pour \" f\"beta2 = {beta2}\" \" et pour \"f\"m = {m}\" )  \n",
    "      \n",
    "          plt.scatter(x_test, pb, label = \"pb = (y - yb) pour \" f\"beta2 = {beta2}\" \" et pour \"f\"m = {m}\", color = \"orange\", s = 8)\n",
    "          plt.scatter(x_test, pa, label = \"pa = (y - ya) pour \" f\"beta2 = {beta2}\" \" et pour \"f\"m = {m}\", color = \"red\", s = 8)\n",
    "       \n",
    "          plt.grid()\n",
    "          plt.legend()\n",
    "\n",
    "          filename = f\"{path_antoine}/Erreurs/plot_m_{m}_beta2_{beta2}.png\"\n",
    "          plt.savefig(filename)\n",
    "\n",
    "          plt.show()\n",
    "\n",
    "          plt.figure() # Différence de prédiction des modèles\n",
    "          plt.title(\"Différence de prédiction des modèles pour \" f\"beta2 = {beta2}\" \" et pour \"f\"m = {m}\" )  \n",
    "      \n",
    "          plt.scatter(x_test, differences, label = \"pb = (y - yb) pour \" f\"beta2 = {beta2}\" \" et pour \"f\"m = {m}\", color = \"red\", s = 8)\n",
    "          plt.axhline(y=0, color='black', linestyle='--', label='y = 0')\n",
    "       \n",
    "          plt.grid()\n",
    "          plt.legend()\n",
    "\n",
    "          filename = f\"{path_antoine}/Differences/plot_m_{m}_beta2_{beta2}.png\"\n",
    "          plt.savefig(filename)\n",
    "\n",
    "          plt.show()\n",
    "\n",
    "          plt.figure() # Fits des modèles \n",
    "          plt.title(\"Fits des modèles pour \" f\"beta2 = {beta2}\" \" et pour \"f\"m = {m}\" )  \n",
    "\n",
    "      \n",
    "          plt.scatter(x_test, y_test, label = \"Y réel\", color = \"green\", s = 8)\n",
    "          plt.scatter(x_test, y_pred_a, label = \"Prédiction linéaire pour \" f\"beta2 = {beta2}\" \" et pour \"f\"m = {m}\", color = \"red\", s = 8)\n",
    "          plt.scatter(x_test, y_pred_b, label = \"Prédiction quadratique pour \" f\"beta2 = {beta2}\" \" et pour \"f\"m = {m}\", color = \"orange\", s = 8)\n",
    "       \n",
    "          plt.grid()\n",
    "          plt.legend()\n",
    "\n",
    "          filename = f\"{path_antoine}/Fits/plot_m_{m}_beta2_{beta2}.png\"\n",
    "          plt.savefig(filename)\n",
    "\n",
    "          plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_metrics_2():\n",
    "    \n",
    "    n = 150\n",
    "    M = [50, 100, 150, 200, 500, 1000, 2000]\n",
    "    \n",
    "    for m in M:\n",
    "        np.random.seed(42)\n",
    "        beta1 = 2\n",
    "        epsilon = np.random.normal(0, 1, n + m) \n",
    "        x = np.random.uniform(0, 5, n + m)\n",
    "\n",
    "        x_train = x[:n]\n",
    "        x_test = x[n:n+m]\n",
    "\n",
    "        epsilon_train = epsilon[:n]\n",
    "        epsilon_test = epsilon[n:n+m]\n",
    "    \n",
    "        for beta2 in beta2_values:\n",
    "\n",
    "            y_train = beta1 * x_train + beta2 * x_train**2 + epsilon_train\n",
    "            y_test = beta1 * x_test + beta2 * x_test**2 + epsilon_test\n",
    "\n",
    "            # Linear Model : A\n",
    "            model_a = LinearRegression().fit(x_train.reshape(-1, 1), y_train)\n",
    "            y_pred_a = model_a.predict(x_test.reshape(-1, 1))\n",
    "            pa = (y_test - y_pred_a)**2\n",
    "    \n",
    "            # Quadratic Model : B\n",
    "            x_train_quad = np.column_stack((x_train, x_train**2))\n",
    "            x_test_quad = np.column_stack((x_test, x_test**2))\n",
    "            \n",
    "            model_b = LinearRegression().fit(x_train_quad, y_train)\n",
    "            y_pred_b = model_b.predict(x_test_quad)\n",
    "            pb = (y_test - y_pred_b)**2\n",
    "\n",
    "            differences = pa-pb\n",
    "\n",
    "            # Calcul des quantiles et de la médiane\n",
    "            q1 = np.percentile(differences, 25)\n",
    "            median = np.median(differences)\n",
    "            q3 = np.percentile(differences, 75)\n",
    "\n",
    "            # Création du boxplot\n",
    "            plt.figure(figsize=(10, 6))\n",
    "\n",
    "            plt.scatter(x_test, differences, color='red', label='pa - pb ' f\"beta2 = {beta2}\" \" et pour \"f\"m = {m}\")\n",
    "            plt.axhline(y=0, color='black', linestyle='--', label='y = 0')\n",
    "\n",
    "            plt.boxplot(differences, positions=[max(x_test) + 1], widths=0.5, patch_artist=True,\n",
    "                        boxprops=dict(facecolor='blue', color='blue', alpha=0.5),\n",
    "                        medianprops=dict(color='yellow'),\n",
    "                        whiskerprops=dict(color='blue'),\n",
    "                        capprops=dict(color='blue'),\n",
    "                        flierprops=dict(color='blue', markeredgecolor='blue'))\n",
    "\n",
    "\n",
    "            plt.text(max(x_test) + 1, q1, f'Q1: {q1:.2f}', horizontalalignment='center', color='black')\n",
    "            plt.text(max(x_test) + 1, median, f'Median: {median:.2f}', horizontalalignment='center', color='black')\n",
    "            plt.text(max(x_test) + 1, q3, f'Q3: {q3:.2f}', horizontalalignment='center', color='black')\n",
    "\n",
    "\n",
    "            plt.title('Erreurs de prédiction du modèle quadratique pour ' f\"beta2 = {beta2}\" \" et pour \"f\"m = {m}\")\n",
    "            plt.legend()\n",
    "            plt.grid()\n",
    "            filename = f\"{path_antoine}/Erreurs/plot_m_{m}_beta2_{beta2}.png\"\n",
    "            plt.savefig(filename)\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE():\n",
    "    \n",
    "    n = 150\n",
    "    m = 2000\n",
    "\n",
    "    np.random.seed(42)\n",
    "    beta1 = 2\n",
    "    epsilon = np.random.normal(0, 1, n + m) \n",
    "    x = np.random.uniform(0, 5, n + m)\n",
    "\n",
    "    x_train = x[:n]\n",
    "    x_test = x[n:n+m]\n",
    "\n",
    "    epsilon_train = epsilon[:n]\n",
    "    epsilon_test = epsilon[n:n+m]\n",
    "\n",
    "    mse_A = []\n",
    "    mse_B = []\n",
    "    \n",
    "    for beta2 in beta2_values:\n",
    "            \n",
    "        y_train = beta1 * x_train + beta2 * x_train**2 + epsilon_train\n",
    "        y_test = beta1 * x_test + beta2 * x_test**2 + epsilon_test\n",
    "\n",
    "         # Linear Model : A\n",
    "        model_a = LinearRegression().fit(x_train.reshape(-1, 1), y_train)\n",
    "        y_pred_a = model_a.predict(x_test.reshape(-1, 1))\n",
    "\n",
    "        mse_A.append(mean_squared_error(y_pred_a, y_test))\n",
    "    \n",
    "          # Quadratic Model : B\n",
    "        x_train_quad = np.column_stack((x_train, x_train**2))\n",
    "        x_test_quad = np.column_stack((x_test, x_test**2))\n",
    "            \n",
    "        model_b = LinearRegression().fit(x_train_quad, y_train)\n",
    "        y_pred_b = model_b.predict(x_test_quad)\n",
    "        mse_B.append(mean_squared_error(y_pred_b, y_test))\n",
    "\n",
    "    plt.figure()\n",
    "    plt.title(\"Différence des MSE\")\n",
    "    plt.plot(beta2_values, mse_A, label = \"MSE_A\")\n",
    "    plt.plot(beta2_values, mse_B, label = \"MSE_B\")\n",
    "       \n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descriptive_statistics():\n",
    "    \n",
    "    n = 150\n",
    "\n",
    "    M = [50, 100, 150, 200, 500, 1000, 2000]\n",
    "\n",
    "    empirical_means_A = []\n",
    "    standard_deviations_A = []\n",
    "    medians_A = []\n",
    "    Q1_A = []\n",
    "    Q3_A = []\n",
    "    IQR_A = []\n",
    "\n",
    "    empirical_means_B = []\n",
    "    standard_deviations_B = []\n",
    "    medians_B = []\n",
    "    Q1_B = []\n",
    "    Q3_B = []\n",
    "    IQR_B = []\n",
    "\n",
    "    for m in M:\n",
    "\n",
    "      a = []\n",
    "      b = []\n",
    "      c = []\n",
    "      d = []\n",
    "      q = []\n",
    "      iqr = []\n",
    "\n",
    "      e = []\n",
    "      f = []\n",
    "      g = []\n",
    "      h = []\n",
    "      q_ = []\n",
    "      iqr_ = []\n",
    "\n",
    "\n",
    "      np.random.seed(42)\n",
    "      beta1 = 2\n",
    "      beta2_values_bis = [0.2, 0.3, 0.4, 0.5, 1]\n",
    "      epsilon = np.random.normal(0, 1, n + m) \n",
    "      x = np.random.uniform(0, 5, n + m)\n",
    "\n",
    "      x_train = x[:n]\n",
    "      x_test = x[n:n+m]\n",
    "\n",
    "      epsilon_train = epsilon[:n]\n",
    "      epsilon_test = epsilon[n:n+m]\n",
    "    \n",
    "      for beta2 in beta2_values:\n",
    "            \n",
    "          y_train = beta1 * x_train + beta2 * x_train**2 + epsilon_train\n",
    "          y_test = beta1 * x_test + beta2 * x_test**2 + epsilon_test\n",
    "\n",
    "        # Linear Model : A\n",
    "          model_a = LinearRegression().fit(x_train.reshape(-1, 1), y_train)\n",
    "          y_pred_a = model_a.predict(x_test.reshape(-1, 1))\n",
    "          pa = (y_test - y_pred_a)**2\n",
    "    \n",
    "        # Quadratic Model : B\n",
    "          x_train_quad = np.column_stack((x_train, x_train**2))\n",
    "          x_test_quad = np.column_stack((x_test, x_test**2))\n",
    "            \n",
    "          model_b = LinearRegression().fit(x_train_quad, y_train)\n",
    "          y_pred_b = model_b.predict(x_test_quad)\n",
    "          pb = (y_test - y_pred_b)**2\n",
    "\n",
    "          mean_a = sum(pa)/m\n",
    "          mean_b = sum(pb)/m\n",
    "\n",
    "          a.append(mean_a)\n",
    "          e.append(mean_b)\n",
    "\n",
    "          std_a = np.std(pa, ddof=1)\n",
    "          std_b = np.std(pb, ddof = 1)\n",
    "\n",
    "          b.append(std_a)\n",
    "          f.append(std_b)\n",
    "\n",
    "          q1_a = np.percentile(pa, 25)\n",
    "          med_a = np.percentile(pa, 50)        \n",
    "          q3_a = np.percentile(pa, 75)\n",
    "\n",
    "          q1_b = np.percentile(pb, 25)\n",
    "          med_b = np.percentile(pb, 50)        \n",
    "          q3_b = np.percentile(pb, 75)\n",
    "\n",
    "          c.append(med_a)\n",
    "          g.append(med_b)\n",
    "          d.append(q1_a)\n",
    "          q.append(q3_a)\n",
    "          h.append(q1_b)\n",
    "          q_.append(q3_b)\n",
    "\n",
    "          iqr.append(q3_a - q1_a)\n",
    "          iqr_.append(q3_b - q1_b)\n",
    "\n",
    "      empirical_means_A.append(a)\n",
    "      empirical_means_B.append(e)\n",
    "      standard_deviations_A.append(b)\n",
    "      standard_deviations_B.append(f)\n",
    "      medians_A.append(c)\n",
    "      medians_B.append(g)\n",
    "      Q1_A.append(d)\n",
    "      Q1_B.append(h)\n",
    "      Q3_A.append(q)\n",
    "      Q3_B.append(q_)\n",
    "      IQR_A.append(iqr)\n",
    "      IQR_B.append(iqr_)\n",
    "\n",
    "    return empirical_means_A, standard_deviations_A, medians_A, Q1_A, Q3_A, IQR_A, empirical_means_B, standard_deviations_B, medians_B, Q1_B, Q3_B, IQR_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nempirical_means_A, standard_deviations_A, medians_A, Q1_A, Q3_A, IQR_A, empirical_means_B, standard_deviations_B, medians_B, Q1_B, Q3_B, IQR_B = descriptive_statistics()\\n'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "empirical_means_A, standard_deviations_A, medians_A, Q1_A, Q3_A, IQR_A, empirical_means_B, standard_deviations_B, medians_B, Q1_B, Q3_B, IQR_B = descriptive_statistics()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data():\n",
    "    \n",
    "    M = [50, 100, 150, 200, 500, 1000, 2000]\n",
    "    \n",
    "    empirical_means_A, standard_deviations_A, medians_A, Q1_A, Q3_A, IQR_A, empirical_means_B, standard_deviations_B, medians_B, Q1_B, Q3_B, IQR_B = descriptive_statistics()\n",
    "    \n",
    "    \n",
    "    data_A_all = {\n",
    "    \"Empirical Mean\": empirical_means_A,\n",
    "    \"Standard Deviation\": standard_deviations_A,\n",
    "    \"Median\": medians_A,\n",
    "    \"Q1\": Q1_A,\n",
    "    \"Q3\": Q3_A,\n",
    "    \"IQR\": IQR_A\n",
    "   }\n",
    "\n",
    "    stats_A_all = pd.DataFrame(data_A_all, index=M)\n",
    "\n",
    "    data_B_all = {\n",
    "    \"Empirical Mean\": empirical_means_B,\n",
    "    \"Standard Deviation\": standard_deviations_B,\n",
    "    \"Median\": medians_B,\n",
    "    \"Q1\": Q1_B,\n",
    "    \"Q3\": Q3_B,\n",
    "    \"IQR\": IQR_B\n",
    "   }\n",
    "\n",
    "    stats_B_all = pd.DataFrame(data_B_all, index=M)\n",
    "\n",
    "    df_empirical_means_A = pd.DataFrame(empirical_means_A, index=M, columns=beta2_values).transpose()\n",
    "    df_empirical_standard_deviations_A = pd.DataFrame(standard_deviations_A, index=M, columns=beta2_values).transpose()\n",
    "    df_medians_A = pd.DataFrame(medians_A, index=M, columns=beta2_values).transpose()\n",
    "    df_Q1_A = pd.DataFrame(Q1_A, index=M, columns=beta2_values).transpose()\n",
    "    df_Q3_A = pd.DataFrame(Q3_A, index=M, columns=beta2_values).transpose()\n",
    "    df_IQR_A = pd.DataFrame(IQR_A, index=M, columns=beta2_values).transpose()\n",
    "\n",
    "    df_empirical_means_B = pd.DataFrame(empirical_means_B, index=M, columns=beta2_values).transpose()\n",
    "    df_empirical_standard_deviations_B = pd.DataFrame(standard_deviations_B, index=M, columns=beta2_values).transpose()\n",
    "    df_medians_B = pd.DataFrame(medians_B, index=M, columns=beta2_values).transpose()\n",
    "    df_Q1_B = pd.DataFrame(Q1_B, index=M, columns=beta2_values).transpose()\n",
    "    df_Q3_B = pd.DataFrame(Q3_B, index=M, columns=beta2_values).transpose()\n",
    "    df_IQR_B = pd.DataFrame(IQR_B, index=M, columns=beta2_values).transpose()    \n",
    "\n",
    "    return stats_A_all, df_empirical_means_A, df_empirical_standard_deviations_A, df_medians_A, df_Q1_A, df_Q3_A, df_IQR_A, \\\n",
    "    stats_B_all, df_empirical_means_B, df_empirical_standard_deviations_B, df_medians_B, df_Q1_B, df_Q3_B, df_IQR_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\n(stats_A_all, df_empirical_means_A, df_empirical_standard_deviations_A, df_medians_A, df_Q1_A, df_Q3_A, df_IQR_A, \\n    stats_B_all, df_empirical_means_B, df_empirical_standard_deviations_B, df_medians_B, df_Q1_B, df_Q3_B, df_IQR_B) = create_data()\\n\\n'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" \n",
    "(stats_A_all, df_empirical_means_A, df_empirical_standard_deviations_A, df_medians_A, df_Q1_A, df_Q3_A, df_IQR_A, \n",
    "    stats_B_all, df_empirical_means_B, df_empirical_standard_deviations_B, df_medians_B, df_Q1_B, df_Q3_B, df_IQR_B) = create_data()\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inferential statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already have the standard error of the mean (according to m and beta2), that gives us a first information of the precisation of mA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Derive formulas (or algorithms) for the standard error (SE) of the mean\n",
    "\n",
    "Methods: \n",
    "- parametric estimates (consider different cases when n is small versus large and when VA is assumed to be Gaussian or not)\n",
    "- bootstrap estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Parametric estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### when n is large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>50</th>\n",
       "      <th>100</th>\n",
       "      <th>150</th>\n",
       "      <th>200</th>\n",
       "      <th>500</th>\n",
       "      <th>1000</th>\n",
       "      <th>2000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.00</th>\n",
       "      <td>0.108307</td>\n",
       "      <td>0.158772</td>\n",
       "      <td>0.153919</td>\n",
       "      <td>0.135794</td>\n",
       "      <td>0.123666</td>\n",
       "      <td>0.117376</td>\n",
       "      <td>0.118897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.02</th>\n",
       "      <td>0.107108</td>\n",
       "      <td>0.162813</td>\n",
       "      <td>0.152160</td>\n",
       "      <td>0.135294</td>\n",
       "      <td>0.123638</td>\n",
       "      <td>0.118496</td>\n",
       "      <td>0.119130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.04</th>\n",
       "      <td>0.106237</td>\n",
       "      <td>0.167218</td>\n",
       "      <td>0.150613</td>\n",
       "      <td>0.135050</td>\n",
       "      <td>0.123969</td>\n",
       "      <td>0.119958</td>\n",
       "      <td>0.119716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.06</th>\n",
       "      <td>0.105706</td>\n",
       "      <td>0.171974</td>\n",
       "      <td>0.149281</td>\n",
       "      <td>0.135065</td>\n",
       "      <td>0.124653</td>\n",
       "      <td>0.121761</td>\n",
       "      <td>0.120656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.08</th>\n",
       "      <td>0.105527</td>\n",
       "      <td>0.177070</td>\n",
       "      <td>0.148172</td>\n",
       "      <td>0.135342</td>\n",
       "      <td>0.125685</td>\n",
       "      <td>0.123903</td>\n",
       "      <td>0.121949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.10</th>\n",
       "      <td>0.105711</td>\n",
       "      <td>0.182494</td>\n",
       "      <td>0.147292</td>\n",
       "      <td>0.135883</td>\n",
       "      <td>0.127057</td>\n",
       "      <td>0.126382</td>\n",
       "      <td>0.123592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.12</th>\n",
       "      <td>0.106264</td>\n",
       "      <td>0.188234</td>\n",
       "      <td>0.146647</td>\n",
       "      <td>0.136690</td>\n",
       "      <td>0.128766</td>\n",
       "      <td>0.129194</td>\n",
       "      <td>0.125580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.14</th>\n",
       "      <td>0.107195</td>\n",
       "      <td>0.194280</td>\n",
       "      <td>0.146242</td>\n",
       "      <td>0.137764</td>\n",
       "      <td>0.130803</td>\n",
       "      <td>0.132337</td>\n",
       "      <td>0.127907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.16</th>\n",
       "      <td>0.108504</td>\n",
       "      <td>0.200622</td>\n",
       "      <td>0.146083</td>\n",
       "      <td>0.139103</td>\n",
       "      <td>0.133165</td>\n",
       "      <td>0.135807</td>\n",
       "      <td>0.130567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          50        100       150       200       500       1000      2000\n",
       "0.00  0.108307  0.158772  0.153919  0.135794  0.123666  0.117376  0.118897\n",
       "0.02  0.107108  0.162813  0.152160  0.135294  0.123638  0.118496  0.119130\n",
       "0.04  0.106237  0.167218  0.150613  0.135050  0.123969  0.119958  0.119716\n",
       "0.06  0.105706  0.171974  0.149281  0.135065  0.124653  0.121761  0.120656\n",
       "0.08  0.105527  0.177070  0.148172  0.135342  0.125685  0.123903  0.121949\n",
       "0.10  0.105711  0.182494  0.147292  0.135883  0.127057  0.126382  0.123592\n",
       "0.12  0.106264  0.188234  0.146647  0.136690  0.128766  0.129194  0.125580\n",
       "0.14  0.107195  0.194280  0.146242  0.137764  0.130803  0.132337  0.127907\n",
       "0.16  0.108504  0.200622  0.146083  0.139103  0.133165  0.135807  0.130567"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def standard_error_n_large():\n",
    "\n",
    "    n = 150\n",
    "\n",
    "    (stats_A_all, df_empirical_means_A, df_empirical_standard_deviations_A, df_medians_A, df_Q1_A, df_Q3_A, df_IQR_A, \n",
    "    stats_B_all, df_empirical_means_B, df_empirical_standard_deviations_B, df_medians_B, df_Q1_B, df_Q3_B, df_IQR_B) = create_data()\n",
    "\n",
    "    n_sqrt = np.sqrt(n)\n",
    "    df_standard_error_A = df_empirical_standard_deviations_A.apply(lambda x: x / n_sqrt)\n",
    "    df_standard_error_B = df_empirical_standard_deviations_B.apply(lambda x: x / n_sqrt)\n",
    "\n",
    "    return df_standard_error_A, df_standard_error_B\n",
    "\n",
    "\n",
    "df_standard_error_A, df_standard_error_B = standard_error_n_large()\n",
    "df_standard_error_A\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### when n is small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>50</th>\n",
       "      <th>100</th>\n",
       "      <th>150</th>\n",
       "      <th>200</th>\n",
       "      <th>500</th>\n",
       "      <th>1000</th>\n",
       "      <th>2000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.00</th>\n",
       "      <td>0.411982</td>\n",
       "      <td>0.603945</td>\n",
       "      <td>0.585483</td>\n",
       "      <td>0.516539</td>\n",
       "      <td>0.470407</td>\n",
       "      <td>0.446481</td>\n",
       "      <td>0.452267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.02</th>\n",
       "      <td>0.407424</td>\n",
       "      <td>0.619315</td>\n",
       "      <td>0.578795</td>\n",
       "      <td>0.514638</td>\n",
       "      <td>0.470301</td>\n",
       "      <td>0.450741</td>\n",
       "      <td>0.453151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.04</th>\n",
       "      <td>0.404110</td>\n",
       "      <td>0.636070</td>\n",
       "      <td>0.572907</td>\n",
       "      <td>0.513709</td>\n",
       "      <td>0.471560</td>\n",
       "      <td>0.456301</td>\n",
       "      <td>0.455380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.06</th>\n",
       "      <td>0.402090</td>\n",
       "      <td>0.654164</td>\n",
       "      <td>0.567842</td>\n",
       "      <td>0.513765</td>\n",
       "      <td>0.474161</td>\n",
       "      <td>0.463159</td>\n",
       "      <td>0.458956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.08</th>\n",
       "      <td>0.401409</td>\n",
       "      <td>0.673548</td>\n",
       "      <td>0.563625</td>\n",
       "      <td>0.514819</td>\n",
       "      <td>0.478084</td>\n",
       "      <td>0.471307</td>\n",
       "      <td>0.463875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.10</th>\n",
       "      <td>0.402107</td>\n",
       "      <td>0.694179</td>\n",
       "      <td>0.560277</td>\n",
       "      <td>0.516878</td>\n",
       "      <td>0.483306</td>\n",
       "      <td>0.480736</td>\n",
       "      <td>0.470123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.12</th>\n",
       "      <td>0.404213</td>\n",
       "      <td>0.716012</td>\n",
       "      <td>0.557823</td>\n",
       "      <td>0.519948</td>\n",
       "      <td>0.489804</td>\n",
       "      <td>0.491435</td>\n",
       "      <td>0.477686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.14</th>\n",
       "      <td>0.407751</td>\n",
       "      <td>0.739010</td>\n",
       "      <td>0.556282</td>\n",
       "      <td>0.524031</td>\n",
       "      <td>0.497556</td>\n",
       "      <td>0.503390</td>\n",
       "      <td>0.486539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.16</th>\n",
       "      <td>0.412734</td>\n",
       "      <td>0.763136</td>\n",
       "      <td>0.555677</td>\n",
       "      <td>0.529126</td>\n",
       "      <td>0.506540</td>\n",
       "      <td>0.516587</td>\n",
       "      <td>0.496658</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          50        100       150       200       500       1000      2000\n",
       "0.00  0.411982  0.603945  0.585483  0.516539  0.470407  0.446481  0.452267\n",
       "0.02  0.407424  0.619315  0.578795  0.514638  0.470301  0.450741  0.453151\n",
       "0.04  0.404110  0.636070  0.572907  0.513709  0.471560  0.456301  0.455380\n",
       "0.06  0.402090  0.654164  0.567842  0.513765  0.474161  0.463159  0.458956\n",
       "0.08  0.401409  0.673548  0.563625  0.514819  0.478084  0.471307  0.463875\n",
       "0.10  0.402107  0.694179  0.560277  0.516878  0.483306  0.480736  0.470123\n",
       "0.12  0.404213  0.716012  0.557823  0.519948  0.489804  0.491435  0.477686\n",
       "0.14  0.407751  0.739010  0.556282  0.524031  0.497556  0.503390  0.486539\n",
       "0.16  0.412734  0.763136  0.555677  0.529126  0.506540  0.516587  0.496658"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def standard_error_n_small():\n",
    "    n = 30\n",
    "    confidence_level = 0.95\n",
    "    df = n - 1\n",
    "    \n",
    "    (stats_A_all, df_empirical_means_A, df_empirical_standard_deviations_A, df_medians_A, df_Q1_A, df_Q3_A, df_IQR_A, \n",
    "     stats_B_all, df_empirical_means_B, df_empirical_standard_deviations_B, df_medians_B, df_Q1_B, df_Q3_B, df_IQR_B) = create_data()\n",
    "    \n",
    "    n_sqrt = np.sqrt(n)\n",
    "    student = stats.t.ppf(confidence_level, df - 1)\n",
    "    df_standard_error_small_A = df_empirical_standard_deviations_A.apply(lambda x: x*student / n_sqrt)\n",
    "    df_standard_error_small_B = df_empirical_standard_deviations_B.apply(lambda x: x*student / n_sqrt)\n",
    "\n",
    "    return df_standard_error_small_A, df_standard_error_small_B\n",
    "\n",
    "\n",
    "df_standard_error_small_A, df_standard_error_small_B = standard_error_n_small()\n",
    "df_standard_error_small_A\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 / Non parametric estimates - Bootstrap estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bootstrap on test sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap estimate : sur l'ensemble de test\n",
    "\n",
    "def standard_error_bootstrap_test():\n",
    "   \n",
    "   n = 150\n",
    "   np.random.seed(42)\n",
    "\n",
    "   M = [50, 100, 150, 200, 500, 1000, 2000]\n",
    "\n",
    "   se_bootstrap_A = []\n",
    "   se_bootstrap_B = []\n",
    "\n",
    "   for m in M:\n",
    "   \n",
    "      liste_A = []\n",
    "      liste_B = []\n",
    "\n",
    "   \n",
    "      beta1 = 2\n",
    "      epsilon = np.random.normal(0, 1, n + m) \n",
    "      x = np.random.uniform(0, 5, n + m)\n",
    "\n",
    "      x_train = x[:n]\n",
    "      x_test = x[n:n+m]\n",
    "\n",
    "      epsilon_train = epsilon[:n]\n",
    "      epsilon_test = epsilon[n:n+m]\n",
    "    \n",
    "      for beta2 in beta2_values:\n",
    "            \n",
    "          y_train = beta1 * x_train + beta2 * x_train**2 + epsilon_train\n",
    "          y_test = beta1 * x_test + beta2 * x_test**2 + epsilon_test\n",
    "\n",
    "        # Linear Model : A\n",
    "          model_a = LinearRegression().fit(x_train.reshape(-1, 1), y_train)\n",
    "          y_pred_a = model_a.predict(x_test.reshape(-1, 1))\n",
    "          pa = (y_test - y_pred_a)**2\n",
    "    \n",
    "        # Quadratic Model : B\n",
    "          x_train_quad = np.column_stack((x_train, x_train**2))\n",
    "          x_test_quad = np.column_stack((x_test, x_test**2))\n",
    "            \n",
    "          model_b = LinearRegression().fit(x_train_quad, y_train)\n",
    "          y_pred_b = model_b.predict(x_test_quad)\n",
    "          pb = (y_test - y_pred_b)**2\n",
    "       \n",
    "          B = 1000\n",
    "          bootstrap_means = np.zeros(B)\n",
    "\n",
    "          for i in range(B):\n",
    "          \n",
    "             sample_indices = np.random.choice(np.arange(m), size=m, replace=True)\n",
    "             bootstrap_sample = pa[sample_indices]\n",
    "             bootstrap_means[i] = np.mean(bootstrap_sample)\n",
    "\n",
    "          std_bootstrap_A_i = np.std(bootstrap_means)\n",
    "\n",
    "          liste_A.append(std_bootstrap_A_i)\n",
    "\n",
    "          for i in range(B):\n",
    "          \n",
    "             sample_indices = np.random.choice(np.arange(m), size=m, replace=True)\n",
    "             bootstrap_sample = pb[sample_indices]\n",
    "             bootstrap_means[i] = np.mean(bootstrap_sample)\n",
    "\n",
    "          std_bootstrap_B_i = np.std(bootstrap_means)\n",
    "\n",
    "          liste_B.append(std_bootstrap_B_i)\n",
    "    \n",
    "      se_bootstrap_A.append(liste_A)\n",
    "      se_bootstrap_B.append(liste_B)\n",
    "\n",
    "   df_se_bootstrap_A = pd.DataFrame(se_bootstrap_A, index=M, columns=beta2_values).transpose()\n",
    "   df_se_bootstrap_B = pd.DataFrame(se_bootstrap_B, index=M, columns=beta2_values).transpose()\n",
    "\n",
    "   return df_se_bootstrap_A, df_se_bootstrap_B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bootstrap on train sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def se_each_bootstrap(n, B, m):\n",
    "\n",
    "    np.random.seed(42)\n",
    "\n",
    "    se_bootstrap_A = []\n",
    "    se_bootstrap_B = []\n",
    "\n",
    "    beta1 = 2\n",
    "    B = 250\n",
    "    epsilon = np.random.normal(0, 1, n + m) \n",
    "    x = np.random.uniform(0, 5, n + m)\n",
    "\n",
    "    x_train = x[:n]\n",
    "    x_test = x[n:n+m]\n",
    "\n",
    "    epsilon_train = epsilon[:n]\n",
    "    epsilon_test = epsilon[n:n+m]\n",
    "\n",
    "    bootstrap_indices = np.random.choice(n, size=(B, n), replace=True) # bootstrapping\n",
    "    \n",
    "    for beta2 in beta2_values:\n",
    "\n",
    "        liste_A = []\n",
    "        liste_B = []\n",
    "\n",
    "        for bootstrap_index in bootstrap_indices:\n",
    "       \n",
    "           x_train = x[bootstrap_index]\n",
    "           y_train = beta1 * x_train + beta2 * x_train**2 + epsilon[bootstrap_index]\n",
    "      \n",
    "           y_train = beta1 * x_train + beta2 * x_train**2 + epsilon_train\n",
    "           y_test = beta1 * x_test + beta2 * x_test**2 + epsilon_test\n",
    "\n",
    "           model_a = LinearRegression().fit(x_train.reshape(-1, 1), y_train)\n",
    "           y_pred_a = model_a.predict(x_test.reshape(-1, 1))\n",
    "           pa = (y_test - y_pred_a)**2\n",
    "\n",
    "           x_train_quad = np.column_stack((x_train, x_train**2))\n",
    "           x_test_quad = np.column_stack((x_test, x_test**2))\n",
    "\n",
    "           model_b = LinearRegression().fit(x_train_quad, y_train)\n",
    "           y_pred_b = model_b.predict(x_test_quad)\n",
    "           pb = (y_test - y_pred_b)**2\n",
    "\n",
    "           sea = np.std(pa, ddof=1) / (m**0.5)\n",
    "           seb = np.std(pb, ddof = 1) / (m**0.5)\n",
    "\n",
    "           liste_A.append(sea)\n",
    "           liste_B.append(seb)\n",
    "\n",
    "        se_bootstrap_A.append(sum(liste_A)/B)\n",
    "        se_bootstrap_B.append(sum(liste_B)/B)\n",
    "    \n",
    "    return se_bootstrap_A, se_bootstrap_B     \n",
    "\n",
    "\n",
    "def standard_error_bootstrap_train():\n",
    "\n",
    "   M = [50, 100, 150, 200, 500, 1000, 2000]\n",
    "\n",
    "   liste_se_bootstrap_A = []\n",
    "   liste_se_bootstrap_B = []\n",
    "\n",
    "   for m in M:\n",
    "\n",
    "      se_bootstrap_A, se_bootstrap_B = se_each_bootstrap(150,250,m)\n",
    "\n",
    "      liste_se_bootstrap_A.append(se_bootstrap_A)\n",
    "      liste_se_bootstrap_B.append(se_bootstrap_B)\n",
    "\n",
    "   df_se_bootstrap_A_v2 = pd.DataFrame(liste_se_bootstrap_A, index=M, columns=beta2_values).transpose()\n",
    "   df_se_bootstrap_B_v2 = pd.DataFrame(liste_se_bootstrap_B, index=M, columns=beta2_values).transpose()\n",
    "\n",
    "   return df_se_bootstrap_A_v2, df_se_bootstrap_B_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_se_bootstrap_A_v2, df_se_bootstrap_B_v2 = standard_error_bootstrap_train()\n",
    "df_se_bootstrap_A, df_se_bootstrap_B = standard_error_bootstrap_test()\n",
    "df_standard_error_A, df_standard_error_B = standard_error_n_large()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef standard_error_varying_test(k):\\n\\n'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def standard_error_varying_test(k):\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confidence interval of the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>50</th>\n",
       "      <th>100</th>\n",
       "      <th>150</th>\n",
       "      <th>200</th>\n",
       "      <th>500</th>\n",
       "      <th>1000</th>\n",
       "      <th>2000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.00</th>\n",
       "      <td>0.818757</td>\n",
       "      <td>1.017362</td>\n",
       "      <td>1.068112</td>\n",
       "      <td>0.946084</td>\n",
       "      <td>0.998206</td>\n",
       "      <td>0.989027</td>\n",
       "      <td>1.001446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.02</th>\n",
       "      <td>0.807679</td>\n",
       "      <td>1.039631</td>\n",
       "      <td>1.066514</td>\n",
       "      <td>0.943095</td>\n",
       "      <td>0.996299</td>\n",
       "      <td>0.995650</td>\n",
       "      <td>1.002097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.04</th>\n",
       "      <td>0.799399</td>\n",
       "      <td>1.065438</td>\n",
       "      <td>1.067658</td>\n",
       "      <td>0.942545</td>\n",
       "      <td>0.997513</td>\n",
       "      <td>1.005144</td>\n",
       "      <td>1.005558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.06</th>\n",
       "      <td>0.793918</td>\n",
       "      <td>1.094783</td>\n",
       "      <td>1.071546</td>\n",
       "      <td>0.944434</td>\n",
       "      <td>1.001848</td>\n",
       "      <td>1.017509</td>\n",
       "      <td>1.011829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.08</th>\n",
       "      <td>0.791235</td>\n",
       "      <td>1.127668</td>\n",
       "      <td>1.078176</td>\n",
       "      <td>0.948763</td>\n",
       "      <td>1.009303</td>\n",
       "      <td>1.032746</td>\n",
       "      <td>1.020910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.10</th>\n",
       "      <td>0.791350</td>\n",
       "      <td>1.164091</td>\n",
       "      <td>1.087549</td>\n",
       "      <td>0.955531</td>\n",
       "      <td>1.019879</td>\n",
       "      <td>1.050853</td>\n",
       "      <td>1.032802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.12</th>\n",
       "      <td>0.794263</td>\n",
       "      <td>1.204052</td>\n",
       "      <td>1.099665</td>\n",
       "      <td>0.964738</td>\n",
       "      <td>1.033576</td>\n",
       "      <td>1.071832</td>\n",
       "      <td>1.047503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.14</th>\n",
       "      <td>0.799975</td>\n",
       "      <td>1.247552</td>\n",
       "      <td>1.114524</td>\n",
       "      <td>0.976384</td>\n",
       "      <td>1.050393</td>\n",
       "      <td>1.095683</td>\n",
       "      <td>1.065015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.16</th>\n",
       "      <td>0.808484</td>\n",
       "      <td>1.294591</td>\n",
       "      <td>1.132126</td>\n",
       "      <td>0.990469</td>\n",
       "      <td>1.070331</td>\n",
       "      <td>1.122404</td>\n",
       "      <td>1.085336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          50        100       150       200       500       1000      2000\n",
       "0.00  0.818757  1.017362  1.068112  0.946084  0.998206  0.989027  1.001446\n",
       "0.02  0.807679  1.039631  1.066514  0.943095  0.996299  0.995650  1.002097\n",
       "0.04  0.799399  1.065438  1.067658  0.942545  0.997513  1.005144  1.005558\n",
       "0.06  0.793918  1.094783  1.071546  0.944434  1.001848  1.017509  1.011829\n",
       "0.08  0.791235  1.127668  1.078176  0.948763  1.009303  1.032746  1.020910\n",
       "0.10  0.791350  1.164091  1.087549  0.955531  1.019879  1.050853  1.032802\n",
       "0.12  0.794263  1.204052  1.099665  0.964738  1.033576  1.071832  1.047503\n",
       "0.14  0.799975  1.247552  1.114524  0.976384  1.050393  1.095683  1.065015\n",
       "0.16  0.808484  1.294591  1.132126  0.990469  1.070331  1.122404  1.085336"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "    alpha = 0.05\n",
    "    n = 150\n",
    "    \n",
    "\n",
    "    (stats_A_all, df_empirical_means_A, df_empirical_standard_deviations_A, df_medians_A, df_Q1_A, df_Q3_A, df_IQR_A, \n",
    "     stats_B_all, df_empirical_means_B, df_empirical_standard_deviations_B, df_medians_B, df_Q1_B, df_Q3_B, df_IQR_B) = create_data()\n",
    "    \n",
    "    df_standard_error_A, df_standard_error_B = standard_error_n_large()\n",
    "\n",
    "    t_critical = stats.t.ppf(1 - alpha / 2, n - 1)\n",
    "\n",
    "    CI_lower_A = df_empirical_means_A - t_critical * df_standard_error_A\n",
    "    CI_lower_B = df_empirical_means_B - t_critical * df_standard_error_B\n",
    "    CI_upper_A = df_empirical_means_A + t_critical * df_standard_error_A\n",
    "    CI_upper_B = df_empirical_means_B + t_critical * df_standard_error_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    return confidence_intervals_A, confidence_intervals_B\n",
    "\n",
    "confidence_intervals_A, confidence_intervals_B = confidence_interval_mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
