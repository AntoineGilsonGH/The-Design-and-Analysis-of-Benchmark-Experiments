{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.5724\n",
      "MSE2: 0.4743\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Génération de données synthétiques\n",
    "np.random.seed(42)\n",
    "n = 150\n",
    "beta1 = 2\n",
    "x = np.random.uniform(0, 5, n)\n",
    "epsilon = np.random.normal(0, 1, n)\n",
    "beta2 =  0.16\n",
    "y = beta1 * x + beta2 * x**2 + epsilon\n",
    "\n",
    "x_reshape = x.reshape(-1, 1)\n",
    "\n",
    "# Division des données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_reshape, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Modèle d'entraînement\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Évaluation du modèle\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"MSE: {mse:.4f}\")\n",
    "\n",
    "\n",
    "x_train_quad = np.column_stack((X_train, X_train**2))\n",
    "model_a2 = LinearRegression().fit(x_train_quad, y_train)\n",
    "x_test_quad = np.column_stack((X_test, X_test**2))\n",
    "y_pred_a2 = model_a2.predict(x_test_quad)\n",
    "mse2 = mean_squared_error(y_test, y_pred_a2)\n",
    "print(f\"MSE2: {mse2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap MSE: 0.5969 ± 0.0610\n",
      "Bootstrap MSE2: 19.7870 ± 3.8311\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# Données de compétition\n",
    "np.random.seed(42)\n",
    "n = 150\n",
    "beta1 = 2\n",
    "x = np.random.uniform(0, 5, n)\n",
    "epsilon = np.random.normal(0, 1, n)\n",
    "beta2 =  0.16\n",
    "y = beta1 * x + beta2 * x**2 + epsilon\n",
    "\n",
    "x_reshape = x.reshape(-1, 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_reshape, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Bootstrapping\n",
    "n_bootstraps = 1000\n",
    "bootstrap_scores = []\n",
    "bootstrap_scores2 = []\n",
    "\n",
    "for _ in range(n_bootstraps):\n",
    "    X_resampled, y_resampled = resample(X_train, y_train)\n",
    "\n",
    "    model.fit(X_resampled, y_resampled)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    bootstrap_scores.append(mse)\n",
    "\n",
    "    x_train_quad = np.column_stack((X_resampled, X_resampled**2))\n",
    "    x_test_quad = np.column_stack((X_test, X_test**2))\n",
    "\n",
    "    model_a2 = LinearRegression().fit(x_train_quad, y_train)\n",
    "    y_pred_a2 = model_a2.predict(x_test_quad)\n",
    "    mse2 = mean_squared_error(y_test, y_pred_a2)\n",
    "    bootstrap_scores2.append(mse2)\n",
    "\n",
    "mean_mse = np.mean(bootstrap_scores)\n",
    "std_mse = np.std(bootstrap_scores)\n",
    "mean_mse2 = np.mean(bootstrap_scores2)\n",
    "std_mse2 = np.std(bootstrap_scores2)\n",
    "print(f\"Bootstrap MSE: {mean_mse:.4f} ± {std_mse:.4f}\")\n",
    "print(f\"Bootstrap MSE2: {mean_mse2:.4f} ± {std_mse2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real World"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[1.87270059 4.75357153 3.65996971 2.99329242 0.7800932  0.7799726\n 0.29041806 4.33088073 3.00557506 3.54036289 0.10292247 4.84954926\n 4.1622132  1.06169555 0.90912484 0.91702255 1.52121121 2.62378216\n 2.15972509 1.4561457  3.05926447 0.6974693  1.46072324 1.83180922\n 2.28034992 3.92587981 0.99836891 2.57117219 2.96207284 0.23225206\n 3.03772426 0.85262062 0.32525796 4.74442769 4.82816017 4.04198674\n 1.52306885 0.48836057 3.42116513 2.20076247 0.61019117 2.47588455\n 0.17194261 4.54660201 1.29389991 3.31261142 1.55855538 2.60034011\n 2.7335514  0.92427228 4.84792314 3.87566412 4.69749471 4.47413675\n 2.98949989 4.60937118 0.44246251 0.97991431 0.22613644 1.62665165\n 1.94338645 1.35674516 4.14368755 1.78376663 1.40467255 2.71348042\n 0.70462112 4.0109849  0.37275322 4.93443468 3.86122385 0.99357841\n 0.02761059 4.07730714 3.53428672 3.64503584 3.85635173 0.37022326\n 1.79232864 0.5793453  4.31551713 3.11649063 1.65449012 0.31779175\n 1.55491161 1.62591661 3.64803089 3.18778736 4.43606371 2.36107463\n 0.59797123 3.56622394 3.80392524 2.80638599 3.8548359  2.46897798\n 2.61366415 2.13770509 0.12709563 0.53945713 0.15714593 3.18205206\n 1.57177991 2.54285346 4.53783237 1.24646115 2.05191462 3.77775569\n 1.14399083 0.38489955 1.44875726 0.80610644 4.64848826 4.0406019\n 3.16701878 4.35730295 4.01836038 0.93285029 4.46279499 2.69671121\n 4.03720078 4.4804565  1.59001737 0.55025962 1.13967581 2.13553894\n 4.09007383 4.30365292 0.03476065 2.55373651 2.08705502 1.11053905\n 0.59932684 1.68807586 4.71454852 1.61601466 2.59395311 3.51509479\n 1.81814801 4.85891041 4.81223647 1.25891148 2.48624253 1.50439155\n 1.42420247 0.18443474 3.04782167 2.51339512 0.25739376 1.39323232].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m y_resampled \u001b[38;5;241m=\u001b[39m y_resampled\u001b[38;5;241m.\u001b[39mravel()\n\u001b[1;32m     24\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_resampled, y_resampled)\n\u001b[0;32m---> 25\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m mse \u001b[38;5;241m=\u001b[39m mean_squared_error(y, y_pred)\n\u001b[1;32m     27\u001b[0m bootstrap_scores\u001b[38;5;241m.\u001b[39mappend(mse)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_base.py:306\u001b[0m, in \u001b[0;36mLinearModel.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    293\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;124;03m    Predict using the linear model.\u001b[39;00m\n\u001b[1;32m    295\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;124;03m        Returns predicted values.\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_base.py:285\u001b[0m, in \u001b[0;36mLinearModel._decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_decision_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    283\u001b[0m     check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 285\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcoo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    286\u001b[0m     coef_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m coef_\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:633\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    631\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 633\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[1;32m    635\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py:1045\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1038\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1039\u001b[0m             msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1040\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124marray=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marray\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1041\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1042\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1043\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1044\u001b[0m             )\n\u001b[0;32m-> 1045\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_numeric \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(array\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkind\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSV\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1048\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1049\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1050\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1051\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[1.87270059 4.75357153 3.65996971 2.99329242 0.7800932  0.7799726\n 0.29041806 4.33088073 3.00557506 3.54036289 0.10292247 4.84954926\n 4.1622132  1.06169555 0.90912484 0.91702255 1.52121121 2.62378216\n 2.15972509 1.4561457  3.05926447 0.6974693  1.46072324 1.83180922\n 2.28034992 3.92587981 0.99836891 2.57117219 2.96207284 0.23225206\n 3.03772426 0.85262062 0.32525796 4.74442769 4.82816017 4.04198674\n 1.52306885 0.48836057 3.42116513 2.20076247 0.61019117 2.47588455\n 0.17194261 4.54660201 1.29389991 3.31261142 1.55855538 2.60034011\n 2.7335514  0.92427228 4.84792314 3.87566412 4.69749471 4.47413675\n 2.98949989 4.60937118 0.44246251 0.97991431 0.22613644 1.62665165\n 1.94338645 1.35674516 4.14368755 1.78376663 1.40467255 2.71348042\n 0.70462112 4.0109849  0.37275322 4.93443468 3.86122385 0.99357841\n 0.02761059 4.07730714 3.53428672 3.64503584 3.85635173 0.37022326\n 1.79232864 0.5793453  4.31551713 3.11649063 1.65449012 0.31779175\n 1.55491161 1.62591661 3.64803089 3.18778736 4.43606371 2.36107463\n 0.59797123 3.56622394 3.80392524 2.80638599 3.8548359  2.46897798\n 2.61366415 2.13770509 0.12709563 0.53945713 0.15714593 3.18205206\n 1.57177991 2.54285346 4.53783237 1.24646115 2.05191462 3.77775569\n 1.14399083 0.38489955 1.44875726 0.80610644 4.64848826 4.0406019\n 3.16701878 4.35730295 4.01836038 0.93285029 4.46279499 2.69671121\n 4.03720078 4.4804565  1.59001737 0.55025962 1.13967581 2.13553894\n 4.09007383 4.30365292 0.03476065 2.55373651 2.08705502 1.11053905\n 0.59932684 1.68807586 4.71454852 1.61601466 2.59395311 3.51509479\n 1.81814801 4.85891041 4.81223647 1.25891148 2.48624253 1.50439155\n 1.42420247 0.18443474 3.04782167 2.51339512 0.25739376 1.39323232].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Données du monde réel\n",
    "np.random.seed(42)\n",
    "n = 150\n",
    "beta1 = 2\n",
    "x = np.random.uniform(0, 5, n)\n",
    "epsilon = np.random.normal(0, 1, n)\n",
    "beta2 =  0.16\n",
    "y = beta1 * x + beta2 * x**2 + epsilon\n",
    "\n",
    "# Bootstrapping\n",
    "n_bootstraps = 1000\n",
    "bootstrap_scores = []\n",
    "\n",
    "for _ in range(n_bootstraps):\n",
    "\n",
    "    X_resampled, y_resampled = resample(x, y)\n",
    "    \n",
    "    model.fit(X_resampled, y_resampled)\n",
    "    y_pred = model.predict(x)\n",
    "    mse = mean_squared_error(y, y_pred)\n",
    "    bootstrap_scores.append(mse)\n",
    "\n",
    "mean_mse = np.mean(bootstrap_scores)\n",
    "std_mse = np.std(bootstrap_scores)\n",
    "print(f\"Bootstrap MSE: {mean_mse:.4f} ± {std_mse:.4f}\")\n",
    "\n",
    "# Validation croisée\n",
    "cv_scores = cross_val_score(model, x, y, cv=5, scoring='neg_mean_squared_error')\n",
    "mean_cv_mse = -np.mean(cv_scores)\n",
    "std_cv_mse = np.std(cv_scores)\n",
    "print(f\"Cross-Validation MSE: {mean_cv_mse:.4f} ± {std_cv_mse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42) # Definition des variables \n",
    "n = 150\n",
    "beta1 = 2\n",
    "beta2_values = np.linspace(0, 0.16, 9)  # Values of beta2 to test\n",
    "mse_a1 = []\n",
    "mse_a2 = []\n",
    "results = []\n",
    "\n",
    "x = np.random.uniform(0, 5, n)\n",
    "epsilon = np.random.normal(0, 1, n)\n",
    "\n",
    "for beta2 in beta2_values: # Premier essai\n",
    "    y = beta1 * x + beta2 * x**2 + epsilon\n",
    "    \n",
    "    x_reshape = x.reshape(-1, 1)\n",
    "    \n",
    "    # Model a1: simple linear regression (y ~ x)\n",
    "    model_a1 = LinearRegression().fit(x_reshape, y)\n",
    "    y_pred_a1 = model_a1.predict(x_reshape)\n",
    "    mse_a1.append(mean_squared_error(y, y_pred_a1))\n",
    "    coef_a1 = (model_a1.intercept_, model_a1.coef_[0])\n",
    "    \n",
    "    # Model a2: quadratic regression (y ~ x + x^2)\n",
    "    x_quad = np.column_stack((x, x**2))\n",
    "    model_a2 = LinearRegression().fit(x_quad, y)\n",
    "    y_pred_a2 = model_a2.predict(x_quad)\n",
    "    mse_a2.append(mean_squared_error(y, y_pred_a2))\n",
    "    coef_a2 = (model_a2.intercept_, model_a2.coef_[0], model_a2.coef_[1])\n",
    "\n",
    "    results.append({\n",
    "        'beta2': beta2,\n",
    "        'coef_a1_intercept': coef_a1[0],\n",
    "        'coef_a1_x': coef_a1[1],\n",
    "        'mse_a1': mean_squared_error(y, y_pred_a1),\n",
    "        'coef_a2_intercept': coef_a2[0],\n",
    "        'coef_a2_x': coef_a2[1],\n",
    "        'coef_a2_x2': coef_a2[2],\n",
    "        'mse_a2': mean_squared_error(y, y_pred_a2)\n",
    "    })\n",
    "    \n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(beta2_values, mse_a1, label='Linear Regression', marker='o')\n",
    "plt.plot(beta2_values, mse_a2, label='Quadratic Regression', marker='o')\n",
    "plt.xlabel(r'beta_2')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.title('Mean Squared Error vs beta_2 for Linear and Quadratic Models')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
